@article{Dalle2024, 
  doi = {10.21105/joss.06436}, 
  url = {https://doi.org/10.21105/joss.06436}, 
  year = {2024}, 
  publisher = {The Open Journal}, 
  volume = {9}, 
  number = {96}, 
  pages = {6436}, 
  author = {Guillaume Dalle}, 
  title = {HiddenMarkovModels.jl: generic, fast and reliable state space modeling}, 
  journal = {Journal of Open Source Software}
}

@software{PySSM2022,
  title = {SSM: Bayesian learning and inference for state space models},
  author = {Linderman, Scott},
  date = {2022},
  url = {https://github.com/lindermanlab/ssm},
  abstract = {SSM is a python library for fitting state space models},
  keywords = {SSM}
}

@software{HMMjl2024,
  title = {HiddenMarkovModels.jl},
  author = {Dalle, Guillaume},
  date = {2024},
  url = {https://github.com/gdalle/HiddenMarkovModels.jl},
  abstract = {A Julia package for simulation, inference and learning of Hidden Markov Models},
  keywords = {HMM}
}

@software{SSMjl2024,
  title = {StateSpaceModels.jl},
  author = {{Bodin, Guilherme}, {Saavedra, Raphael}},
  date = {2024},
  url = {https://github.com/LAMPSPUC/StateSpaceModels.jl},
  abstract = {StateSpaceModels.jl is a package for modeling, forecasting, 
    and simulating time series in a state-space framework. Implementations were made based on the book 
    "Time Series Analysis by State Space Methods" (2012) by James Durbin and Siem Jan Koopman. 
    The notation of the variables in the code also follows the book.},
  keywords = {SSM}
}

@software{SSLjl2024,
  title = {StateSpaceLearning.jl},
  author = {Ramos, Andre},
  date = {2024},
  url = {https://github.com/LAMPSPUC/StateSpaceLearning.jl},
  abstract = {StateSpaceLearning.jl is a package for modeling and forecasting time series in a high-dimension regression framework},
  keywords = {SSM}
}

@article{NIPS2011_7143d7fb,
 author = {Macke, Jakob H and Buesing, Lars and Cunningham, John P and Yu, Byron M and Shenoy, Krishna V and Sahani, Maneesh},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Empirical models of spiking in neural populations},
 url = {https://proceedings.neurips.cc/paper_files/paper/2011/file/7143d7fbadfa4693b9eec507d9d37443-Paper.pdf},
 volume = {24},
 year = {2011}
}

@software{ChangUnknown-wn,
  type        = {software},
  title       = {dynamax: State Space Models library in {JAX}},
  author      = {Chang, Peter and Harper-Donnelly, Giles and Kara, Aleyna and
                 Li, Xinglong and Linderman, Scott and Murphy, Kevin},
  institution = {Github},
  abstract    = {State Space Models library in JAX. Contribute to probml/dynamax
                 development by creating an account on GitHub.},
  language    = {en}
}

@article{Paninski2010-ns,
  title        = {A new look at state-space models for neural data},
  author       = {Paninski, Liam and Ahmadian, Yashar and Ferreira, Daniel Gil
                  and Koyama, Shinsuke and Rahnama Rad, Kamiar and Vidne,
                  Michael and Vogelstein, Joshua and Wu, Wei},
  journaltitle = {J. Comput. Neurosci.},
  publisher    = {Springer Science and Business Media LLC},
  volume       = {29},
  issue        = {1-2},
  pages        = {107--126},
  date         = {2010-08},
  abstract     = {State space methods have proven indispensable in neural data
                  analysis. However, common methods for performing inference in
                  state-space models with non-Gaussian observations rely on
                  certain approximations which are not always accurate. Here we
                  review direct optimization methods that avoid these
                  approximations, but that nonetheless retain the computational
                  efficiency of the approximate methods. We discuss a variety of
                  examples, applying these direct optimization techniques to
                  problems in spike train smoothing, stimulus decoding,
                  parameter estimation, and inference of synaptic properties.
                  Along the way, we point out connections to some related
                  standard statistical methods, including spline smoothing and
                  isotonic regression. Finally, we note that the computational
                  methods reviewed here do not in fact depend on the state-space
                  setting at all; instead, the key property we are exploiting
                  involves the bandedness of certain matrices. We close by
                  discussing some applications of this more general point of
                  view, including Markov chain Monte Carlo methods for neural
                  decoding and efficient estimation of spatially-varying firing
                  rates.},
  urldate      = {2024-09-11},
  language     = {en}
}

@software{SSDjl2024,
  title = {StateSpaceDynamics.jl: A Julia package for probabilistic
state space models},
  author = {Senne, Ryan and Loughridge, Carson and Loschinsky, Zach and DePasquale, Brian},
  date = {2024},
  howpublished = {\url{https://github.com/depasquale-lab/StateSpaceDynamics.jl}},
  url = {https://github.com/depasquale-lab/StateSpaceDynamics.jl},
  abstract = {A Julia package for probabilistic state space models},
  keywords = {SSM}
}

@article{bezanson2017julia,
  title={Julia: A fresh approach to numerical computing},
  author={Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
  journal={SIAM review},
  volume={59},
  number={1},
  pages={65--98},
  year={2017},
  publisher={SIAM}
}