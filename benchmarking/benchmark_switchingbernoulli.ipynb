{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    CondaPkg \u001b[22m\u001b[39m\u001b[0mFound dependencies: c:\\Users\\zachl\\OneDrive\\Documents\\GitHub\\StateSpaceDynamics.jl\\benchmarking\\CondaPkg.toml\n",
      "\u001b[32m\u001b[1m    CondaPkg \u001b[22m\u001b[39m\u001b[0mFound dependencies: C:\\Users\\zachl\\.julia\\packages\\PythonCall\\Nr75f\\CondaPkg.toml\n",
      "\u001b[32m\u001b[1m    CondaPkg \u001b[22m\u001b[39m\u001b[0mDependencies already up to date\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "using Random\n",
    "using Statistics\n",
    "using PythonCall\n",
    "using DataFrames\n",
    "using Printf\n",
    "using LinearAlgebra\n",
    "using CSV\n",
    "using Distributions\n",
    "using HiddenMarkovModels\n",
    "using StateSpaceDynamics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python: <module 'jax.numpy' from 'c:\\\\Users\\\\zachl\\\\OneDrive\\\\Documents\\\\GitHub\\\\StateSpaceDynamics.jl\\\\benchmarking\\\\.CondaPkg\\\\env\\\\Lib\\\\site-packages\\\\jax\\\\numpy\\\\__init__.py'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const np = pyimport(\"numpy\")\n",
    "const dynamax = pyimport(\"dynamax.hidden_markov_model\")\n",
    "const jr = pyimport(\"jax.random\")\n",
    "const jnp = pyimport(\"jax.numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benchmark_fitting (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "struct BenchConfig\n",
    "    latent_dims::Vector{Int}\n",
    "    input_dims::Vector{Int}\n",
    "    obs_dims::Vector{Int} \n",
    "    seq_lengths::Vector{Int}\n",
    "    n_iters::Int\n",
    "    n_repeats::Int\n",
    "end\n",
    "\n",
    "default_config = BenchConfig(\n",
    "    [2,4,8,16],       # latent dimensions\n",
    "    [2,4,8,16],        # input dimension\n",
    "    [1],      # observation dimensions \n",
    "    [100, 500, 1000],    # sequence lengths\n",
    "    200,                 # EM iterations\n",
    "    5                    # benchmark repeats\n",
    ")\n",
    "\n",
    "function initialize_transition_matrix(K::Int)\n",
    "    # Initialize a transition matrix with zeros\n",
    "    A = zeros(Float64, K, K)\n",
    "    \n",
    "    for i in 1:K\n",
    "        # Sample from a Dirichlet distribution\n",
    "        A[i, :] = rand(Dirichlet(ones(K)))\n",
    "    end\n",
    "\n",
    "    A .+= 0.5.*I(K)\n",
    "    A .= A ./ sum(A, dims=2)\n",
    "    return A\n",
    "end\n",
    "\n",
    "function initialize_state_distribution(K::Int)\n",
    "    # initialize a state distribution\n",
    "    return rand(Dirichlet(ones(K)))\n",
    "end\n",
    "\n",
    "\n",
    "function generate_random_hmm(latent_dim::Int, input_dim::Int, obs_dim::Int)\n",
    "    \"\"\"\n",
    "    Create the StateSpaceDynamics.jl Model\n",
    "    \"\"\"\n",
    "    # Create Gaussian Emission Models with random means and covariances\n",
    "    emissions = Vector{BernoulliRegressionEmission}(undef, latent_dim)\n",
    "    true_model = StateSpaceDynamics.SwitchingBernoulliRegression(K=latent_dim, input_dim=input_dim, output_dim=obs_dim, include_intercept=false)\n",
    "\n",
    "    # Make the dynamax emission weights\n",
    "    key=jr.PRNGKey(1)\n",
    "    emission_dyna = jr.uniform(key, shape=(latent_dim, input_dim))\n",
    "    emission_biases=jnp.zeros(input_dim)\n",
    "    emission_ssd = pyconvert(Matrix, emission_dyna)\n",
    "    emission_ssd = convert(Matrix{Float64}, emission_ssd)\n",
    "\n",
    "    # Loop through each row of the emission_ssd matrix\n",
    "    for (state, row) in enumerate(eachrow(emission_ssd))\n",
    "        β = Matrix(reshape(row, :, 1))\n",
    "        true_model.B[state] = BernoulliRegressionEmission(input_dim=input_dim, output_dim=obs_dim, β=β, include_intercept=false)\n",
    "    end\n",
    "\n",
    "    true_model.A = initialize_transition_matrix(latent_dim)\n",
    "    true_model.πₖ = initialize_state_distribution(latent_dim)\n",
    "\n",
    "    \"\"\"\n",
    "    Create the Dynamax Model\n",
    "    \"\"\"\n",
    "    # Convert Julia parameters to NumPy arrays\n",
    "    initial_probs = jnp.array(true_model.πₖ)  # Convert initial state probabilities\n",
    "    transition_matrix = jnp.array(true_model.A)  # Convert transition matrix\n",
    "\n",
    "    dynamax_model = dynamax.LogisticRegressionHMM(\n",
    "    num_states=latent_dim,\n",
    "    input_dim=input_dim\n",
    "    )\n",
    "\n",
    "    params, props = dynamax_model.initialize(\n",
    "        method=\"prior\",\n",
    "        initial_probs=initial_probs,\n",
    "        transition_matrix=transition_matrix,\n",
    "        emission_weights=emission_dyna,\n",
    "        emission_biases=emission_biases\n",
    "    )\n",
    "\n",
    "    return true_model, dynamax_model, params, props\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function generate_test_data(model, seq_len::Int)\n",
    "    # Generate random input data\n",
    "    Φ = randn(model.B[1].input_dim, seq_len)\n",
    "\n",
    "    # Sample from the model\n",
    "    labels, data = StateSpaceDynamics.sample(model, Φ, n=seq_len)\n",
    "\n",
    "    return model, labels, Φ, data\n",
    "end\n",
    "\n",
    "\n",
    "function run_single_benchmark(model_type::Symbol, hmm_ssd, y, inputs, params=nothing, props=nothing; config=default_config)\n",
    "    if model_type == :julia\n",
    "        bench = @benchmark begin\n",
    "            model = deepcopy($hmm_ssd)  # Create a fresh copy for each iteration\n",
    "            StateSpaceDynamics.fit!(model, $y, $inputs, max_iters=200, tol=1e-15)\n",
    "        end samples=config.n_repeats\n",
    "        return (time=median(bench).time, memory=bench.memory, allocs=bench.allocs, success=true)\n",
    "    else\n",
    "        bench = @benchmark begin\n",
    "            dynamax_model=deepcopy($hmm_ssd)\n",
    "            p = deepcopy($params)\n",
    "            pr = deepcopy($props)\n",
    "            dynamax_model.fit_em(p, pr, $y, $inputs, num_iters=200,verbose=false)\n",
    "        end samples=config.n_repeats\n",
    "        return (time=median(bench).time, memory=bench.memory, allocs=bench.allocs, success=true)        \n",
    "    end\n",
    "end\n",
    "\n",
    "function benchmark_fitting(config::BenchConfig = default_config)\n",
    "    results = []\n",
    "\n",
    "    for latent_dim in config.latent_dims\n",
    "        for input_dim in config.input_dims\n",
    "            for obs_dim in config.obs_dims\n",
    "                for seq_len in config.seq_lengths\n",
    "                    println(\"\\nTesting configuration: latent_dim=$latent_dim, input_dim=$input_dim, obs_dim=$obs_dim, seq_len=$seq_len\")\n",
    "\n",
    "                    # Create true model\n",
    "                    true_model, dynamax_model, params, props = generate_random_hmm(latent_dim, input_dim, obs_dim)\n",
    "                    \n",
    "                    # Generate test data\n",
    "                    model, labels, Φ, data = generate_test_data(true_model, seq_len)\n",
    "                    vectorized_data = [data[:, i] for i in 1:size(data, 2)]  # Vectorize for HMMjl\n",
    "\n",
    "                    # Convert inputs to NumPy format (inputs are seq_len x input_dim in dynamax)\n",
    "                    inputs_np = np.array(Φ')\n",
    "                    data_np = np.array(data)[0]\n",
    "                    labels_np = np.array(labels .- 1)  # Dynamax expects labels indexed from 0\n",
    "\n",
    "                    # Generate random HMMs for fitting\n",
    "                    test_model, dynamax_model, params, props = generate_random_hmm(latent_dim, input_dim, obs_dim)\n",
    "\n",
    "                    # Run benchmarks separately with error handling\n",
    "                    julia_result = try\n",
    "                        run_single_benchmark(:julia, test_model, data, Φ)\n",
    "                    catch err\n",
    "                        println(\"Error in SSD.jl benchmarking: \", err)\n",
    "                        (time=\"FAIL\", memory=\"FAIL\", allocs=\"FAIL\", success=false)\n",
    "                    end\n",
    "\n",
    "                    dynamax_result = try\n",
    "                        run_single_benchmark(:dynamax, dynamax_model, data_np, inputs_np, params, props)\n",
    "                    catch err\n",
    "                        println(\"Error in dynamax benchmarking: \", err)\n",
    "                        (time=\"FAIL\", memory=\"FAIL\", allocs=\"FAIL\", success=false)\n",
    "                    end\n",
    "\n",
    "                    # Save results\n",
    "                    push!(results, Dict(\n",
    "                        \"config\" => (latent_dim=latent_dim, input_dim=input_dim, obs_dim=obs_dim, seq_len=seq_len),\n",
    "                        \"SSD.jl\" => julia_result,\n",
    "                        \"Dynamax\" => dynamax_result\n",
    "                    ))\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = benchmark_fitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function prepare_results_for_csv(results)\n",
    "    rows = []\n",
    "    for result in results\n",
    "        config = result[\"config\"]\n",
    "        ssd = result[\"SSD.jl\"]\n",
    "        Dynamax = result[\"Dynamax\"]\n",
    "\n",
    "        # Add a row for SSD.jl\n",
    "        push!(rows, (\n",
    "            latent_dim=config.latent_dim,\n",
    "            obs_dim=config.obs_dim,\n",
    "            seq_len=config.seq_len,\n",
    "            library=\"SSD.jl\",\n",
    "            time=ssd.time,\n",
    "            memory=ssd.memory,\n",
    "            allocs=ssd.allocs,\n",
    "            success=ssd.success,\n",
    "        ))\n",
    "\n",
    "        # Add a row for HMM.jl\n",
    "        push!(rows, (\n",
    "            latent_dim=config.latent_dim,\n",
    "            obs_dim=config.obs_dim,\n",
    "            seq_len=config.seq_len,\n",
    "            library=\"Dynamax\",\n",
    "            time=Dynamax.time,\n",
    "            memory=Dynamax.memory,\n",
    "            allocs=Dynamax.allocs,\n",
    "            success=Dynamax.success,\n",
    "        ))\n",
    "    end\n",
    "    return DataFrame(rows)\n",
    "end\n",
    "\n",
    "results_df = prepare_results_for_csv(results)\n",
    "CSV.write(\"benchmark_results.csv\", results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function transform_to_df(data_vector::Vector)\n",
    "    # Initialize vectors for all our columns\n",
    "    packages = String[]\n",
    "    times = Float64[]\n",
    "    memories = Int[]\n",
    "    allocs = Int[]\n",
    "    successes = Bool[]\n",
    "    latent_dims = Int[]\n",
    "    obs_dims = Int[]\n",
    "    seq_lens = Int[]\n",
    "    \n",
    "    # Process each dictionary in the vector\n",
    "    for dict in data_vector\n",
    "        # Get configuration values for this batch\n",
    "        config = dict[\"config\"]\n",
    "        latent_dim = config.latent_dim\n",
    "        obs_dim = config.obs_dim\n",
    "        seq_len = config.seq_len\n",
    "        \n",
    "        # Process each package's results\n",
    "        for (pkg_name, results) in dict\n",
    "            if pkg_name != \"config\"\n",
    "                push!(packages, pkg_name)\n",
    "                push!(times, results.time)\n",
    "                push!(memories, results.memory)\n",
    "                push!(allocs, results.allocs)\n",
    "                push!(successes, results.success)\n",
    "                push!(latent_dims, latent_dim)\n",
    "                push!(obs_dims, obs_dim)\n",
    "                push!(seq_lens, seq_len)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    DataFrame(\n",
    "        package = packages,\n",
    "        time = times,\n",
    "        memory = memories,\n",
    "        allocs = allocs,\n",
    "        success = successes,\n",
    "        latent_dim = latent_dims,\n",
    "        obs_dim = obs_dims,\n",
    "        seq_length = seq_lens\n",
    "    )\n",
    "end\n",
    "\n",
    "function plot_benchmarks(df::DataFrame)\n",
    "    # Create a unique identifier for each obs_dim/latent_dim combination\n",
    "    df.dim_combo = string.(df.obs_dim, \"x\", df.latent_dim)\n",
    "    \n",
    "    # Define line styles that will cycle if we have more combinations than styles\n",
    "    base_styles = [:solid, :dash, :dot, :dashdot, :dashdotdot]\n",
    "    dim_combos = unique(df.dim_combo)\n",
    "    \n",
    "    # Create style dictionary by cycling through available styles\n",
    "    style_dict = Dict(\n",
    "        combo => base_styles[mod1(i, length(base_styles))] \n",
    "        for (i, combo) in enumerate(dim_combos)\n",
    "    )\n",
    "    \n",
    "    # Create the plot\n",
    "    p = plot(\n",
    "        xlabel=\"Sequence Length\",\n",
    "        ylabel=\"Time (seconds)\",\n",
    "        title=\"Package Performance Across Sequence Lengths\",\n",
    "        legend=:outertopright,\n",
    "        xscale=:log10,\n",
    "        yscale=:log10\n",
    "    )\n",
    "    \n",
    "    # Plot each package with a different color\n",
    "    packages = unique(df.package)\n",
    "    for (i, pkg) in enumerate(packages)\n",
    "        pkg_data = df[df.package .== pkg, :]\n",
    "        \n",
    "        # Plot each dimension combination for this package\n",
    "        for dim_combo in dim_combos\n",
    "            combo_data = pkg_data[pkg_data.dim_combo .== dim_combo, :]\n",
    "            if !isempty(combo_data)\n",
    "                plot!(\n",
    "                    p,\n",
    "                    combo_data.seq_length,\n",
    "                    combo_data.time ./ 1e9,  # Convert to seconds\n",
    "                    label=\"$(pkg) ($(dim_combo))\",\n",
    "                    color=i,\n",
    "                    linestyle=style_dict[dim_combo],\n",
    "                    marker=:circle,\n",
    "                    markersize=4\n",
    "                )\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Add gridlines and adjust layout\n",
    "    plot!(\n",
    "        p,\n",
    "        grid=true,\n",
    "        minorgrid=true,\n",
    "        size=(900, 600),\n",
    "        margin=10Plots.mm\n",
    "    )\n",
    "    \n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = transform_to_df(results)\n",
    "df.time = df.time / 1e9;\n",
    "\n",
    "CSV.write(\"benchmark_results_bernoulli.csv\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "benchmark_plot = plot_benchmarks(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
