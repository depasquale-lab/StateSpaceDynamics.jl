{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using Random\n",
    "using Statistics\n",
    "using PythonCall\n",
    "using DataFrames\n",
    "using Printf\n",
    "using LinearAlgebra\n",
    "using CSV\n",
    "using Distributions\n",
    "using HiddenMarkovModels\n",
    "using StateSpaceDynamics\n",
    "using Base.Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HiddenMarkovModels as HMMs\n",
    "using StatsAPI\n",
    "using StableRNGs\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function HiddenMarkovModels.baum_welch_has_converged(\n",
    "    logL_evolution::Vector; atol::Real, loglikelihood_increasing::Bool\n",
    ")\n",
    "    if length(logL_evolution) >= 2\n",
    "        logL, logL_prev = logL_evolution[end], logL_evolution[end - 1]\n",
    "        progress = logL - logL_prev\n",
    "        if loglikelihood_increasing && progress < min(0, -atol)\n",
    "            error(\"Loglikelihood decreased from $logL_prev to $logL in Baum-Welch\")\n",
    "        elseif progress < atol\n",
    "            return false\n",
    "        end\n",
    "    end\n",
    "    return false\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for fitting SwitchingBernoulliRegression using HMM.jl\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "logistic(x) = 1 / (1 + exp(-x))\n",
    "\n",
    "# Helper function: Converts a vector to a matrix with a given shape\n",
    "function vec_to_matrix(vec::Vector, shape::Tuple{Int, Int})\n",
    "    reshape(vec, shape)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "mutable struct ControlledBernoulliHMM{T} <: HMMs.AbstractHMM\n",
    "    init::Vector{T}\n",
    "    trans::Matrix{T}\n",
    "    dist_coeffs::Vector{Vector{T}}  # One vector for each state\n",
    "end\n",
    "\n",
    "function HMMs.initialization(hmm::ControlledBernoulliHMM)\n",
    "    return hmm.init\n",
    "end\n",
    "\n",
    "function HMMs.transition_matrix(hmm::ControlledBernoulliHMM, control::AbstractVector)\n",
    "    return hmm.trans\n",
    "end\n",
    "\n",
    "# Modified to use Bernoulli with probabilities from logistic regression\n",
    "function HMMs.obs_distributions(hmm::ControlledBernoulliHMM, control::AbstractVector)\n",
    "    return [\n",
    "        Bernoulli(logistic(dot(hmm.dist_coeffs[i], control))) for i in 1:length(hmm)\n",
    "    ]\n",
    "end\n",
    "\n",
    "\n",
    "# Example regression optimization structure\n",
    "struct RegressionOptimizationTest{}\n",
    "    X::Matrix{}\n",
    "    y::Matrix{}\n",
    "    w::Vector{}\n",
    "    β_shape::Tuple{Int, Int}\n",
    "end\n",
    "\n",
    "# Bernoulli Regression Objective Function\n",
    "function objective(opt::RegressionOptimizationTest, β_vec)\n",
    "    β_mat = vec_to_matrix(β_vec, opt.β_shape) # Reshape vector to matrix\n",
    "    p = logistic.(opt.X * β_mat)             # Predicted probabilities\n",
    "    # Calculate negative log-likelihood\n",
    "    val = -sum(opt.w .* (opt.y .* log.(p) .+ (1 .- opt.y) .* log.(1 .- p)))\n",
    "    return val\n",
    "end\n",
    "\n",
    "function objective_gradient!(\n",
    "    G::Vector{Float64},\n",
    "    opt::RegressionOptimizationTest,\n",
    "    β_vec::Vector{Float64})\n",
    "    β_mat = vec_to_matrix(β_vec, opt.β_shape)\n",
    "\n",
    "\n",
    "    p = logistic.(opt.X * β_mat)\n",
    "\n",
    "    grad_mat = -(opt.X' * (opt.w .* (opt.y .- p)))\n",
    "    return G .= vec(grad_mat)\n",
    "end\n",
    "\n",
    "\n",
    "function fit_bern(X::Matrix{<:Real}, y::Matrix{<:Real}, β_shape::Tuple{Int, Int}, β_init::Vector{<:Real}, w::Vector{Float64}=ones(size(y,1)))\n",
    "    # Create the RegressionOptimization struct\n",
    "    opt_problem = RegressionOptimizationTest(X, y, w, β_shape)\n",
    "    f(β) = objective(opt_problem, β)\n",
    "    g!(G, β) = objective_gradient!(G, opt_problem, β)\n",
    "\n",
    "    # Set optimization options\n",
    "    opts = Optim.Options(\n",
    "        x_abstol=1e-8,\n",
    "        x_reltol=1e-8,\n",
    "        f_abstol=1e-8,\n",
    "        f_reltol=1e-8,\n",
    "        g_abstol=1e-8,\n",
    "        g_reltol=1e-8,\n",
    "    )\n",
    "\n",
    "    # Run optimization\n",
    "    result = optimize(f, g!, β_init, LBFGS(), opts)\n",
    "    # Retrieve the optimized parameters\n",
    "    β_opt_vec = result.minimizer\n",
    "    β_opt_mat = vec_to_matrix(β_opt_vec, β_shape)\n",
    "\n",
    "    return β_opt_mat\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "function StatsAPI.fit!(\n",
    "    hmm::ControlledBernoulliHMM{T},\n",
    "    fb_storage::HMMs.ForwardBackwardStorage,\n",
    "    obs_seq::AbstractVector,\n",
    "    control_seq::AbstractVector;\n",
    "    seq_ends,\n",
    ") where {T}\n",
    "    (; γ, ξ) = fb_storage\n",
    "    N = length(hmm)\n",
    "\n",
    "    # Update initial probabilities and transition matrix\n",
    "    hmm.init .= 0\n",
    "    hmm.trans .= 0\n",
    "    for k in eachindex(seq_ends)\n",
    "        t1, t2 = HMMs.seq_limits(seq_ends, k)\n",
    "        hmm.init .+= γ[:, t1]\n",
    "        hmm.trans .+= sum(ξ[t1:t2])\n",
    "    end\n",
    "    hmm.init ./= sum(hmm.init)\n",
    "    for row in eachrow(hmm.trans)\n",
    "        row ./= sum(row)\n",
    "    end\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Update Bernoulli Regression Coefficients for Each State\n",
    "    \"\"\"\n",
    "    updated_betas = Vector{Vector{Float64}}(undef, N)  # To store new coefficients for each state\n",
    "    @threads for i in 1:N\n",
    "        # Weight observations by state responsibility (γ)\n",
    "        state_weights = γ[i, :]\n",
    "\n",
    "        # Get right shapes for fit_bern\n",
    "        β_shape = size(hmm.dist_coeffs[i])[1]\n",
    "        β_init = vec(hmm.dist_coeffs[i])\n",
    "        control_matrix = hcat(control_seq...)\n",
    "        obs_matrix = reshape(obs_seq, :, 1)\n",
    "        control_matrix = permutedims(control_matrix)\n",
    "        result = fit_bern(control_matrix, obs_matrix,(β_shape, 1), β_init, state_weights)\n",
    "\n",
    "        # Store updated coefficients\n",
    "        updated_betas[i] = vec(result)  # Store the updated coefficients as a vector\n",
    "    end\n",
    "\n",
    "    # Update the HMM's coefficients with the newly fitted values\n",
    "    hmm.dist_coeffs = updated_betas\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python: <module 'jax.numpy' from 'c:\\\\Users\\\\zachl\\\\OneDrive\\\\Documents\\\\GitHub\\\\StateSpaceDynamics.jl\\\\benchmarking\\\\.CondaPkg\\\\env\\\\Lib\\\\site-packages\\\\jax\\\\numpy\\\\__init__.py'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const np = pyimport(\"numpy\")\n",
    "const dynamax = pyimport(\"dynamax.hidden_markov_model\")\n",
    "const jr = pyimport(\"jax.random\")\n",
    "const jnp = pyimport(\"jax.numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benchmark_fitting (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Functions for benchmarking\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "struct BenchConfig\n",
    "    latent_dims::Vector{Int}\n",
    "    input_dims::Vector{Int}\n",
    "    obs_dims::Vector{Int} \n",
    "    seq_lengths::Vector{Int}\n",
    "    n_iters::Int\n",
    "    n_repeats::Int\n",
    "end\n",
    "\n",
    "default_config = BenchConfig(\n",
    "    [2,4,8],       # latent dimensions\n",
    "    [2,4,8],        # input dimension\n",
    "    [1],      # observation dimensions \n",
    "    [100, 200, 1000],    # sequence lengths\n",
    "    200,                 # EM iterations\n",
    "    5                    # benchmark repeats\n",
    ")\n",
    "\n",
    "function initialize_transition_matrix(K::Int)\n",
    "    # Initialize a transition matrix with zeros\n",
    "    A = zeros(Float64, K, K)\n",
    "    \n",
    "    for i in 1:K\n",
    "        # Sample from a Dirichlet distribution\n",
    "        A[i, :] = rand(Dirichlet(ones(K)))\n",
    "    end\n",
    "\n",
    "    A .+= 0.5.*I(K)\n",
    "    A .= A ./ sum(A, dims=2)\n",
    "    return A\n",
    "end\n",
    "\n",
    "function initialize_state_distribution(K::Int)\n",
    "    # initialize a state distribution\n",
    "    return rand(Dirichlet(ones(K)))\n",
    "end\n",
    "\n",
    "\n",
    "function generate_random_hmm(latent_dim::Int, input_dim::Int, obs_dim::Int)\n",
    "    \"\"\"\n",
    "    Create the StateSpaceDynamics.jl Model\n",
    "    \"\"\"\n",
    "    # Create Gaussian Emission Models with random means and covariances\n",
    "    emissions = Vector{BernoulliRegressionEmission}(undef, latent_dim)\n",
    "    emissions_hmmjl = Vector{Any}(undef, latent_dim)\n",
    "    true_model = StateSpaceDynamics.SwitchingBernoulliRegression(K=latent_dim, input_dim=input_dim, output_dim=obs_dim, include_intercept=false)\n",
    "\n",
    "    # Make the dynamax emission weights\n",
    "    key=jr.PRNGKey(1)\n",
    "    emission_dyna = jr.uniform(key, shape=(latent_dim, input_dim))\n",
    "    emission_biases=jnp.zeros(input_dim)\n",
    "    emission_ssd = pyconvert(Matrix, emission_dyna)\n",
    "    emission_ssd = convert(Matrix{Float64}, emission_ssd)\n",
    "\n",
    "    # Loop through each row of the emission_ssd matrix\n",
    "    for (state, row) in enumerate(eachrow(emission_ssd))\n",
    "        β = Matrix(reshape(row, :, 1))\n",
    "        true_model.B[state] = BernoulliRegressionEmission(input_dim=input_dim, output_dim=obs_dim, β=β, include_intercept=false)\n",
    "        emissions_hmmjl[state] = convert(Vector{Float64}, row)\n",
    "    end\n",
    "\n",
    "    true_model.A = initialize_transition_matrix(latent_dim)\n",
    "    true_model.πₖ = initialize_state_distribution(latent_dim)\n",
    "\n",
    "    \"\"\"\n",
    "    Create the HMM.jl model\n",
    "    \"\"\"\n",
    "    init = true_model.πₖ\n",
    "    trans = true_model.A\n",
    "    emissions_hmmjl = convert(Vector{Vector{Float64}}, emissions_hmmjl)\n",
    "    hmmjl = ControlledBernoulliHMM(init, trans, emissions_hmmjl)\n",
    "\n",
    "    \"\"\"\n",
    "    Create the Dynamax Model\n",
    "    \"\"\"\n",
    "    # Convert Julia parameters to NumPy arrays\n",
    "    initial_probs = jnp.array(true_model.πₖ)  # Convert initial state probabilities\n",
    "    transition_matrix = jnp.array(true_model.A)  # Convert transition matrix\n",
    "\n",
    "    dynamax_model = dynamax.LogisticRegressionHMM(\n",
    "    num_states=latent_dim,\n",
    "    input_dim=input_dim\n",
    "    )\n",
    "\n",
    "    params, props = dynamax_model.initialize(\n",
    "        method=\"prior\",\n",
    "        initial_probs=initial_probs,\n",
    "        transition_matrix=transition_matrix,\n",
    "        emission_weights=emission_dyna,\n",
    "        emission_biases=emission_biases\n",
    "    )\n",
    "\n",
    "    return true_model, dynamax_model, params, props, hmmjl\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function generate_test_data(model, seq_len::Int)\n",
    "    # Generate random input data\n",
    "    Φ = randn(model.B[1].input_dim, seq_len)\n",
    "\n",
    "    # Sample from the model\n",
    "    labels, data = StateSpaceDynamics.sample(model, Φ, n=seq_len)\n",
    "\n",
    "    return model, labels, Φ, data\n",
    "end\n",
    "\n",
    "\n",
    "function run_single_benchmark(model_type::Symbol, hmm_ssd, y, inputs, params=nothing, props=nothing; config=default_config, seq_ends=nothing)\n",
    "    if model_type == :julia\n",
    "        bench = @benchmark begin\n",
    "            model = deepcopy($hmm_ssd)  # Create a fresh copy for each iteration\n",
    "            StateSpaceDynamics.fit!(model, $y, $inputs, max_iters=200, tol=1e-25)\n",
    "        end samples=config.n_repeats\n",
    "        return (time=median(bench).time, memory=bench.memory, allocs=bench.allocs, success=true)\n",
    "    elseif model_type==:dynamax\n",
    "        bench = @benchmark begin\n",
    "            dynamax_model=deepcopy($hmm_ssd)\n",
    "            p = deepcopy($params)\n",
    "            pr = deepcopy($props)\n",
    "            dynamax_model.fit_em(p, pr, $y, $inputs, num_iters=200,verbose=false)\n",
    "        end samples=config.n_repeats\n",
    "        return (time=median(bench).time, memory=bench.memory, allocs=bench.allocs, success=true)\n",
    "    else\n",
    "        bench = @benchmark begin\n",
    "            hmm=deepcopy($hmm_ssd)\n",
    "            hmm_est, loglikelihood_evolution = baum_welch(hmm, vec($y), $inputs, loglikelihood_increasing=false, max_iterations=200; seq_ends=[length(vec($y))])\n",
    "        end samples=config.n_repeats\n",
    "        return (time=median(bench).time, memory=bench.memory, allocs=bench.allocs, success=true)\n",
    "    end\n",
    "end\n",
    "\n",
    "function benchmark_fitting(config::BenchConfig = default_config)\n",
    "    results = []\n",
    "\n",
    "    for latent_dim in config.latent_dims\n",
    "        for input_dim in config.input_dims\n",
    "            for obs_dim in config.obs_dims\n",
    "                for seq_len in config.seq_lengths\n",
    "                    println(\"\\nTesting configuration: latent_dim=$latent_dim, input_dim=$input_dim, obs_dim=$obs_dim, seq_len=$seq_len\")\n",
    "\n",
    "                    # Create true model\n",
    "                    true_model, dynamax_model, params, props, hmmjl = generate_random_hmm(latent_dim, input_dim, obs_dim)\n",
    "                    \n",
    "                    # Generate test data\n",
    "                    model, labels, Φ, data = generate_test_data(true_model, seq_len)\n",
    "                    vectorized_data = [data[:, i] for i in 1:size(data, 2)]  # Vectorize for HMMjl\n",
    "\n",
    "                    # Convert inputs to NumPy format (inputs are seq_len x input_dim in dynamax)\n",
    "                    inputs_np = np.array(Φ')\n",
    "                    data_np = np.array(data)[0]\n",
    "                    labels_np = np.array(labels .- 1)  # Dynamax expects labels indexed from 0\n",
    "\n",
    "                    # Generate random HMMs for fitting\n",
    "                    test_model, dynamax_model, params, props, hmmjl = generate_random_hmm(latent_dim, input_dim, obs_dim)\n",
    "\n",
    "                    # get data in format for hmm.jl benchmarking\n",
    "                    # convert to vector\n",
    "                    obs_seq = vec(data)\n",
    "                    seq_ends = [length(obs_seq)]\n",
    "                    Φ_vector = [Φ[:, t] for t in 1:size(Φ, 2)]  # Create vector for baum_welch input\n",
    "                    \n",
    "                    \n",
    "                    hmmjl_result = try\n",
    "                        println(\"Testing HMM.jl\")\n",
    "                        run_single_benchmark(:hmmjl, hmmjl, data, Φ_vector; seq_ends=seq_ends)\n",
    "                    catch err\n",
    "                        println(\"Error in HMM.jl benchmarking: \", err)\n",
    "                        (time=\"FAIL\", memory=\"FAIL\", allocs=\"FAIL\", success=false)\n",
    "                    end\n",
    "\n",
    "                    # Run benchmarks separately with error handling\n",
    "                    julia_result = try\n",
    "                        println(\"Testing SSD.jl\")\n",
    "                        run_single_benchmark(:julia, test_model, data, Φ)\n",
    "                    catch err\n",
    "                        println(\"Error in SSD.jl benchmarking: \", err)\n",
    "                        (time=\"FAIL\", memory=\"FAIL\", allocs=\"FAIL\", success=false)\n",
    "                    end\n",
    "\n",
    "                    dynamax_result = try\n",
    "                        println(\"Testing Dynamax\")\n",
    "                        run_single_benchmark(:dynamax, dynamax_model, data_np, inputs_np, params, props)\n",
    "                    catch err\n",
    "                        println(\"Error in dynamax benchmarking: \", err)\n",
    "                        (time=\"FAIL\", memory=\"FAIL\", allocs=\"FAIL\", success=false)\n",
    "                    end\n",
    "\n",
    "                    # Save results\n",
    "                    push!(results, Dict(\n",
    "                        \"config\" => (latent_dim=latent_dim, input_dim=input_dim, obs_dim=obs_dim, seq_len=seq_len),\n",
    "                        \"SSD.jl\" => julia_result,\n",
    "                        \"Dynamax\" => dynamax_result,\n",
    "                        \"HMM.jl\" => hmmjl_result\n",
    "                    ))\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing configuration: latent_dim=2, input_dim=2, obs_dim=1, seq_len=100\n",
      "Testing HMM.jl\n"
     ]
    }
   ],
   "source": [
    "results = benchmark_fitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function prepare_results_for_csv(results)\n",
    "    rows = []\n",
    "    for result in results\n",
    "        config = result[\"config\"]\n",
    "        ssd = result[\"SSD.jl\"]\n",
    "        Dynamax = result[\"Dynamax\"]\n",
    "        hmmjl = result[\"HMM.jl\"]\n",
    "\n",
    "        # Add a row for SSD.jl\n",
    "        push!(rows, (\n",
    "            latent_dim=config.latent_dim,\n",
    "            obs_dim=config.obs_dim,\n",
    "            seq_len=config.seq_len,\n",
    "            library=\"SSD.jl\",\n",
    "            time=ssd.time,\n",
    "            memory=ssd.memory,\n",
    "            allocs=ssd.allocs,\n",
    "            success=ssd.success,\n",
    "        ))\n",
    "\n",
    "        # Add a row for HMM.jl\n",
    "        push!(rows, (\n",
    "            latent_dim=config.latent_dim,\n",
    "            obs_dim=config.obs_dim,\n",
    "            seq_len=config.seq_len,\n",
    "            library=\"Dynamax\",\n",
    "            time=Dynamax.time,\n",
    "            memory=Dynamax.memory,\n",
    "            allocs=Dynamax.allocs,\n",
    "            success=Dynamax.success,\n",
    "        ))\n",
    "\n",
    "        # Add a row for HMM.jl\n",
    "        push!(rows, (\n",
    "            latent_dim=config.latent_dim,\n",
    "            obs_dim=config.obs_dim,\n",
    "            seq_len=config.seq_len,\n",
    "            library=\"HMM.jll\",\n",
    "            time=hmmjl.time,\n",
    "            memory=hmmjl.memory,\n",
    "            allocs=hmmjl.allocs,\n",
    "            success=hmmjl.success,\n",
    "        ))\n",
    "    end\n",
    "    return DataFrame(rows)\n",
    "end\n",
    "\n",
    "results_df = prepare_results_for_csv(results)\n",
    "CSV.write(\"benchmark_results.csv\", results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function transform_to_df(data_vector::Vector)\n",
    "    # Initialize vectors for all our columns\n",
    "    packages = String[]\n",
    "    times = Float64[]\n",
    "    memories = Int[]\n",
    "    allocs = Int[]\n",
    "    successes = Bool[]\n",
    "    latent_dims = Int[]\n",
    "    obs_dims = Int[]\n",
    "    seq_lens = Int[]\n",
    "    \n",
    "    # Process each dictionary in the vector\n",
    "    for dict in data_vector\n",
    "        # Get configuration values for this batch\n",
    "        config = dict[\"config\"]\n",
    "        latent_dim = config.latent_dim\n",
    "        obs_dim = config.obs_dim\n",
    "        seq_len = config.seq_len\n",
    "        \n",
    "        # Process each package's results\n",
    "        for (pkg_name, results) in dict\n",
    "            if pkg_name != \"config\"\n",
    "                push!(packages, pkg_name)\n",
    "                push!(times, results.time)\n",
    "                push!(memories, results.memory)\n",
    "                push!(allocs, results.allocs)\n",
    "                push!(successes, results.success)\n",
    "                push!(latent_dims, latent_dim)\n",
    "                push!(obs_dims, obs_dim)\n",
    "                push!(seq_lens, seq_len)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    DataFrame(\n",
    "        package = packages,\n",
    "        time = times,\n",
    "        memory = memories,\n",
    "        allocs = allocs,\n",
    "        success = successes,\n",
    "        latent_dim = latent_dims,\n",
    "        obs_dim = obs_dims,\n",
    "        seq_length = seq_lens\n",
    "    )\n",
    "end\n",
    "\n",
    "function plot_benchmarks(df::DataFrame)\n",
    "    # Create a unique identifier for each obs_dim/latent_dim combination\n",
    "    df.dim_combo = string.(df.obs_dim, \"x\", df.latent_dim)\n",
    "    \n",
    "    # Define line styles that will cycle if we have more combinations than styles\n",
    "    base_styles = [:solid, :dash, :dot, :dashdot, :dashdotdot]\n",
    "    dim_combos = unique(df.dim_combo)\n",
    "    \n",
    "    # Create style dictionary by cycling through available styles\n",
    "    style_dict = Dict(\n",
    "        combo => base_styles[mod1(i, length(base_styles))] \n",
    "        for (i, combo) in enumerate(dim_combos)\n",
    "    )\n",
    "    \n",
    "    # Create the plot\n",
    "    p = plot(\n",
    "        xlabel=\"Sequence Length\",\n",
    "        ylabel=\"Time (seconds)\",\n",
    "        title=\"Package Performance Across Sequence Lengths\",\n",
    "        legend=:outertopright,\n",
    "        xscale=:log10,\n",
    "        yscale=:log10\n",
    "    )\n",
    "    \n",
    "    # Plot each package with a different color\n",
    "    packages = unique(df.package)\n",
    "    for (i, pkg) in enumerate(packages)\n",
    "        pkg_data = df[df.package .== pkg, :]\n",
    "        \n",
    "        # Plot each dimension combination for this package\n",
    "        for dim_combo in dim_combos\n",
    "            combo_data = pkg_data[pkg_data.dim_combo .== dim_combo, :]\n",
    "            if !isempty(combo_data)\n",
    "                plot!(\n",
    "                    p,\n",
    "                    combo_data.seq_length,\n",
    "                    combo_data.time ./ 1e9,  # Convert to seconds\n",
    "                    label=\"$(pkg) ($(dim_combo))\",\n",
    "                    color=i,\n",
    "                    linestyle=style_dict[dim_combo],\n",
    "                    marker=:circle,\n",
    "                    markersize=4\n",
    "                )\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Add gridlines and adjust layout\n",
    "    plot!(\n",
    "        p,\n",
    "        grid=true,\n",
    "        minorgrid=true,\n",
    "        size=(900, 600),\n",
    "        margin=10Plots.mm\n",
    "    )\n",
    "    \n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = transform_to_df(results)\n",
    "df.time = df.time / 1e9;\n",
    "\n",
    "CSV.write(\"benchmark_results_bernoulli.csv\", df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "benchmark_plot = plot_benchmarks(df)\n",
    "savefig(benchmark_plot, \"benchmark_bernoulli_plot.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
