{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b6c0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-482033.28522111394, -260982.53860078458)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Control dependency\n",
    "\n",
    "#=\n",
    "Here, we give a example of controlled HMM (also called input-output HMM), in the special case of Markov switching regression.\n",
    "=#\n",
    "\n",
    "using Distributions\n",
    "using HiddenMarkovModels\n",
    "import HiddenMarkovModels as HMMs\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using StableRNGs\n",
    "using StatsAPI\n",
    "\n",
    "#-\n",
    "\n",
    "rng = StableRNG(63);\n",
    "\n",
    "# ## Model\n",
    "\n",
    "#=\n",
    "A Markov switching regression is like a classical regression, except that the weights depend on the unobserved state of an HMM.\n",
    "We can represent it with the following subtype of `AbstractHMM` (see [Custom HMM structures](@ref)), which has one vector of coefficients $\\beta_i$ per state.\n",
    "=#\n",
    "\n",
    "struct ControlledGaussianHMM{T} <: AbstractHMM\n",
    "    init::Vector{T}\n",
    "    trans::Matrix{T}\n",
    "    dist_coeffs::Vector{Vector{T}}\n",
    "end\n",
    "\n",
    "#=\n",
    "In state $i$ with a vector of controls $u$, our observation is given by the linear model $y \\sim \\mathcal{N}(\\beta_i^\\top u, 1)$.\n",
    "Controls must be provided to both `transition_matrix` and `obs_distributions` even if they are only used by one.\n",
    "=#\n",
    "\n",
    "function HMMs.initialization(hmm::ControlledGaussianHMM)\n",
    "    return hmm.init\n",
    "end\n",
    "\n",
    "function HMMs.transition_matrix(hmm::ControlledGaussianHMM, control::AbstractVector)\n",
    "    return hmm.trans\n",
    "end\n",
    "\n",
    "function HMMs.obs_distributions(hmm::ControlledGaussianHMM, control::AbstractVector)\n",
    "    return [Normal(dot(hmm.dist_coeffs[i], control), 1.0) for i in 1:length(hmm)]\n",
    "end\n",
    "\n",
    "#=\n",
    "In this case, the transition matrix does not depend on the control.\n",
    "=#\n",
    "\n",
    "# ## Simulation\n",
    "\n",
    "d = 3\n",
    "init = [0.6, 0.4]\n",
    "trans = [0.7 0.3; 0.2 0.8]\n",
    "dist_coeffs = [-ones(d), ones(d)]\n",
    "hmm = ControlledGaussianHMM(init, trans, dist_coeffs);\n",
    "\n",
    "#=\n",
    "Simulation requires a vector of controls, each being a vector itself with the right dimension.\n",
    "\n",
    "Let us build several sequences of variable lengths.\n",
    "=#\n",
    "\n",
    "control_seqs = [[randn(rng, d) for t in 1:rand(100:200)] for k in 1:1000];\n",
    "obs_seqs = [rand(rng, hmm, control_seq).obs_seq for control_seq in control_seqs];\n",
    "\n",
    "obs_seq = reduce(vcat, obs_seqs)\n",
    "control_seq = reduce(vcat, control_seqs)\n",
    "seq_ends = cumsum(length.(obs_seqs));\n",
    "\n",
    "# ## Inference\n",
    "\n",
    "#=\n",
    "Not much changes from the case with simple time dependency.\n",
    "=#\n",
    "\n",
    "best_state_seq, _ = viterbi(hmm, obs_seq, control_seq; seq_ends)\n",
    "\n",
    "# ## Learning\n",
    "\n",
    "#=\n",
    "Once more, we override the `fit!` function.\n",
    "The state-related parameters are estimated in the standard way.\n",
    "Meanwhile, the observation coefficients are given by the formula for [weighted least squares](https://en.wikipedia.org/wiki/Weighted_least_squares).\n",
    "=#\n",
    "\n",
    "function StatsAPI.fit!(\n",
    "    hmm::ControlledGaussianHMM{T},\n",
    "    fb_storage::HMMs.ForwardBackwardStorage,\n",
    "    obs_seq::AbstractVector,\n",
    "    control_seq::AbstractVector;\n",
    "    seq_ends,\n",
    ") where {T}\n",
    "    (; γ, ξ) = fb_storage\n",
    "    N = length(hmm)\n",
    "\n",
    "    hmm.init .= 0\n",
    "    hmm.trans .= 0\n",
    "    for k in eachindex(seq_ends)\n",
    "        t1, t2 = HMMs.seq_limits(seq_ends, k)\n",
    "        hmm.init .+= γ[:, t1]\n",
    "        hmm.trans .+= sum(ξ[t1:t2])\n",
    "    end\n",
    "    hmm.init ./= sum(hmm.init)\n",
    "    for row in eachrow(hmm.trans)\n",
    "        row ./= sum(row)\n",
    "    end\n",
    "\n",
    "    U = reduce(hcat, control_seq)'\n",
    "    y = obs_seq\n",
    "    for i in 1:N\n",
    "        W = sqrt.(Diagonal(γ[i, :]))\n",
    "        hmm.dist_coeffs[i] = (W * U) \\ (W * y)\n",
    "    end\n",
    "end\n",
    "\n",
    "#=\n",
    "Now we put it to the test.\n",
    "=#\n",
    "\n",
    "init_guess = [0.5, 0.5]\n",
    "trans_guess = [0.6 0.4; 0.3 0.7]\n",
    "dist_coeffs_guess = [-2 * ones(d), 2 * ones(d)]\n",
    "hmm_guess = ControlledGaussianHMM(init_guess, trans_guess, dist_coeffs_guess);\n",
    "\n",
    "#-\n",
    "\n",
    "hmm_est, loglikelihood_evolution = baum_welch(hmm_guess, obs_seq, control_seq; seq_ends)\n",
    "first(loglikelihood_evolution), last(loglikelihood_evolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "533d7653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150110-element Vector{Vector{Float64}}:\n",
       " [-1.2724663276017179, -0.5425092089741408, -0.006775114305754266]\n",
       " [0.39899635102542447, 0.6879079099787647, -0.011462083229865102]\n",
       " [-0.3778445956351776, 1.02611610123778, -0.7521106533303417]\n",
       " [-0.05023471135145104, 1.1592855860576567, 1.600041146986573]\n",
       " [0.3024054684489508, 0.07762793399392462, -2.1032490660891834]\n",
       " [-0.4914103455484126, 1.5029814490027942, -0.48991872574893264]\n",
       " [0.1676976135048406, -0.6519291268812127, -0.03569567969966787]\n",
       " [-1.6538832667367795, -0.42886974189154153, -0.44106095881055]\n",
       " [-0.39234414283073954, 0.2287469842189177, 0.0930174991863142]\n",
       " [-0.34402635947107824, 0.5003837097671952, 0.7384034098094486]\n",
       " ⋮\n",
       " [-0.5190687943174294, -0.23376686824753887, 0.5361063482684831]\n",
       " [0.5518973819422871, 1.1883943478539016, 0.5546575013552255]\n",
       " [-1.0643243410902814, 0.22637917814975755, -0.05665553546986064]\n",
       " [-0.3313557353889336, -0.08741062427993526, -0.7741876282484813]\n",
       " [0.04135352660160016, -1.6520944862449851, 0.8570456393079647]\n",
       " [0.08386224566048776, 0.2858626016885098, -0.5695281857455085]\n",
       " [1.2146248065225267, 0.9323806280073154, 1.6714192718043779]\n",
       " [-0.40826419352594656, 0.9350989988762396, -0.22113898678875812]\n",
       " [-1.5367880103832425, 0.16121005909158861, -1.75228475846669]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "control_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40dfbfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Vector{Float64}}:\n",
       " [-2.0, -2.0, -2.0]\n",
       " [2.0, 2.0, 2.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_coeffs_guess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
