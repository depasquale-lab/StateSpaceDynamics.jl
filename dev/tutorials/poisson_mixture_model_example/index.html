<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Poisson Mixture Model Example · StateSpaceDynamics.jl</title><meta name="title" content="Poisson Mixture Model Example · StateSpaceDynamics.jl"/><meta property="og:title" content="Poisson Mixture Model Example · StateSpaceDynamics.jl"/><meta property="twitter:title" content="Poisson Mixture Model Example · StateSpaceDynamics.jl"/><meta name="description" content="Documentation for StateSpaceDynamics.jl."/><meta property="og:description" content="Documentation for StateSpaceDynamics.jl."/><meta property="twitter:description" content="Documentation for StateSpaceDynamics.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="StateSpaceDynamics.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">StateSpaceDynamics.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Models</span><ul><li><a class="tocitem" href="../../LinearDynamicalSystems/">Linear Dynamical Systems</a></li><li><a class="tocitem" href="../../HiddenMarkovModels/">Hidden Markov Models</a></li><li><a class="tocitem" href="../../SLDS/">Switching Linear Dynamical Systems</a></li><li><a class="tocitem" href="../../EmissionModels/">EmissionModels</a></li><li><a class="tocitem" href="../../MixtureModels/">Mixture Models</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../gaussian_latent_dynamics_example/">Gaussian LDS Example</a></li><li><a class="tocitem" href="../poisson_latent_dynamics_example/">Poisson LDS Example</a></li><li><a class="tocitem" href="../hidden_markov_model_example/">Hidden Markov Model Example</a></li><li><a class="tocitem" href="../gaussian_glm_hmm_example/">Gaussian GLM-GMM Example</a></li><li><a class="tocitem" href="../gaussian_mixture_model_example/">Gaussian Mixture Model Example</a></li><li class="is-active"><a class="tocitem" href>Poisson Mixture Model Example</a><ul class="internal"><li><a class="tocitem" href="#What-is-a-Poisson-Mixture-Model?"><span>What is a Poisson Mixture Model?</span></a></li><li><a class="tocitem" href="#EM-in-one-paragraph"><span>EM in one paragraph</span></a></li><li><a class="tocitem" href="#Create-a-true-PoissonMixtureModel-to-simulate-from"><span>Create a true PoissonMixtureModel to simulate from</span></a></li><li><a class="tocitem" href="#Generate-data-from-the-true-model"><span>Generate data from the true model</span></a></li><li><a class="tocitem" href="#Quick-look:-histogram-of-Poisson-samples-by-component"><span>Quick look: histogram of Poisson samples by component</span></a></li><li><a class="tocitem" href="#Fit-a-new-PoissonMixtureModel-to-the-data"><span>Fit a new PoissonMixtureModel to the data</span></a></li><li><a class="tocitem" href="#Convergence-diagnostics"><span>Convergence diagnostics</span></a></li><li><a class="tocitem" href="#Visual-model-check:-mixture-PMFs-vs-data"><span>Visual model check: mixture PMFs vs data</span></a></li><li><a class="tocitem" href="#Interpreting-the-fitted-parameters"><span>Interpreting the fitted parameters</span></a></li><li><a class="tocitem" href="#Posterior-responsibilities-(soft-clustering)"><span>Posterior responsibilities (soft clustering)</span></a></li><li><a class="tocitem" href="#Information-criteria:-picking-k"><span>Information criteria: picking k</span></a></li><li><a class="tocitem" href="#Practical-tips-and-pitfalls"><span>Practical tips &amp; pitfalls</span></a></li><li><a class="tocitem" href="#Next-steps-(ideas-for-exercises)"><span>Next steps (ideas for exercises)</span></a></li></ul></li><li><a class="tocitem" href="../Probabilistic_PCA_example/">Probabilistic PCA Example</a></li><li><a class="tocitem" href="../switching_linear_dynamical_system_example/">Switching Linear Dynamical System Example</a></li></ul></li><li><a class="tocitem" href="../../Misc/">Miscellaneous</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Poisson Mixture Model Example</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Poisson Mixture Model Example</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/depasquale-lab/StateSpaceDynamics.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/depasquale-lab/StateSpaceDynamics.jl/blob/main/docs/examples/PoissonMixtureModel.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Simulating-and-Fitting-a-Poisson-Mixture-Model"><a class="docs-heading-anchor" href="#Simulating-and-Fitting-a-Poisson-Mixture-Model">Simulating and Fitting a Poisson Mixture Model</a><a id="Simulating-and-Fitting-a-Poisson-Mixture-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-and-Fitting-a-Poisson-Mixture-Model" title="Permalink"></a></h1><p>This tutorial shows how to build and fit a <strong>Poisson Mixture Model (PMM)</strong> with <code>StateSpaceDynamics.jl</code> using the Expectation–Maximization (EM) algorithm. It starts from simulation, fits the model, and then walks through diagnostics, interpretation, and common extensions.</p><h2 id="What-is-a-Poisson-Mixture-Model?"><a class="docs-heading-anchor" href="#What-is-a-Poisson-Mixture-Model?">What is a Poisson Mixture Model?</a><a id="What-is-a-Poisson-Mixture-Model?-1"></a><a class="docs-heading-anchor-permalink" href="#What-is-a-Poisson-Mixture-Model?" title="Permalink"></a></h2><p>A PMM assumes each observation (x<em>i\in {0,1,2,\dots}) is drawn from one of (k) Poisson distributions, with means (rates) (\lambda</em>1,\dots,\lambda<em>k). The component is a latent categorical variable (z</em>i\in{1,\dots,k}) with mixing weights (\pi<em>1,\dots,\pi</em>k) ((\sum<em>j \pi</em>j = 1)). The generative process:</p><ol><li>Draw (z_i \sim \text{Categorical}(\pi))</li><li>Given (z<em>i=j), draw (x</em>i \sim \text{Poisson}(\lambda_j))</li></ol><p>PMMs are handy for <strong>count data</strong> that come from a few heterogeneous sub-populations (e.g., spike counts from cells with different firing rates, click counts from multiple user segments, etc.).</p><h2 id="EM-in-one-paragraph"><a class="docs-heading-anchor" href="#EM-in-one-paragraph">EM in one paragraph</a><a id="EM-in-one-paragraph-1"></a><a class="docs-heading-anchor-permalink" href="#EM-in-one-paragraph" title="Permalink"></a></h2><p>EM maximizes the marginal log-likelihood (\log p(x\,|\,\pi,\lambda)) by iterating:</p><ul><li><strong>E-step:</strong> compute responsibilities (\gamma<em>{ij} = p(z</em>i=j\,|\,x_i,\theta))</li><li><strong>M-step:</strong> update (\pi<em>j) and (\lambda</em>j) to maximize the expected complete-data log-likelihood.</li></ul><p>For Poisson mixtures, the closed-form M-step is: [ \pi<em>j \leftarrow \frac{1}{n} \sum</em>i \gamma<em>{ij}, \qquad \lambda</em>j \leftarrow \frac{\sum<em>i \gamma</em>{ij} x<em>i}{\sum</em>i \gamma_{ij}}. ] <code>fit!</code> in <code>StateSpaceDynamics.jl</code> performs these steps under the hood.</p><hr/><pre><code class="language-julia hljs">using StateSpaceDynamics
using LinearAlgebra
using Random
using Plots
using StableRNGs
using StatsPlots
using Distributions</code></pre><p>We fix the RNG for reproducibility of simulated data and k-means seeding.</p><pre><code class="language-julia hljs">rng = StableRNG(1234);</code></pre><h2 id="Create-a-true-PoissonMixtureModel-to-simulate-from"><a class="docs-heading-anchor" href="#Create-a-true-PoissonMixtureModel-to-simulate-from">Create a true PoissonMixtureModel to simulate from</a><a id="Create-a-true-PoissonMixtureModel-to-simulate-from-1"></a><a class="docs-heading-anchor-permalink" href="#Create-a-true-PoissonMixtureModel-to-simulate-from" title="Permalink"></a></h2><p>We&#39;ll simulate from a mixture of k=3 Poisson components with distinct means and mixing weights. Feel free to change these and observe how the fitted model behaves.</p><pre><code class="language-julia hljs">k = 3
true_λs = [5.0, 10.0, 25.0]   # Poisson means (rates) per component
true_πs = [0.25, 0.45, 0.30]  # Mixing weights (must sum to 1)

true_pmm = PoissonMixtureModel(k, true_λs, true_πs);</code></pre><h2 id="Generate-data-from-the-true-model"><a class="docs-heading-anchor" href="#Generate-data-from-the-true-model">Generate data from the true model</a><a id="Generate-data-from-the-true-model-1"></a><a class="docs-heading-anchor-permalink" href="#Generate-data-from-the-true-model" title="Permalink"></a></h2><p>We&#39;ll draw n IID samples. <code>labels</code> are the latent component indices used for simulation; in practice these are unknown and must be inferred.</p><pre><code class="language-julia hljs">n = 500
labels = rand(rng, Categorical(true_πs), n)
data   = [rand(rng, Poisson(true_λs[labels[i]])) for i in 1:n];  # Vector{Int}</code></pre><h2 id="Quick-look:-histogram-of-Poisson-samples-by-component"><a class="docs-heading-anchor" href="#Quick-look:-histogram-of-Poisson-samples-by-component">Quick look: histogram of Poisson samples by component</a><a id="Quick-look:-histogram-of-Poisson-samples-by-component-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-look:-histogram-of-Poisson-samples-by-component" title="Permalink"></a></h2><p>In real applications we don&#39;t see the true <code>labels</code>, but plotting them here helps build intuition: components with larger λ shift mass to larger counts.</p><pre><code class="language-julia hljs">p1 = histogram(
    data;
    group=labels,
    bins=0:1:maximum(data),
    bar_position=:dodge,
    xlabel=&quot;Count&quot;,
    ylabel=&quot;Frequency&quot;,
    title=&quot;Poisson Mixture Samples by Component&quot;,
    alpha=0.7,
    legend=:topright,
)
p1</code></pre><img src="ca7cb28e.svg" alt="Example block output"/><h2 id="Fit-a-new-PoissonMixtureModel-to-the-data"><a class="docs-heading-anchor" href="#Fit-a-new-PoissonMixtureModel-to-the-data">Fit a new PoissonMixtureModel to the data</a><a id="Fit-a-new-PoissonMixtureModel-to-the-data-1"></a><a class="docs-heading-anchor-permalink" href="#Fit-a-new-PoissonMixtureModel-to-the-data" title="Permalink"></a></h2><p>We construct an empty model with k components and call <code>fit!</code>. Options:</p><ul><li><code>maxiter</code>: EM iterations cap</li><li><code>tol</code>: stop if relative improvement in log-likelihood is smaller than this</li><li><code>initialize_kmeans=true</code>: seed with k-means on the 1D counts for more stable starts</li></ul><p>Note: EM is sensitive to initialization; try toggling <code>initialize_kmeans</code> or running from multiple random starts when you care about global optima.</p><pre><code class="language-julia hljs">fit_pmm = PoissonMixtureModel(k)
_, lls = fit!(fit_pmm, data; maxiter=100, tol=1e-6, initialize_kmeans=true);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Iteration 1: Log-likelihood = -1710.2956383796247
Iteration 2: Log-likelihood = -1707.5801809496086
Iteration 3: Log-likelihood = -1706.3657655884006
Iteration 4: Log-likelihood = -1705.7718351759063
Iteration 5: Log-likelihood = -1705.459104196352
Iteration 6: Log-likelihood = -1705.2786215730473
Iteration 7: Log-likelihood = -1705.1623777330624
Iteration 8: Log-likelihood = -1705.0780650642696
Iteration 9: Log-likelihood = -1705.009671514942
Iteration 10: Log-likelihood = -1704.9489102566108
Iteration 11: Log-likelihood = -1704.8912955699536
Iteration 12: Log-likelihood = -1704.834273535983
Iteration 13: Log-likelihood = -1704.7762955243295
Iteration 14: Log-likelihood = -1704.7163410077158
Iteration 15: Log-likelihood = -1704.6536622760675
Iteration 16: Log-likelihood = -1704.5876420954983
Iteration 17: Log-likelihood = -1704.517710091527
Iteration 18: Log-likelihood = -1704.4432898376692
Iteration 19: Log-likelihood = -1704.3637615747296
Iteration 20: Log-likelihood = -1704.2784320295616
Iteration 21: Log-likelihood = -1704.1865061335777
Iteration 22: Log-likelihood = -1704.0870570856332
Iteration 23: Log-likelihood = -1703.9789919084806
Iteration 24: Log-likelihood = -1703.8610097777264
Iteration 25: Log-likelihood = -1703.7315501281987
Iteration 26: Log-likelihood = -1703.5887269333255
Iteration 27: Log-likelihood = -1703.4302446207796
Iteration 28: Log-likelihood = -1703.2532898251027
Iteration 29: Log-likelihood = -1703.0543915946514
Iteration 30: Log-likelihood = -1702.8292408645536
Iteration 31: Log-likelihood = -1702.5724582997739
Iteration 32: Log-likelihood = -1702.277298822526
Iteration 33: Log-likelihood = -1701.935283114318
Iteration 34: Log-likelihood = -1701.5357549724574
Iteration 35: Log-likelihood = -1701.0653860612795
Iteration 36: Log-likelihood = -1700.5076995913969
Iteration 37: Log-likelihood = -1699.8427823778632
Iteration 38: Log-likelihood = -1699.0475244674017
Iteration 39: Log-likelihood = -1698.0969717463777
Iteration 40: Log-likelihood = -1696.967620663258
Iteration 41: Log-likelihood = -1695.643444425955
Iteration 42: Log-likelihood = -1694.124555161875
Iteration 43: Log-likelihood = -1692.4361538609414
Iteration 44: Log-likelihood = -1690.6324809401692
Iteration 45: Log-likelihood = -1688.7899636409954
Iteration 46: Log-likelihood = -1686.989196694715
Iteration 47: Log-likelihood = -1685.2944098782884
Iteration 48: Log-likelihood = -1683.7421273432585
Iteration 49: Log-likelihood = -1682.3431291202949
Iteration 50: Log-likelihood = -1681.092095859406
Iteration 51: Log-likelihood = -1679.9771128636512
Iteration 52: Log-likelihood = -1678.9853009078674
Iteration 53: Log-likelihood = -1678.1049011253963
Iteration 54: Log-likelihood = -1677.3254938350967
Iteration 55: Log-likelihood = -1676.6376505373273
Iteration 56: Log-likelihood = -1676.0326105591396
Iteration 57: Log-likelihood = -1675.502121351898
Iteration 58: Log-likelihood = -1675.038404323978
Iteration 59: Log-likelihood = -1674.6341788559612
Iteration 60: Log-likelihood = -1674.282697492575
Iteration 61: Log-likelihood = -1673.977769883428
Iteration 62: Log-likelihood = -1673.7137690441543
Iteration 63: Log-likelihood = -1673.485621191847
Iteration 64: Log-likelihood = -1673.2887830192406
Iteration 65: Log-likelihood = -1673.1192104861605
Iteration 66: Log-likelihood = -1672.9733225583966
Iteration 67: Log-likelihood = -1672.8479625127193
Iteration 68: Log-likelihood = -1672.7403587064218
Iteration 69: Log-likelihood = -1672.6480861384866
Iteration 70: Log-likelihood = -1672.569029694989
Iteration 71: Log-likelihood = -1672.5013496471622
Iteration 72: Log-likelihood = -1672.4434497299467
Iteration 73: Log-likelihood = -1672.3939479526052
Iteration 74: Log-likelihood = -1672.351650165266
Iteration 75: Log-likelihood = -1672.3155263155663
Iteration 76: Log-likelihood = -1672.2846892690638
Iteration 77: Log-likelihood = -1672.2583760280972
Iteration 78: Log-likelihood = -1672.2359311627567
Iteration 79: Log-likelihood = -1672.2167922577764
Iteration 80: Log-likelihood = -1672.20047717932
Iteration 81: Log-likelihood = -1672.1865729712397
Iteration 82: Log-likelihood = -1672.1747262006784
Iteration 83: Log-likelihood = -1672.1646345852123
Iteration 84: Log-likelihood = -1672.1560397477647
Iteration 85: Log-likelihood = -1672.1487209597158
Iteration 86: Log-likelihood = -1672.1424897467255
Iteration 87: Log-likelihood = -1672.1371852454085
Iteration 88: Log-likelihood = -1672.1326702118563
Iteration 89: Log-likelihood = -1672.1288275943043
Iteration 90: Log-likelihood = -1672.1255575935368
Iteration 91: Log-likelihood = -1672.1227751438037
Iteration 92: Log-likelihood = -1672.120407755957
Iteration 93: Log-likelihood = -1672.1183936720543
Iteration 94: Log-likelihood = -1672.1166802874404
Iteration 95: Log-likelihood = -1672.1152228023425
Iteration 96: Log-likelihood = -1672.113983070198
Iteration 97: Log-likelihood = -1672.1129286144644
Iteration 98: Log-likelihood = -1672.1120317895666
Iteration 99: Log-likelihood = -1672.1112690651892
Iteration 100: Log-likelihood = -1672.1106204158698</code></pre><h2 id="Convergence-diagnostics"><a class="docs-heading-anchor" href="#Convergence-diagnostics">Convergence diagnostics</a><a id="Convergence-diagnostics-1"></a><a class="docs-heading-anchor-permalink" href="#Convergence-diagnostics" title="Permalink"></a></h2><p>EM guarantees non-decreasing log-likelihood. Monotone ascent is a good basic check.</p><pre><code class="language-julia hljs">p2 = plot(
    lls;
    xlabel=&quot;Iteration&quot;,
    ylabel=&quot;Log-Likelihood&quot;,
    title=&quot;EM Convergence (Poisson Mixture)&quot;,
    marker=:circle,
    label=&quot;log_likelihood&quot;,
)
p2</code></pre><img src="764d5d06.svg" alt="Example block output"/><h2 id="Visual-model-check:-mixture-PMFs-vs-data"><a class="docs-heading-anchor" href="#Visual-model-check:-mixture-PMFs-vs-data">Visual model check: mixture PMFs vs data</a><a id="Visual-model-check:-mixture-PMFs-vs-data-1"></a><a class="docs-heading-anchor-permalink" href="#Visual-model-check:-mixture-PMFs-vs-data" title="Permalink"></a></h2><p>Overlay the fitted component probability mass functions (PMFs) and the overall mixture PMF on the normalized histogram. Components should plausibly explain the major modes and tail behavior in the data.</p><pre><code class="language-julia hljs">p3 = histogram(
    data;
    bins=0:1:maximum(data),
    normalize=true,
    alpha=0.3,
    label=&quot;Data&quot;,
    xlabel=&quot;Count&quot;,
    ylabel=&quot;Density&quot;,
    title=&quot;Poisson Mixtures: Data and PMFs&quot;,
)

x = collect(0:maximum(data))
colors = [:red, :green, :blue]

for i in 1:k
    λi = fit_pmm.λₖ[i]
    πi = fit_pmm.πₖ[i]
    pmf_i = πi .* pdf.(Poisson(λi), x)
    plot!(
        p3, x, pmf_i;
        lw=2,
        c=colors[i],
        label=&quot;Comp $i (λ=$(round(λi, sigdigits=3)))&quot;,
    )
end

mix_pmf = reduce(+, (πi .* pdf.(Poisson(λi), x) for (λi, πi) in zip(fit_pmm.λₖ, fit_pmm.πₖ)))
plot!(
    p3, x, mix_pmf;
    lw=3, ls=:dash, c=:black,
    label=&quot;Mixture&quot;,
)

p3</code></pre><img src="499726a1.svg" alt="Example block output"/><h2 id="Interpreting-the-fitted-parameters"><a class="docs-heading-anchor" href="#Interpreting-the-fitted-parameters">Interpreting the fitted parameters</a><a id="Interpreting-the-fitted-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Interpreting-the-fitted-parameters" title="Permalink"></a></h2><ul><li><code>fit_pmm.λₖ</code> are the estimated Poisson rates per component.</li><li><code>fit_pmm.πₖ</code> are the estimated mixing weights (sum to 1).</li></ul><p>Larger λ means the component puts more mass on larger counts. If two λs are close, EM may swap their order from run to run (label switching); the mixture distribution is unchanged.</p><h2 id="Posterior-responsibilities-(soft-clustering)"><a class="docs-heading-anchor" href="#Posterior-responsibilities-(soft-clustering)">Posterior responsibilities (soft clustering)</a><a id="Posterior-responsibilities-(soft-clustering)-1"></a><a class="docs-heading-anchor-permalink" href="#Posterior-responsibilities-(soft-clustering)" title="Permalink"></a></h2><p>Responsibilities (\gamma<em>{ij}=p(z</em>i=j\,|\,x_i,\hat\theta)) quantify how likely each point belongs to each component. These are useful for soft assignments, uncertainty-aware summaries, and inspecting ambiguous points.</p><pre><code class="language-julia hljs">function responsibilities_pmm(λs::AbstractVector, πs::AbstractVector, x::AbstractVector)
    k = length(λs)
    n = length(x)
    Γ = zeros(n, k)
    for i in 1:n
        for j in 1:k
            Γ[i, j] = πs[j] * pdf(Poisson(λs[j]), x[i])
        end
        s = sum(Γ[i, :])
        Γ[i, :] ./= s &gt; 0 ? s : 1.0
    end
    return Γ
end

Γ = responsibilities_pmm(fit_pmm.λₖ, fit_pmm.πₖ, data);</code></pre><p>Hard labels (if you need them) are argmax over responsibilities.</p><pre><code class="language-julia hljs">hard_labels = map(i -&gt; argmax(view(Γ, i, :)), 1:n);</code></pre><h2 id="Information-criteria:-picking-k"><a class="docs-heading-anchor" href="#Information-criteria:-picking-k">Information criteria: picking k</a><a id="Information-criteria:-picking-k-1"></a><a class="docs-heading-anchor-permalink" href="#Information-criteria:-picking-k" title="Permalink"></a></h2><p>If you don&#39;t know k, you can fit several models and compare AIC/BIC:   AIC = 2p - 2LL,   BIC = p*log(n) - 2LL with parameter count p = (k-1) mixing weights + k rates = 2k-1.</p><pre><code class="language-julia hljs">function aic_bic(lls::AbstractVector, n::Int, k::Int)
    ll = last(lls)
    p = 2k - 1
    return (AIC = 2p - 2ll, BIC = p*log(n) - 2ll)
end

(ic_aic, ic_bic) = aic_bic(lls, n, k), aic_bic(lls, n, k)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((AIC = 3354.2212408317396, BIC = 3375.2942813238506), (AIC = 3354.2212408317396, BIC = 3375.2942813238506))</code></pre><p>(In practice, compute these for multiple k and choose the one with the smallest AIC/BIC, balancing parsimony and fit.)</p><h2 id="Practical-tips-and-pitfalls"><a class="docs-heading-anchor" href="#Practical-tips-and-pitfalls">Practical tips &amp; pitfalls</a><a id="Practical-tips-and-pitfalls-1"></a><a class="docs-heading-anchor-permalink" href="#Practical-tips-and-pitfalls" title="Permalink"></a></h2><ul><li><strong>Initialization matters.</strong> Try multiple random starts or k-means seeding.</li><li><strong>Label switching.</strong> Component indices are arbitrary; sort components by λ for stable presentation if needed.</li><li><strong>Small/empty components.</strong> If some π_j \approx 0, consider reducing k or adding a tiny ridge prior on λ to avoid degenerate updates.</li><li><strong>Zero-inflation / overdispersion.</strong> If data have excess zeros or variance &gt;&gt; mean, consider a Negative Binomial mixture or a zero-inflated Poisson.</li><li><strong>Train/validation split.</strong> Use held-out likelihood or posterior predictive checks for model assessment beyond AIC/BIC.</li></ul><h2 id="Next-steps-(ideas-for-exercises)"><a class="docs-heading-anchor" href="#Next-steps-(ideas-for-exercises)">Next steps (ideas for exercises)</a><a id="Next-steps-(ideas-for-exercises)-1"></a><a class="docs-heading-anchor-permalink" href="#Next-steps-(ideas-for-exercises)" title="Permalink"></a></h2><ol><li><strong>Unknown k:</strong> loop over k=1:6, fit each, compare AIC/BIC.</li><li><strong>Stress test:</strong> change true λs to be closer (e.g., [10, 12, 14]) and see how EM behaves and how responsibilities reflect ambiguity.</li><li><strong>Posterior predictive check:</strong> simulate new data from the fitted mixture and compare histograms / tail behavior.</li><li><strong>Zero-inflation:</strong> inject extra zeros and try a more flexible mixture class.</li></ol><hr/><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gaussian_mixture_model_example/">« Gaussian Mixture Model Example</a><a class="docs-footer-nextpage" href="../Probabilistic_PCA_example/">Probabilistic PCA Example »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 9 September 2025 14:58">Tuesday 9 September 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
