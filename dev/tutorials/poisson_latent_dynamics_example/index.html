<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Poisson LDS Example · StateSpaceDynamics.jl</title><meta name="title" content="Poisson LDS Example · StateSpaceDynamics.jl"/><meta property="og:title" content="Poisson LDS Example · StateSpaceDynamics.jl"/><meta property="twitter:title" content="Poisson LDS Example · StateSpaceDynamics.jl"/><meta name="description" content="Documentation for StateSpaceDynamics.jl."/><meta property="og:description" content="Documentation for StateSpaceDynamics.jl."/><meta property="twitter:description" content="Documentation for StateSpaceDynamics.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="StateSpaceDynamics.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">StateSpaceDynamics.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Models</span><ul><li><a class="tocitem" href="../../LinearDynamicalSystems/">Linear Dynamical Systems</a></li><li><a class="tocitem" href="../../HiddenMarkovModels/">Hidden Markov Models</a></li><li><a class="tocitem" href="../../SLDS/">Switching Linear Dynamical Systems</a></li><li><a class="tocitem" href="../../EmissionModels/">EmissionModels</a></li><li><a class="tocitem" href="../../MixtureModels/">Mixture Models</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../gaussian_latent_dynamics_example/">Gaussian LDS Example</a></li><li class="is-active"><a class="tocitem" href>Poisson LDS Example</a><ul class="internal"><li><a class="tocitem" href="#Load-Required-Packages"><span>Load Required Packages</span></a></li><li><a class="tocitem" href="#Create-a-Poisson-Linear-Dynamical-System"><span>Create a Poisson Linear Dynamical System</span></a></li><li><a class="tocitem" href="#Simulate-Latent-States-and-Observations"><span>Simulate Latent States and Observations</span></a></li><li><a class="tocitem" href="#Plot-Vector-Field-of-Latent-Dynamics"><span>Plot Vector Field of Latent Dynamics</span></a></li><li><a class="tocitem" href="#Plot-Latent-States-and-Observations"><span>Plot Latent States and Observations</span></a></li><li><a class="tocitem" href="#Initialize-Model-and-Perform-Initial-Smoothing"><span>Initialize Model and Perform Initial Smoothing</span></a></li><li><a class="tocitem" href="#Fit-the-Poisson-LDS-Using-Laplace-EM"><span>Fit the Poisson LDS Using Laplace-EM</span></a></li><li><a class="tocitem" href="#Monitor-ELBO-Convergence"><span>Monitor ELBO Convergence</span></a></li><li><a class="tocitem" href="#Model-Comparison-and-Validation"><span>Model Comparison and Validation</span></a></li><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li></ul></li><li><a class="tocitem" href="../hidden_markov_model_example/">Hidden Markov Model Example</a></li><li><a class="tocitem" href="../gaussian_glm_hmm_example/">Gaussian GLM-GMM Example</a></li><li><a class="tocitem" href="../gaussian_mixture_model_example/">Gaussian Mixture Model Example</a></li><li><a class="tocitem" href="../poisson_mixture_model_example/">Poisson Mixture Model Example</a></li><li><a class="tocitem" href="../Probabilistic_PCA_example/">Probabilistic PCA Example</a></li><li><a class="tocitem" href="../switching_linear_dynamical_system_example/">Switching Linear Dynamical System Example</a></li></ul></li><li><a class="tocitem" href="../../Misc/">Miscellaneous</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Poisson LDS Example</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Poisson LDS Example</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/depasquale-lab/StateSpaceDynamics.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/depasquale-lab/StateSpaceDynamics.jl/blob/main/docs/examples/PoissonLDS.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Simulating-and-Fitting-a-Poisson-Linear-Dynamical-System"><a class="docs-heading-anchor" href="#Simulating-and-Fitting-a-Poisson-Linear-Dynamical-System">Simulating and Fitting a Poisson Linear Dynamical System</a><a id="Simulating-and-Fitting-a-Poisson-Linear-Dynamical-System-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-and-Fitting-a-Poisson-Linear-Dynamical-System" title="Permalink"></a></h1><p>This tutorial demonstrates how to use <code>StateSpaceDynamics.jl</code> to simulate and fit a Linear Dynamical System (LDS) with Poisson observations using the Laplace-EM algorithm. Unlike the standard Gaussian LDS, this model is designed for count data (e.g., neural spike counts, customer arrivals, or any discrete event data) where observations are non-negative integers that follow Poisson distributions.</p><h2 id="Load-Required-Packages"><a class="docs-heading-anchor" href="#Load-Required-Packages">Load Required Packages</a><a id="Load-Required-Packages-1"></a><a class="docs-heading-anchor-permalink" href="#Load-Required-Packages" title="Permalink"></a></h2><p>We begin by loading the necessary packages. The core difference from the Gaussian case is that we&#39;ll be working with Poisson observation models, which require more sophisticated inference algorithms (Laplace approximations) due to the non-conjugate nature of Poisson likelihoods with Gaussian latent states.</p><pre><code class="language-julia hljs">using StateSpaceDynamics
using LinearAlgebra
using Random
using Plots
using LaTeXStrings
using StableRNGs</code></pre><p>Set up reproducible random number generation</p><pre><code class="language-julia hljs">rng = StableRNG(123);</code></pre><h2 id="Create-a-Poisson-Linear-Dynamical-System"><a class="docs-heading-anchor" href="#Create-a-Poisson-Linear-Dynamical-System">Create a Poisson Linear Dynamical System</a><a id="Create-a-Poisson-Linear-Dynamical-System-1"></a><a class="docs-heading-anchor-permalink" href="#Create-a-Poisson-Linear-Dynamical-System" title="Permalink"></a></h2><p>We define a system where continuous latent dynamics generate discrete count observations. This is particularly relevant in neuroscience (modeling neural spike trains) and other domains where we observe discrete events generated by underlying continuous processes.</p><pre><code class="language-julia hljs">obs_dim = 10      # Number of observed count variables (e.g., neurons)
latent_dim = 2    # Number of latent state dimensions</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2</code></pre><p>Define the latent dynamics: same spiral structure as the Gaussian case The latent states evolve smoothly and continuously according to linear dynamics</p><pre><code class="language-julia hljs">A = 0.95 * [cos(0.25) -sin(0.25); sin(0.25) cos(0.25)]  # Rotation with contraction
Q = Matrix(0.1 * I(latent_dim))     # Process noise covariance
x0 = zeros(latent_dim)              # Initial state mean
P0 = Matrix(0.1 * I(latent_dim))    # Initial state covariance</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 Matrix{Float64}:
 0.1  0.0
 0.0  0.1</code></pre><p>Poisson observation model parameters: For Poisson observations, the rate parameter λ is typically modeled as: log(λ<em>i) = C</em>i^T * x<em>t + log</em>d<em>i where C maps latent states to log-rates and log</em>d provides baseline log-rates</p><pre><code class="language-julia hljs">log_d = log.(fill(0.1, obs_dim))    # Log baseline rates (small positive rates)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">10-element Vector{Float64}:
 -2.3025850929940455
 -2.3025850929940455
 -2.3025850929940455
 -2.3025850929940455
 -2.3025850929940455
 -2.3025850929940455
 -2.3025850929940455
 -2.3025850929940455
 -2.3025850929940455
 -2.3025850929940455</code></pre><p>Observation matrix C: maps 2D latent states to log-rates for each observed dimension We use positive values to ensure that latent activity increases firing rates</p><pre><code class="language-julia hljs">C = permutedims([abs.(randn(rng, obs_dim))&#39;; abs.(randn(rng, obs_dim))&#39;])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">10×2 Matrix{Float64}:
 0.126838   0.999572
 0.666885   1.49198
 1.25661    1.31032
 0.0849956  0.956236
 0.094274   2.04466
 0.977885   1.63446
 0.670663   0.61053
 0.71474    0.547159
 0.967198   0.32746
 1.36419    0.506752</code></pre><p>Construct the model components</p><pre><code class="language-julia hljs">state_model = GaussianStateModel(; A, Q, x0, P0)          # Gaussian latent dynamics
obs_model = PoissonObservationModel(; C, log_d)           # Poisson observations</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">PoissonObservationModel{Float64, Matrix{Float64}, Vector{Float64}}([0.12683768965424458 0.9995722599695167; 0.6668851724871252 1.4919831226368483; … ; 0.9671975288083468 0.3274601670258862; 1.3641880343579902 0.5067518363436612], [-2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455])</code></pre><p>Create the complete Poisson Linear Dynamical System</p><pre><code class="language-julia hljs">true_plds = LinearDynamicalSystem(;
    state_model=state_model,
    obs_model=obs_model,
    latent_dim=latent_dim,
    obs_dim=obs_dim,
    fit_bool=fill(true, 6)  # Learn all parameters: A, Q, C, log_d, x0, P0
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">LinearDynamicalSystem{Float64, GaussianStateModel{Float64, Matrix{Float64}, Vector{Float64}}, PoissonObservationModel{Float64, Matrix{Float64}, Vector{Float64}}}(GaussianStateModel{Float64, Matrix{Float64}, Vector{Float64}}([0.9204668006251124 -0.2350337612917968; 0.2350337612917968 0.9204668006251124], [0.1 0.0; 0.0 0.1], [0.0, 0.0], [0.1 0.0; 0.0 0.1]), PoissonObservationModel{Float64, Matrix{Float64}, Vector{Float64}}([0.12683768965424458 0.9995722599695167; 0.6668851724871252 1.4919831226368483; … ; 0.9671975288083468 0.3274601670258862; 1.3641880343579902 0.5067518363436612], [-2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455]), 2, 10, Bool[1, 1, 1, 1, 1, 1])</code></pre><h2 id="Simulate-Latent-States-and-Observations"><a class="docs-heading-anchor" href="#Simulate-Latent-States-and-Observations">Simulate Latent States and Observations</a><a id="Simulate-Latent-States-and-Observations-1"></a><a class="docs-heading-anchor-permalink" href="#Simulate-Latent-States-and-Observations" title="Permalink"></a></h2><p>Generate synthetic data from our Poisson LDS. The latent states evolve according to the linear dynamics, while observations are drawn from Poisson distributions whose rates depend on the current latent state.</p><pre><code class="language-julia hljs">tSteps = 500
println(&quot;Simulating $tSteps time steps of Poisson LDS data...&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Simulating 500 time steps of Poisson LDS data...</code></pre><p>Generate both latent trajectories and count observations</p><pre><code class="language-julia hljs">latents, observations = rand(rng, true_plds; tsteps=tSteps, ntrials=1)

println(&quot;Generated latent states with range: [$(minimum(latents)), $(maximum(latents))]&quot;)
println(&quot;Generated count observations with range: [$(minimum(observations)), $(maximum(observations))]&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Generated latent states with range: [-3.033528616816815, 2.274838111182266]
Generated count observations with range: [0.0, 210.0]</code></pre><h2 id="Plot-Vector-Field-of-Latent-Dynamics"><a class="docs-heading-anchor" href="#Plot-Vector-Field-of-Latent-Dynamics">Plot Vector Field of Latent Dynamics</a><a id="Plot-Vector-Field-of-Latent-Dynamics-1"></a><a class="docs-heading-anchor-permalink" href="#Plot-Vector-Field-of-Latent-Dynamics" title="Permalink"></a></h2><p>Visualize the underlying continuous dynamics that drive the discrete observations. This vector field shows how latent states evolve deterministically (ignoring noise).</p><p>Create a grid of starting points in latent space</p><pre><code class="language-julia hljs">x = y = -3:0.5:3
X = repeat(x&#39;, length(y), 1)
Y = repeat(y, 1, length(x))
U = zeros(size(X))  # Flow in x-direction
V = zeros(size(Y))  # Flow in y-direction</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">13×13 Matrix{Float64}:
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0</code></pre><p>Compute the deterministic flow at each grid point</p><pre><code class="language-julia hljs">for i in 1:size(X, 1), j in 1:size(X, 2)
    v = A * [X[i,j], Y[i,j]]
    U[i,j] = v[1] - X[i,j]
    V[i,j] = v[2] - Y[i,j]
end</code></pre><p>Normalize arrow lengths for cleaner visualization</p><pre><code class="language-julia hljs">magnitude = @. sqrt(U^2 + V^2)
U_norm = U ./ magnitude
V_norm = V ./ magnitude</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">13×13 Matrix{Float64}:
 -0.443144  -0.360164  -0.25873   -0.136921  …  0.792134  0.852648  0.89645
 -0.522485  -0.443144  -0.341437  -0.212492     0.84203   0.89645   0.932889
 -0.610347  -0.53943   -0.443144  -0.311913     0.89645   0.939904  0.96595
 -0.703886  -0.647334  -0.565468  -0.443144     0.950111  0.977163  0.990582
 -0.797265  -0.760443  -0.703886  -0.610347     0.990582  0.998531  0.99999
 -0.881652  -0.865979  -0.841213  -0.797265  …  0.996696  0.991704  0.987044
 -0.947236  -0.947236  -0.947236  -0.947236     0.947236  0.947236  0.947236
 -0.987044  -0.991704  -0.996696  -0.99999      0.841213  0.865979  0.881652
 -0.99999   -0.998531  -0.990582  -0.96595      0.703886  0.760443  0.797265
 -0.990582  -0.977163  -0.950111  -0.89645      0.565468  0.647334  0.703886
 -0.96595   -0.939904  -0.89645   -0.82477   …  0.443144  0.53943   0.610347
 -0.932889  -0.89645   -0.84203   -0.762206     0.341437  0.443144  0.522485
 -0.89645   -0.852648  -0.792134  -0.710313     0.25873   0.360164  0.443144</code></pre><p>Plot the vector field with the actual simulated trajectory</p><pre><code class="language-julia hljs">p = quiver(X, Y, quiver=(U_norm, V_norm), color=:blue, alpha=0.3,
           linewidth=1, arrow=arrow(:closed, :head, 0.1, 0.1))
plot!(latents[1, :, 1], latents[2, :, 1], xlabel=&quot;x₁&quot;, ylabel=&quot;x₂&quot;,
      color=:black, linewidth=1.5, title=&quot;Latent Dynamics&quot;, legend=false)</code></pre><img src="34d1dbe2.svg" alt="Example block output"/><h2 id="Plot-Latent-States-and-Observations"><a class="docs-heading-anchor" href="#Plot-Latent-States-and-Observations">Plot Latent States and Observations</a><a id="Plot-Latent-States-and-Observations-1"></a><a class="docs-heading-anchor-permalink" href="#Plot-Latent-States-and-Observations" title="Permalink"></a></h2><p>Create visualizations that highlight the key difference between continuous latent dynamics and discrete count observations. The latent states are smooth curves, while observations are spike trains (discrete events over time).</p><pre><code class="language-julia hljs">states = latents[:, :, 1]
emissions = observations[:, :, 1]
time_bins = size(states, 2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">500</code></pre><p>Two-panel layout: latent states above, spike rasters below</p><pre><code class="language-julia hljs">plot(size=(800, 600), layout=@layout[a{0.3h}; b])</code></pre><img src="a793167a.svg" alt="Example block output"/><p>Plot smooth latent state trajectories</p><pre><code class="language-julia hljs">lim_states = maximum(abs.(states))
for d in 1:latent_dim
    plot!(1:time_bins, states[d, :] .+ lim_states * (d-1), color=:black,
          linewidth=2, label=&quot;&quot;, subplot=1)
end

plot!(subplot=1, yticks=(lim_states .* (0:latent_dim-1), [L&quot;x_%$d&quot; for d in 1:latent_dim]),
      xticks=[], xlims=(0, time_bins), title=&quot;Simulated Latent States&quot;,
      yformatter=y-&gt;&quot;&quot;, tickfontsize=12)</code></pre><img src="832d43c9.svg" alt="Example block output"/><p>Plot discrete observations as spike rasters Each row represents one observed dimension, spikes shown as vertical lines</p><pre><code class="language-julia hljs">colors = palette(:default, obs_dim)
for f in 1:obs_dim
    spike_times = findall(x -&gt; x &gt; 0, emissions[f, :])
    for t in spike_times
        plot!([t, t], [f-0.4, f+0.4], color=colors[f], linewidth=1, label=&quot;&quot;, subplot=2)
    end
end

plot!(subplot=2, yticks=(1:obs_dim, [L&quot;y_{%$d}&quot; for d in 1:obs_dim]),
      xlims=(0, time_bins), ylims=(0.5, obs_dim + 0.5), title=&quot;Simulated Emissions (Spike Raster)&quot;,
      xlabel=&quot;Time&quot;, tickfontsize=12, grid=false)

println(&quot;Total spike count across all dimensions: $(sum(emissions))&quot;)
println(&quot;Average firing rate: $(sum(emissions)/(obs_dim * time_bins)) spikes per time bin&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Total spike count across all dimensions: 13165.0
Average firing rate: 2.633 spikes per time bin</code></pre><h2 id="Initialize-Model-and-Perform-Initial-Smoothing"><a class="docs-heading-anchor" href="#Initialize-Model-and-Perform-Initial-Smoothing">Initialize Model and Perform Initial Smoothing</a><a id="Initialize-Model-and-Perform-Initial-Smoothing-1"></a><a class="docs-heading-anchor-permalink" href="#Initialize-Model-and-Perform-Initial-Smoothing" title="Permalink"></a></h2><p>In practice, we only observe the spike counts, not the latent states. Our goal is to infer both the latent dynamics and the mapping from latent states to observed firing rates. We start with a randomly initialized model.</p><p>Random initialization (simulating lack of prior knowledge)</p><pre><code class="language-julia hljs">A_init = random_rotation_matrix(latent_dim, rng)  # Random rotation matrix
Q_init = Matrix(0.1 * I(latent_dim))              # Process noise guess
C_init = randn(rng, obs_dim, latent_dim)          # Random observation mapping
log_d_init = log.(fill(0.1, obs_dim))             # Baseline log-rate guess
x0_init = zeros(latent_dim)                       # Start from origin
P0_init = Matrix(0.1 * I(latent_dim))             # Initial uncertainty</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 Matrix{Float64}:
 0.1  0.0
 0.0  0.1</code></pre><p>Construct the naive model</p><pre><code class="language-julia hljs">sm_init = GaussianStateModel(; A=A_init, Q=Q_init, x0=x0_init, P0=P0_init)
om_init = PoissonObservationModel(; C=C_init, log_d=log_d_init)

naive_plds = LinearDynamicalSystem(;
    state_model=sm_init,
    obs_model=om_init,
    latent_dim=latent_dim,
    obs_dim=obs_dim,
    fit_bool=fill(true, 6)
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">LinearDynamicalSystem{Float64, GaussianStateModel{Float64, Matrix{Float64}, Vector{Float64}}, PoissonObservationModel{Float64, Matrix{Float64}, Vector{Float64}}}(GaussianStateModel{Float64, Matrix{Float64}, Vector{Float64}}([-0.09264983461435561 0.9956987537131562; 0.9956987537131562 0.09264983461435572], [0.1 0.0; 0.0 0.1], [0.0, 0.0], [0.1 0.0; 0.0 0.1]), PoissonObservationModel{Float64, Matrix{Float64}, Vector{Float64}}([0.44059884707879793 0.4314818885119216; 0.4643722013327123 -0.8139899895090875; … ; 0.451527437636677 -0.19454528045516728; -0.09089253911435208 -0.43470702242404774], [-2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455, -2.3025850929940455]), 2, 10, Bool[1, 1, 1, 1, 1, 1])</code></pre><p>Perform smoothing with the randomly initialized model For Poisson observations, this requires Laplace approximations since the posterior is no longer Gaussian (unlike the linear-Gaussian case)</p><pre><code class="language-julia hljs">println(&quot;Performing initial smoothing with random parameters...&quot;)
smoothed_x, smoothed_p = smooth(naive_plds, observations)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([0.08114847996324367 -0.11380999217009916 … -0.04999918928958035 0.037634678846875796; -0.03857767246002417 0.16041776430512963 … -0.07263066132400729 0.15303280156358376;;;], [0.0492303499217285 -0.005794804264743026; -0.005794804264743026 0.03466932594417146;;; 0.05512896912475814 -0.007973788272109364; -0.007973788272109364 0.04431703723454689;;; 0.055609179377352505 -0.01280997916290965; -0.01280997916290965 0.030705621661926218;;; … ;;; 0.06140722103832712 -0.012082442502287044; -0.012082442502287044 0.04044637620162031;;; 0.06429806965684398 -0.014034779048205426; -0.014034779048205426 0.043724155231262635;;; 0.09706857589728973 -0.0140939681674655; -0.0140939681674655 0.06461485263353083;;;;])</code></pre><p>Compare true vs. initial estimated latent states</p><pre><code class="language-julia hljs">plot()
for d in 1:latent_dim
    plot!(1:time_bins, states[d, :] .+ lim_states * (d-1), color=:black, linewidth=2, label=&quot;&quot;, subplot=1)
    plot!(1:time_bins, smoothed_x[d, :, 1] .+ lim_states * (d-1), color=:red, linewidth=2, label=&quot;&quot;, subplot=1)
end

plot!(subplot=1, yticks=(lim_states .* (0:latent_dim-1), [L&quot;x_%$d&quot; for d in 1:latent_dim]),
      xticks=[], xlims=(0, time_bins), title=&quot;True vs. Predicted Latent States (Pre-EM)&quot;,
      yformatter=y-&gt;&quot;&quot;, tickfontsize=12)</code></pre><img src="d3e0da95.svg" alt="Example block output"/><h2 id="Fit-the-Poisson-LDS-Using-Laplace-EM"><a class="docs-heading-anchor" href="#Fit-the-Poisson-LDS-Using-Laplace-EM">Fit the Poisson LDS Using Laplace-EM</a><a id="Fit-the-Poisson-LDS-Using-Laplace-EM-1"></a><a class="docs-heading-anchor-permalink" href="#Fit-the-Poisson-LDS-Using-Laplace-EM" title="Permalink"></a></h2><p>Now we use the Laplace-EM algorithm to learn the parameters. This is more complex than standard EM because:</p><ol><li>The E-step requires Laplace approximations to handle non-Gaussian posteriors</li><li>The M-step updates must account for the Poisson likelihood structure</li><li>Convergence can be slower due to the non-conjugate nature of the model</li></ol><pre><code class="language-julia hljs">println(&quot;Starting Laplace-EM algorithm...&quot;)
println(&quot;Note: Poisson LDS fitting is more computationally intensive than Gaussian LDS&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Starting Laplace-EM algorithm...
Note: Poisson LDS fitting is more computationally intensive than Gaussian LDS</code></pre><p>Fit the model - using fewer iterations than Gaussian case due to computational cost</p><pre><code class="language-julia hljs">elbo, _ = fit!(naive_plds, observations; max_iter=25, tol=1e-6)

println(&quot;Laplace-EM completed after $(length(elbo)) iterations&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Fitting Poisson LDS via LaPlaceEM...   8%|████                                              |  ETA: 0:00:14 ( 0.60  s/it)Fitting Poisson LDS via LaPlaceEM...  36%|██████████████████                                |  ETA: 0:00:02 ( 0.15  s/it)Fitting Poisson LDS via LaPlaceEM...  68%|██████████████████████████████████                |  ETA: 0:00:01 (83.22 ms/it)Fitting Poisson LDS via LaPlaceEM... 100%|██████████████████████████████████████████████████| Time: 0:00:01 (60.88 ms/it)
Laplace-EM completed after 25 iterations</code></pre><p>Perform smoothing with the learned parameters</p><pre><code class="language-julia hljs">smoothed_x, smoothed_p = smooth(naive_plds, observations)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([0.05768181965115013 0.028334001927526033 … -0.022400063051782458 0.057738051194020375; -0.013249368751427855 -0.005304614765685382 … -0.03924179951154954 0.04786076282081417;;;], [0.00665145593373845 -0.0017421515511116302; -0.0017421515511116302 0.002696970013056209;;; 0.12046645159765686 -0.03313747808194146; -0.03313747808194146 0.027800023443378508;;; 0.12965925972286 -0.03476722235462147; -0.03476722235462147 0.027657454959732878;;; … ;;; 0.1343803776584911 -0.033469493387854016; -0.033469493387854016 0.03016502187252205;;; 0.13236061246434452 -0.032638463816012195; -0.032638463816012195 0.0299251087215229;;; 0.15868328149406843 -0.03504831787547789; -0.03504831787547789 0.03255854020589664;;;;])</code></pre><p>Compare true vs. learned latent state estimates</p><pre><code class="language-julia hljs">plot()
for d in 1:latent_dim
    plot!(1:time_bins, states[d, :] .+ lim_states * (d-1), color=:black, linewidth=2, label=&quot;&quot;, subplot=1)
    plot!(1:time_bins, smoothed_x[d, :, 1] .+ lim_states * (d-1), color=:red, linewidth=2, label=&quot;&quot;, subplot=1)
end

plot!(subplot=1, yticks=(lim_states .* (0:latent_dim-1), [L&quot;x_%$d&quot; for d in 1:latent_dim]),
      xticks=[], xlims=(0, time_bins), title=&quot;True vs. Predicted Latent States (Post-EM)&quot;,
      yformatter=y-&gt;&quot;&quot;, tickfontsize=12)</code></pre><img src="127f5741.svg" alt="Example block output"/><h2 id="Monitor-ELBO-Convergence"><a class="docs-heading-anchor" href="#Monitor-ELBO-Convergence">Monitor ELBO Convergence</a><a id="Monitor-ELBO-Convergence-1"></a><a class="docs-heading-anchor-permalink" href="#Monitor-ELBO-Convergence" title="Permalink"></a></h2><p>The Evidence Lower BOund (ELBO) tracks the algorithm&#39;s progress. For Poisson LDS, the ELBO includes both the data likelihood and the Laplace approximation terms. Convergence may be less smooth than in the Gaussian case due to the approximations.</p><pre><code class="language-julia hljs">plot(elbo, xlabel=&quot;iteration&quot;, ylabel=&quot;ELBO&quot;, title=&quot;ELBO over Iterations&quot;, legend=false)

println(&quot;Initial ELBO: $(elbo[1])&quot;)
println(&quot;Final ELBO: $(elbo[end])&quot;)
println(&quot;ELBO improvement: $(elbo[end] - elbo[1])&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Initial ELBO: -723587.3321356231
Final ELBO: -9.48408821088163e6
ELBO improvement: -8.760500878746007e6</code></pre><h2 id="Model-Comparison-and-Validation"><a class="docs-heading-anchor" href="#Model-Comparison-and-Validation">Model Comparison and Validation</a><a id="Model-Comparison-and-Validation-1"></a><a class="docs-heading-anchor-permalink" href="#Model-Comparison-and-Validation" title="Permalink"></a></h2><p>Let&#39;s examine how well we recovered the true parameters</p><pre><code class="language-julia hljs">println(&quot;\n=== Parameter Recovery Assessment ===&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">
=== Parameter Recovery Assessment ===</code></pre><p>Compare true vs learned observation matrix C</p><pre><code class="language-julia hljs">C_error = norm(true_plds.obs_model.C - naive_plds.obs_model.C) / norm(true_plds.obs_model.C)
println(&quot;Relative error in observation matrix C: $(round(C_error, digits=3))&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Relative error in observation matrix C: 1.525</code></pre><p>Compare true vs learned dynamics matrix A</p><pre><code class="language-julia hljs">A_error = norm(true_plds.state_model.A - naive_plds.state_model.A) / norm(true_plds.state_model.A)
println(&quot;Relative error in dynamics matrix A: $(round(A_error, digits=3))&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Relative error in dynamics matrix A: 0.556</code></pre><p>Compare latent state trajectories</p><pre><code class="language-julia hljs">state_error = norm(states - smoothed_x[:,:,1]) / norm(states)
println(&quot;Relative error in latent state estimation: $(round(state_error, digits=3))&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Relative error in latent state estimation: 1.396</code></pre><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><p>This tutorial demonstrated fitting a Poisson Linear Dynamical System:</p><ol><li><strong>Model Structure</strong>: Continuous Gaussian latent dynamics generate discrete Poisson observations</li><li><strong>Applications</strong>: Ideal for count data like neural spikes, customer arrivals, or event sequences</li><li><strong>Algorithm</strong>: Laplace-EM handles the non-conjugate Poisson-Gaussian combination</li><li><strong>Challenges</strong>: More computationally intensive than Gaussian LDS due to required approximations</li><li><strong>Results</strong>: Successfully recovered both latent dynamics and observation parameters from spike data</li></ol><p>The Poisson LDS extends the linear dynamical system framework to discrete observation models, enabling state-space modeling of count data while maintaining interpretable latent dynamics.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gaussian_latent_dynamics_example/">« Gaussian LDS Example</a><a class="docs-footer-nextpage" href="../hidden_markov_model_example/">Hidden Markov Model Example »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 9 September 2025 14:38">Tuesday 9 September 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
