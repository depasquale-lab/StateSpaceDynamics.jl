<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Poisson LDS Example · StateSpaceDynamics.jl</title><meta name="title" content="Poisson LDS Example · StateSpaceDynamics.jl"/><meta property="og:title" content="Poisson LDS Example · StateSpaceDynamics.jl"/><meta property="twitter:title" content="Poisson LDS Example · StateSpaceDynamics.jl"/><meta name="description" content="Documentation for StateSpaceDynamics.jl."/><meta property="og:description" content="Documentation for StateSpaceDynamics.jl."/><meta property="twitter:description" content="Documentation for StateSpaceDynamics.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="StateSpaceDynamics.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">StateSpaceDynamics.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Models</span><ul><li><a class="tocitem" href="../../LinearDynamicalSystems/">Linear Dynamical Systems</a></li><li><a class="tocitem" href="../../HiddenMarkovModels/">Hidden Markov Models</a></li><li><a class="tocitem" href="../../SLDS/">Switching Linear Dynamical Systems</a></li><li><a class="tocitem" href="../../EmissionModels/">EmissionModels</a></li><li><a class="tocitem" href="../../MixtureModels/">Mixture Models</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../gaussian_latent_dynamics_example/">Gaussian LDS Example</a></li><li class="is-active"><a class="tocitem" href>Poisson LDS Example</a><ul class="internal"><li><a class="tocitem" href="#Load-Required-Packages"><span>Load Required Packages</span></a></li><li><a class="tocitem" href="#Create-a-Poisson-Linear-Dynamical-System"><span>Create a Poisson Linear Dynamical System</span></a></li><li><a class="tocitem" href="#Simulate-Latent-States-and-Count-Observations"><span>Simulate Latent States and Count Observations</span></a></li><li><a class="tocitem" href="#Visualize-Latent-Dynamics"><span>Visualize Latent Dynamics</span></a></li><li><a class="tocitem" href="#Visualize-Latent-States-and-Spike-Observations"><span>Visualize Latent States and Spike Observations</span></a></li><li><a class="tocitem" href="#Initialize-and-Fit-Poisson-LDS"><span>Initialize and Fit Poisson LDS</span></a></li><li><a class="tocitem" href="#Fit-Using-Laplace-EM-Algorithm"><span>Fit Using Laplace-EM Algorithm</span></a></li><li><a class="tocitem" href="#Monitor-ELBO-Convergence"><span>Monitor ELBO Convergence</span></a></li><li><a class="tocitem" href="#Parameter-Recovery-Assessment"><span>Parameter Recovery Assessment</span></a></li><li><a class="tocitem" href="#Computational-Complexity-Notes"><span>Computational Complexity Notes</span></a></li><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li></ul></li><li><a class="tocitem" href="../hidden_markov_model_example/">Hidden Markov Model Example</a></li><li><a class="tocitem" href="../gaussian_glm_hmm_example/">Gaussian GLM-GMM Example</a></li><li><a class="tocitem" href="../gaussian_mixture_model_example/">Gaussian Mixture Model Example</a></li><li><a class="tocitem" href="../poisson_mixture_model_example/">Poisson Mixture Model Example</a></li><li><a class="tocitem" href="../Probabilistic_PCA_example/">Probabilistic PCA Example</a></li><li><a class="tocitem" href="../switching_linear_dynamical_system_example/">Switching Linear Dynamical System Example</a></li></ul></li><li><a class="tocitem" href="../../Misc/">Miscellaneous</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Poisson LDS Example</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Poisson LDS Example</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/depasquale-lab/StateSpaceDynamics.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/depasquale-lab/StateSpaceDynamics.jl/blob/main/docs/examples/PoissonLDS.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Simulating-and-Fitting-a-Poisson-Linear-Dynamical-System"><a class="docs-heading-anchor" href="#Simulating-and-Fitting-a-Poisson-Linear-Dynamical-System">Simulating and Fitting a Poisson Linear Dynamical System</a><a id="Simulating-and-Fitting-a-Poisson-Linear-Dynamical-System-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-and-Fitting-a-Poisson-Linear-Dynamical-System" title="Permalink"></a></h1><p>This tutorial demonstrates how to use <code>StateSpaceDynamics.jl</code> to simulate and fit a Linear Dynamical System (LDS) with Poisson observations using the Laplace-EM algorithm. Unlike the standard Gaussian LDS, this model is designed for count data (e.g., neural spike counts, customer arrivals, or discrete event data) where observations are non-negative integers following Poisson distributions.</p><p>The key insight is that while latent dynamics remain continuous and Gaussian, the observations are discrete counts whose rates depend on the latent state through an exponential link function: <span>$\lambda_i(t) = \exp(\mathbf{C}_i^T \mathbf{x}_t + d_i)$</span>.</p><h2 id="Load-Required-Packages"><a class="docs-heading-anchor" href="#Load-Required-Packages">Load Required Packages</a><a id="Load-Required-Packages-1"></a><a class="docs-heading-anchor-permalink" href="#Load-Required-Packages" title="Permalink"></a></h2><pre><code class="language-julia hljs">using StateSpaceDynamics
using LinearAlgebra
using Random
using Plots
using LaTeXStrings
using StableRNGs</code></pre><p>Set up reproducible random number generation</p><pre><code class="language-julia hljs">rng = StableRNG(1234);</code></pre><h2 id="Create-a-Poisson-Linear-Dynamical-System"><a class="docs-heading-anchor" href="#Create-a-Poisson-Linear-Dynamical-System">Create a Poisson Linear Dynamical System</a><a id="Create-a-Poisson-Linear-Dynamical-System-1"></a><a class="docs-heading-anchor-permalink" href="#Create-a-Poisson-Linear-Dynamical-System" title="Permalink"></a></h2><p>We define a system where continuous latent dynamics generate discrete count observations. This is particularly relevant in neuroscience (neural spike trains) and other domains where discrete events are generated by underlying continuous processes.</p><pre><code class="language-julia hljs">obs_dim = 10       # Number of observed count variables (e.g., neurons)
latent_dim = 2;    # Number of latent state dimensions</code></pre><p>Define latent dynamics: same spiral structure as Gaussian LDS Latent states evolve smoothly according to linear dynamics</p><pre><code class="language-julia hljs">A = 0.95 * [cos(0.25) -sin(0.25); sin(0.25) cos(0.25)]  # Rotation with contraction
Q = Matrix(0.1 * I(latent_dim))     # Process noise covariance
x0 = zeros(latent_dim)              # Initial state mean
P0 = Matrix(0.1 * I(latent_dim));   # Initial state covariance</code></pre><p>Poisson observation model parameters: For Poisson observations, the rate parameter <span>$\lambda_i$</span> is modeled as: <span>$\log(\lambda_i) = \mathbf{C}_i^T \mathbf{x}_t + d_i$</span> where <span>$\mathbf{C}$</span> maps latent states to log-rates and <span>$d_i$</span> provides baseline log-rates</p><pre><code class="language-julia hljs">log_d = log.(fill(0.1, obs_dim));    # Log baseline rates (small positive rates)</code></pre><p>Observation matrix C: maps 2D latent states to log-rates for each observed dimension Use positive values so latent activity increases firing rates</p><pre><code class="language-julia hljs">C = permutedims([abs.(randn(rng, obs_dim))&#39;; abs.(randn(rng, obs_dim))&#39;]);</code></pre><p>Construct the model components</p><pre><code class="language-julia hljs">state_model = GaussianStateModel(; A, Q, x0, P0)          # Gaussian latent dynamics
obs_model = PoissonObservationModel(; C, log_d);           # Poisson observations</code></pre><p>Create the complete Poisson Linear Dynamical System</p><pre><code class="language-julia hljs">true_plds = LinearDynamicalSystem(;
    state_model=state_model,
    obs_model=obs_model,
    latent_dim=latent_dim,
    obs_dim=obs_dim,
    fit_bool=fill(true, 6)  # Learn all parameters: A, Q, C, log_d, x0, P0
);</code></pre><h2 id="Simulate-Latent-States-and-Count-Observations"><a class="docs-heading-anchor" href="#Simulate-Latent-States-and-Count-Observations">Simulate Latent States and Count Observations</a><a id="Simulate-Latent-States-and-Count-Observations-1"></a><a class="docs-heading-anchor-permalink" href="#Simulate-Latent-States-and-Count-Observations" title="Permalink"></a></h2><p>Generate synthetic data from our Poisson LDS. Latent states evolve according to linear dynamics, while observations are drawn from Poisson distributions whose rates depend exponentially on the current latent state.</p><p>Generate both latent trajectories and count observations</p><pre><code class="language-julia hljs">tSteps = 500
latents, observations = rand(rng, true_plds; tsteps=tSteps, ntrials=1);</code></pre><h2 id="Visualize-Latent-Dynamics"><a class="docs-heading-anchor" href="#Visualize-Latent-Dynamics">Visualize Latent Dynamics</a><a id="Visualize-Latent-Dynamics-1"></a><a class="docs-heading-anchor-permalink" href="#Visualize-Latent-Dynamics" title="Permalink"></a></h2><p>Show the underlying continuous dynamics that drive discrete observations. This vector field illustrates how latent states evolve deterministically (ignoring noise).</p><p>Create grid for vector field</p><pre><code class="language-julia hljs">x = y = -3:0.5:3
X = repeat(x&#39;, length(y), 1)
Y = repeat(y, 1, length(x))
U = zeros(size(X))  # Flow in x-direction
V = zeros(size(Y))  # Flow in y-direction

for i in 1:size(X, 1), j in 1:size(X, 2)
    v = A * [X[i,j], Y[i,j]]
    U[i,j] = v[1] - X[i,j]
    V[i,j] = v[2] - Y[i,j]
end

magnitude = @. sqrt(U^2 + V^2)  # Normalize arrow lengths for cleaner visualization
U_norm = U ./ magnitude
V_norm = V ./ magnitude</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">13×13 Matrix{Float64}:
 -0.443144  -0.360164  -0.25873   -0.136921  …  0.792134  0.852648  0.89645
 -0.522485  -0.443144  -0.341437  -0.212492     0.84203   0.89645   0.932889
 -0.610347  -0.53943   -0.443144  -0.311913     0.89645   0.939904  0.96595
 -0.703886  -0.647334  -0.565468  -0.443144     0.950111  0.977163  0.990582
 -0.797265  -0.760443  -0.703886  -0.610347     0.990582  0.998531  0.99999
 -0.881652  -0.865979  -0.841213  -0.797265  …  0.996696  0.991704  0.987044
 -0.947236  -0.947236  -0.947236  -0.947236     0.947236  0.947236  0.947236
 -0.987044  -0.991704  -0.996696  -0.99999      0.841213  0.865979  0.881652
 -0.99999   -0.998531  -0.990582  -0.96595      0.703886  0.760443  0.797265
 -0.990582  -0.977163  -0.950111  -0.89645      0.565468  0.647334  0.703886
 -0.96595   -0.939904  -0.89645   -0.82477   …  0.443144  0.53943   0.610347
 -0.932889  -0.89645   -0.84203   -0.762206     0.341437  0.443144  0.522485
 -0.89645   -0.852648  -0.792134  -0.710313     0.25873   0.360164  0.443144</code></pre><p>Plot vector field with simulated trajectory</p><pre><code class="language-julia hljs">p1 = quiver(X, Y, quiver=(U_norm, V_norm), color=:blue, alpha=0.3,
           linewidth=1, arrow=arrow(:closed, :head, 0.1, 0.1))
plot!(latents[1, :, 1], latents[2, :, 1], xlabel=L&quot;x_1&quot;, ylabel=L&quot;x_2&quot;,
      color=:black, linewidth=1.5, title=&quot;Latent Dynamics&quot;, legend=false)</code></pre><img src="2c8d44ed.svg" alt="Example block output"/><h2 id="Visualize-Latent-States-and-Spike-Observations"><a class="docs-heading-anchor" href="#Visualize-Latent-States-and-Spike-Observations">Visualize Latent States and Spike Observations</a><a id="Visualize-Latent-States-and-Spike-Observations-1"></a><a class="docs-heading-anchor-permalink" href="#Visualize-Latent-States-and-Spike-Observations" title="Permalink"></a></h2><p>Create visualizations highlighting the contrast between continuous latent dynamics and discrete count observations (spike trains).</p><pre><code class="language-julia hljs">states = latents[:, :, 1]
emissions = observations[:, :, 1]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">10×500 Matrix{Float64}:
 0.0  1.0  0.0  3.0  2.0   6.0   6.0  …   5.0   5.0  5.0  3.0  3.0  2.0  3.0
 2.0  0.0  1.0  3.0  4.0  17.0  26.0     21.0  16.0  8.0  6.0  9.0  1.0  1.0
 1.0  0.0  0.0  5.0  3.0  11.0   8.0      1.0   2.0  4.0  0.0  0.0  0.0  0.0
 1.0  1.0  0.0  1.0  7.0   4.0   4.0      1.0   6.0  1.0  1.0  0.0  0.0  0.0
 3.0  0.0  3.0  2.0  3.0   2.0   1.0      2.0   1.0  3.0  2.0  1.0  0.0  0.0
 2.0  0.0  1.0  1.0  3.0   2.0   7.0  …   4.0   3.0  4.0  1.0  0.0  1.0  1.0
 2.0  1.0  1.0  1.0  0.0   2.0   4.0      2.0   1.0  1.0  0.0  3.0  2.0  1.0
 1.0  1.0  1.0  0.0  1.0   2.0   0.0      4.0   4.0  1.0  4.0  2.0  0.0  2.0
 1.0  0.0  2.0  2.0  4.0   5.0   2.0      3.0   0.0  1.0  0.0  0.0  0.0  0.0
 1.0  0.0  2.0  3.0  4.0  10.0   7.0      3.0   2.0  3.0  0.0  1.0  0.0  0.0</code></pre><p>Two-panel layout: continuous latent states above, discrete spike rasters below</p><pre><code class="language-julia hljs">lim_states = maximum(abs.(states))

p2 = plot(size=(800, 600), layout=@layout[a{0.3h}; b])

for d in 1:latent_dim
    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,
          linewidth=2, label=&quot;&quot;, subplot=1) # Plot smooth latent state trajectories

end

plot!(subplot=1, yticks=(lim_states .* (0:latent_dim-1), [L&quot;x_%$d&quot; for d in 1:latent_dim]),
      xticks=[], xlims=(0, tSteps), title=&quot;Simulated Latent States&quot;,
      yformatter=y-&gt;&quot;&quot;, tickfontsize=12)</code></pre><img src="9fafc399.svg" alt="Example block output"/><p>Plot discrete observations as spike rasters Each row represents one observed dimension, spikes shown as vertical lines</p><pre><code class="language-julia hljs">colors = palette(:default, obs_dim)
for f in 1:obs_dim
    spike_times = findall(x -&gt; x &gt; 0, emissions[f, :])
    for t in spike_times
        plot!([t, t], [f-0.4, f+0.4], color=colors[f], linewidth=1, label=&quot;&quot;, subplot=2)
    end
end

plot!(subplot=2, yticks=(1:obs_dim, [L&quot;y_{%$d}&quot; for d in 1:obs_dim]),
      xlims=(0, tSteps), ylims=(0.5, obs_dim + 0.5), title=&quot;Spike Raster Plot&quot;,
      xlabel=&quot;Time&quot;, tickfontsize=12, grid=false)</code></pre><img src="0c25af7c.svg" alt="Example block output"/><h2 id="Initialize-and-Fit-Poisson-LDS"><a class="docs-heading-anchor" href="#Initialize-and-Fit-Poisson-LDS">Initialize and Fit Poisson LDS</a><a id="Initialize-and-Fit-Poisson-LDS-1"></a><a class="docs-heading-anchor-permalink" href="#Initialize-and-Fit-Poisson-LDS" title="Permalink"></a></h2><p>In practice, we only observe spike counts, not latent states. Our goal is to infer both latent dynamics and the mapping from latent states to firing rates. Start with randomly initialized model.</p><p>Random initialization (simulating lack of prior knowledge)</p><pre><code class="language-julia hljs">A_init = random_rotation_matrix(latent_dim, rng)  # Random rotation matrix
Q_init = Matrix(0.1 * I(latent_dim))              # Process noise guess
C_init = randn(rng, obs_dim, latent_dim)          # Random observation mapping
log_d_init = log.(fill(0.1, obs_dim))             # Baseline log-rate guess
x0_init = zeros(latent_dim)                       # Start from origin
P0_init = Matrix(0.1 * I(latent_dim))             # Initial uncertainty</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 Matrix{Float64}:
 0.1  0.0
 0.0  0.1</code></pre><p>Construct naive model</p><pre><code class="language-julia hljs">sm_init = GaussianStateModel(; A=A_init, Q=Q_init, x0=x0_init, P0=P0_init)
om_init = PoissonObservationModel(; C=C_init, log_d=log_d_init)

naive_plds = LinearDynamicalSystem(;
    state_model=sm_init,
    obs_model=om_init,
    latent_dim=latent_dim,
    obs_dim=obs_dim,
    fit_bool=fill(true, 6)
);</code></pre><p>Perform initial smoothing with random parameters</p><pre><code class="language-julia hljs">print(&quot;Initial smoothing with random parameters...&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Initial smoothing with random parameters...</code></pre><p>For Poisson observations, this requires Laplace approximations since the posterior is no longer Gaussian (unlike linear-Gaussian case)</p><pre><code class="language-julia hljs">smoothed_x_pre, smoothed_p_pre = smooth(naive_plds, observations);</code></pre><p>Compare true vs. initial estimated latent states</p><pre><code class="language-julia hljs">p3 = plot()
for d in 1:latent_dim
    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,
          linewidth=2, label=(d==1 ? &quot;True&quot; : &quot;&quot;), alpha=0.8)
    plot!(1:tSteps, smoothed_x_pre[d, :, 1] .+ lim_states * (d-1), color=:red,
          linewidth=2, label=(d==1 ? &quot;Initial Est.&quot; : &quot;&quot;), alpha=0.8)
end

plot!(yticks=(lim_states .* (0:latent_dim-1), [L&quot;x_%$d&quot; for d in 1:latent_dim]),
      xlabel=&quot;Time&quot;, xlims=(0, tSteps), title=&quot;Pre-EM: True vs. Initial Estimates&quot;,
      yformatter=y-&gt;&quot;&quot;, tickfontsize=12, legend=:topright)</code></pre><img src="299dfa63.svg" alt="Example block output"/><h2 id="Fit-Using-Laplace-EM-Algorithm"><a class="docs-heading-anchor" href="#Fit-Using-Laplace-EM-Algorithm">Fit Using Laplace-EM Algorithm</a><a id="Fit-Using-Laplace-EM-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Fit-Using-Laplace-EM-Algorithm" title="Permalink"></a></h2><p>Use Laplace-EM to learn parameters. This is more complex than standard EM because:</p><ol><li>E-step requires Laplace approximations for non-Gaussian posteriors</li><li>M-step updates account for Poisson likelihood structure</li><li>Convergence can be slower due to non-conjugate nature</li></ol><pre><code class="language-julia hljs">print(&quot;Starting Laplace-EM algorithm...&quot;)
print(&quot;Note: Poisson LDS fitting is computationally intensive\n&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Starting Laplace-EM algorithm...Note: Poisson LDS fitting is computationally intensive</code></pre><p>Fit the model - using fewer iterations due to computational cost</p><pre><code class="language-julia hljs">elbo, _ = fit!(naive_plds, observations; max_iter=25, tol=1e-6);

print(&quot;Laplace-EM completed in $(length(elbo)) iterations\n&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Fitting Poisson LDS via LaPlaceEM...   8%|████                                              |  ETA: 0:00:14 ( 0.62  s/it)Fitting Poisson LDS via LaPlaceEM...  40%|████████████████████                              |  ETA: 0:00:02 ( 0.13  s/it)Fitting Poisson LDS via LaPlaceEM...  72%|████████████████████████████████████              |  ETA: 0:00:01 (80.47 ms/it)Fitting Poisson LDS via LaPlaceEM... 100%|██████████████████████████████████████████████████| Time: 0:00:01 (61.36 ms/it)
Laplace-EM completed in 25 iterations</code></pre><p>Perform smoothing with learned parameters</p><pre><code class="language-julia hljs">smoothed_x_post, smoothed_p_post = smooth(naive_plds, observations);</code></pre><p>Compare true vs. learned latent state estimates</p><pre><code class="language-julia hljs">p4 = plot()
for d in 1:latent_dim
    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,
          linewidth=2, label=(d==1 ? &quot;True&quot; : &quot;&quot;), alpha=0.8)
    plot!(1:tSteps, smoothed_x_post[d, :, 1] .+ lim_states * (d-1), color=:red,
          linewidth=2, label=(d==1 ? &quot;Post-EM Est.&quot; : &quot;&quot;), alpha=0.8)
end

plot!(yticks=(lim_states .* (0:latent_dim-1), [L&quot;x_%$d&quot; for d in 1:latent_dim]),
      xlabel=&quot;Time&quot;, xlims=(0, tSteps), title=&quot;Post-EM: True vs. Learned Estimates&quot;,
      yformatter=y-&gt;&quot;&quot;, tickfontsize=12, legend=:topright)</code></pre><img src="368864ca.svg" alt="Example block output"/><h2 id="Monitor-ELBO-Convergence"><a class="docs-heading-anchor" href="#Monitor-ELBO-Convergence">Monitor ELBO Convergence</a><a id="Monitor-ELBO-Convergence-1"></a><a class="docs-heading-anchor-permalink" href="#Monitor-ELBO-Convergence" title="Permalink"></a></h2><p>The Evidence Lower Bound (ELBO) tracks algorithm progress. For Poisson LDS, ELBO includes both data likelihood and Laplace approximation terms. Convergence may be less smooth than Gaussian case due to approximations.</p><pre><code class="language-julia hljs">p5 = plot(elbo, xlabel=&quot;Iteration&quot;, ylabel=&quot;ELBO&quot;,
          title=&quot;Laplace-EM Convergence&quot;, legend=false,
          linewidth=2, marker=:circle, markersize=3, color=:darkgreen)</code></pre><img src="87668c10.svg" alt="Example block output"/><p>Add convergence annotation</p><pre><code class="language-julia hljs">if length(elbo) &gt; 1
    improvement = elbo[end] - elbo[1]
    annotate!(p5, length(elbo)*0.7, elbo[end]*0.95,
        text(&quot;Improvement: $(round(improvement, digits=1))&quot;, 10))
end</code></pre><img src="c2bd9342.svg" alt="Example block output"/><h2 id="Parameter-Recovery-Assessment"><a class="docs-heading-anchor" href="#Parameter-Recovery-Assessment">Parameter Recovery Assessment</a><a id="Parameter-Recovery-Assessment-1"></a><a class="docs-heading-anchor-permalink" href="#Parameter-Recovery-Assessment" title="Permalink"></a></h2><pre><code class="language-julia hljs">print(&quot;\n=== Parameter Recovery Assessment ===\n&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">
=== Parameter Recovery Assessment ===</code></pre><p>Compare key learned parameters with ground truth</p><pre><code class="language-julia hljs">print(&quot;Dynamics Matrix A Recovery:\n&quot;)
A_error = norm(A - naive_plds.state_model.A) / norm(A)
print(&quot;Relative error: $(round(A_error, digits=3))\n&quot;)

print(&quot;Observation Matrix C Recovery:\n&quot;)
C_error = norm(C - naive_plds.obs_model.C) / norm(C)
print(&quot;Relative error: $(round(C_error, digits=3))\n&quot;)

print(&quot;Process Noise Q Recovery:\n&quot;)
Q_error = norm(Q - naive_plds.state_model.Q) / norm(Q)
print(&quot;Relative error: $(round(Q_error, digits=3))\n&quot;);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Dynamics Matrix A Recovery:
Relative error: 0.476
Observation Matrix C Recovery:
Relative error: 1.451
Process Noise Q Recovery:
Relative error: 2.426</code></pre><h2 id="Computational-Complexity-Notes"><a class="docs-heading-anchor" href="#Computational-Complexity-Notes">Computational Complexity Notes</a><a id="Computational-Complexity-Notes-1"></a><a class="docs-heading-anchor-permalink" href="#Computational-Complexity-Notes" title="Permalink"></a></h2><pre><code class="language-julia hljs">print(&quot;\n=== Computational Considerations ===\n&quot;)
print(&quot;Poisson LDS fitting challenges:\n&quot;)
print(&quot;• Non-conjugate Poisson-Gaussian combination requires approximations\n&quot;)
print(&quot;• Laplace approximation adds computational overhead per E-step\n&quot;)
print(&quot;• Optimization landscape can be more complex than Gaussian case\n&quot;)
print(&quot;• Convergence typically slower than standard EM\n&quot;)
print(&quot;\nBenefits:\n&quot;)
print(&quot;• Principled handling of count/spike data\n&quot;)
print(&quot;• Maintains interpretable continuous latent dynamics\n&quot;)
print(&quot;• Extends LDS framework to discrete observations\n&quot;);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">
=== Computational Considerations ===
Poisson LDS fitting challenges:
• Non-conjugate Poisson-Gaussian combination requires approximations
• Laplace approximation adds computational overhead per E-step
• Optimization landscape can be more complex than Gaussian case
• Convergence typically slower than standard EM

Benefits:
• Principled handling of count/spike data
• Maintains interpretable continuous latent dynamics
• Extends LDS framework to discrete observations</code></pre><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><p>This tutorial demonstrated fitting a Poisson Linear Dynamical System:</p><p><strong>Key Concepts:</strong></p><ul><li><strong>Hybrid model</strong>: Continuous Gaussian latent dynamics generate discrete Poisson observations</li><li><strong>Exponential link</strong>: <span>$\log(\lambda_i) = \mathbf{C}_i^T \mathbf{x}_t + d_i$</span> connects latent states to count rates</li><li><strong>Laplace-EM</strong>: Handles non-conjugate Poisson-Gaussian combination through approximations</li><li><strong>Count data modeling</strong>: Extends LDS framework to spike trains and event sequences</li></ul><p><strong>Applications:</strong></p><ul><li>Neural spike train analysis and decoding</li><li>Customer arrival modeling and forecasting</li><li>Event sequence analysis in discrete-time systems</li><li>Any scenario with latent continuous dynamics generating discrete observations</li></ul><p><strong>Technical Insights:</strong></p><ul><li>More computationally intensive than Gaussian LDS due to required approximations</li><li>Convergence can be slower and less smooth than conjugate models</li><li>Parameter recovery quality depends on observation density and latent state separation</li><li>Laplace approximations become more accurate with higher count rates</li></ul><p><strong>Advantages:</strong></p><ul><li>Principled probabilistic framework for count data</li><li>Maintains interpretable continuous latent dynamics</li><li>Enables simultaneous state estimation and parameter learning</li><li>Provides uncertainty quantification for both states and parameters</li></ul><p>The Poisson LDS successfully bridges continuous dynamical systems and discrete observation models, enabling principled analysis of count data with underlying temporal structure.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gaussian_latent_dynamics_example/">« Gaussian LDS Example</a><a class="docs-footer-nextpage" href="../hidden_markov_model_example/">Hidden Markov Model Example »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 9 September 2025 20:42">Tuesday 9 September 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
