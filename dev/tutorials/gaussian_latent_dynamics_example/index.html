<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Gaussian LDS Example · StateSpaceDynamics.jl</title><meta name="title" content="Gaussian LDS Example · StateSpaceDynamics.jl"/><meta property="og:title" content="Gaussian LDS Example · StateSpaceDynamics.jl"/><meta property="twitter:title" content="Gaussian LDS Example · StateSpaceDynamics.jl"/><meta name="description" content="Documentation for StateSpaceDynamics.jl."/><meta property="og:description" content="Documentation for StateSpaceDynamics.jl."/><meta property="twitter:description" content="Documentation for StateSpaceDynamics.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="StateSpaceDynamics.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">StateSpaceDynamics.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Models</span><ul><li><a class="tocitem" href="../../LinearDynamicalSystems/">Linear Dynamical Systems</a></li><li><a class="tocitem" href="../../HiddenMarkovModels/">Hidden Markov Models</a></li><li><a class="tocitem" href="../../SLDS/">Switching Linear Dynamical Systems</a></li><li><a class="tocitem" href="../../EmissionModels/">Emission Models</a></li><li><a class="tocitem" href="../../MixtureModels/">Mixture Models</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li class="is-active"><a class="tocitem" href>Gaussian LDS Example</a><ul class="internal"><li><a class="tocitem" href="#Load-Required-Packages"><span>Load Required Packages</span></a></li><li><a class="tocitem" href="#Create-a-State-Space-Model"><span>Create a State-Space Model</span></a></li><li><a class="tocitem" href="#Mathematical-Foundation-of-Linear-Dynamical-Systems"><span>Mathematical Foundation of Linear Dynamical Systems</span></a></li><li><a class="tocitem" href="#Simulate-Latent-and-Observed-Data"><span>Simulate Latent and Observed Data</span></a></li><li><a class="tocitem" href="#Plot-Vector-Field-of-Latent-Dynamics"><span>Plot Vector Field of Latent Dynamics</span></a></li><li><a class="tocitem" href="#Plot-Latent-States-and-Observations"><span>Plot Latent States and Observations</span></a></li><li><a class="tocitem" href="#The-Learning-Problem"><span>The Learning Problem</span></a></li><li><a class="tocitem" href="#Understanding-the-EM-Algorithm"><span>Understanding the EM Algorithm</span></a></li><li><a class="tocitem" href="#Model-Convergence-Analysis"><span>Model Convergence Analysis</span></a></li><li><a class="tocitem" href="#Interpreting-the-Results"><span>Interpreting the Results</span></a></li><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li></ul></li><li><a class="tocitem" href="../poisson_latent_dynamics_example/">Poisson LDS Example</a></li><li><a class="tocitem" href="../lds_model_selection_example/">LDS Model Selection Example</a></li><li><a class="tocitem" href="../lds_identifiability_example/">Non-Identifiability in LDS Models</a></li><li><a class="tocitem" href="../hidden_markov_model_example/">Hidden Markov Model Example</a></li><li><a class="tocitem" href="../hmm_model_selection_example/">HMM Model Selection</a></li><li><a class="tocitem" href="../gaussian_glm_hmm_example/">Gaussian GLM-HMM Example</a></li><li><a class="tocitem" href="../hmm_identifiability_example/">HMM Identifiability</a></li><li><a class="tocitem" href="../gaussian_mixture_model_example/">Gaussian Mixture Model Example</a></li><li><a class="tocitem" href="../poisson_mixture_model_example/">Poisson Mixture Model Example</a></li><li><a class="tocitem" href="../Probabilistic_PCA_example/">Probabilistic PCA Example</a></li><li><a class="tocitem" href="../switching_linear_dynamical_system_example/">Switching Linear Dynamical System Example</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Gaussian LDS Example</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Gaussian LDS Example</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/depasquale-lab/StateSpaceDynamics.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/depasquale-lab/StateSpaceDynamics.jl/blob/main/docs/examples/GaussianLDS.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Simulating-and-Fitting-a-Linear-Dynamical-System"><a class="docs-heading-anchor" href="#Simulating-and-Fitting-a-Linear-Dynamical-System">Simulating and Fitting a Linear Dynamical System</a><a id="Simulating-and-Fitting-a-Linear-Dynamical-System-1"></a><a class="docs-heading-anchor-permalink" href="#Simulating-and-Fitting-a-Linear-Dynamical-System" title="Permalink"></a></h1><p>This tutorial demonstrates how to use <code>StateSpaceDynamics.jl</code> to simulate a latent linear dynamical system and fit it using the EM algorithm. We&#39;ll walk through the complete workflow: defining a true model, generating synthetic data, initializing a naive model, and then learning the parameters through iterative optimization.</p><h2 id="Load-Required-Packages"><a class="docs-heading-anchor" href="#Load-Required-Packages">Load Required Packages</a><a id="Load-Required-Packages-1"></a><a class="docs-heading-anchor-permalink" href="#Load-Required-Packages" title="Permalink"></a></h2><pre><code class="language-julia hljs">using StateSpaceDynamics
using LinearAlgebra
using Random
using Plots
using LaTeXStrings
using StableRNGs</code></pre><p>Set a stable random number generator for reproducible results</p><pre><code class="language-julia hljs">rng = StableRNG(123);</code></pre><h2 id="Create-a-State-Space-Model"><a class="docs-heading-anchor" href="#Create-a-State-Space-Model">Create a State-Space Model</a><a id="Create-a-State-Space-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Create-a-State-Space-Model" title="Permalink"></a></h2><h2 id="Mathematical-Foundation-of-Linear-Dynamical-Systems"><a class="docs-heading-anchor" href="#Mathematical-Foundation-of-Linear-Dynamical-Systems">Mathematical Foundation of Linear Dynamical Systems</a><a id="Mathematical-Foundation-of-Linear-Dynamical-Systems-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-Foundation-of-Linear-Dynamical-Systems" title="Permalink"></a></h2><p>A Linear Dynamical System describes how a hidden state evolves over time and generates observations through two key equations:</p><p><strong>State Evolution</strong>: <span>$x_{t+1} = \mathbf{A}  x_t + ε_t$</span>,  where <span>$ε_t \sim N(0, \mathbf{Q})$</span> \
<strong>Observation</strong>: <span>$y_t = \mathbf{C}  x_t + η_t$</span>,  where <span>$η_t \sim N(0, \mathbf{R})$</span></p><p>The beauty of this formulation is that it separates the underlying dynamics (governed by <span>$\mathbf{A}$</span>) from what we can actually measure (governed by <span>$\mathbf{C}$</span>). The noise terms <span>$\boldsymbol{\epsilon}$</span> and <span>$\boldsymbol{\eta}$</span> represent our uncertainty about the process and measurements.</p><pre><code class="language-julia hljs">obs_dim = 10      # Number of observed variables at each time step
latent_dim = 2;   # Number of latent state variables</code></pre><p>Define the state transition matrix <span>$\mathbf{A}$</span>. This matrix governs how the latent state evolves from one time step to the next: <span>$\mathbf{x}_{t+1} = \mathbf{A} \mathbf{x}_t + \boldsymbol{\epsilon}$</span>. The rotation angle of 0.25 radians (≈14.3°) creates a gentle spiral, while the 0.95 scaling ensures the system is stable (eigenvalues &lt; 1). Without the scaling factor, trajectories would spiral outward indefinitely. This particular combination creates visually appealing dynamics that are easy to interpret.</p><pre><code class="language-julia hljs">A = 0.95 * [cos(0.25) -sin(0.25); sin(0.25) cos(0.25)];</code></pre><p>Process noise covariance <span>$\mathbf{Q}$</span> controls how much random variation we add to the latent state transitions. A smaller <span>$\mathbf{Q}$</span> means more predictable dynamics.</p><pre><code class="language-julia hljs">Q = Matrix(0.1 * I(2));</code></pre><p>Initial state parameters: where the latent trajectory starts and how uncertain we are about this initial position.</p><pre><code class="language-julia hljs">x0 = [0.0; 0.0]           # Mean of initial state
P0 = Matrix(0.1 * I(2));  # Covariance of initial state</code></pre><p>Observation parameters: how the latent states map to observed data. <span>$\mathbf{C}$</span> is the observation matrix (latent-to-observed mapping), and <span>$\mathbf{R}$</span> is the observation noise covariance.</p><pre><code class="language-julia hljs">C = randn(rng, obs_dim, latent_dim)  # Random linear mapping from 2D latent to 10D observed
R = Matrix(0.5 * I(obs_dim));         # Independent noise on each observation dimension</code></pre><p>Construct the state and observation model components</p><pre><code class="language- hljs">true_gaussian_sm = GaussianStateModel(;A=A, Q=Q, x0=x0, P0=P0)
true_gaussian_om = GaussianObservationModel(;C=C, R=R);
nothing #hide</code></pre><p>Combine them into a complete Linear Dynamical System The fit_bool parameter indicates which parameters should be learned during fitting</p><pre><code class="language- hljs">true_lds = LinearDynamicalSystem(;
    state_model=true_gaussian_sm,
    obs_model=true_gaussian_om,
    latent_dim=latent_dim,
    obs_dim=obs_dim,
    fit_bool=fill(true, 6)  # Fit all 6 parameter matrices: A, Q, C, R, x0, P0
);
nothing #hide</code></pre><h2 id="Simulate-Latent-and-Observed-Data"><a class="docs-heading-anchor" href="#Simulate-Latent-and-Observed-Data">Simulate Latent and Observed Data</a><a id="Simulate-Latent-and-Observed-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Simulate-Latent-and-Observed-Data" title="Permalink"></a></h2><p>Now we generate synthetic data from our true model. This gives us both the latent states (which we&#39;ll later try to recover) and the observations (which is all a real algorithm would see).</p><pre><code class="language-julia hljs">tSteps = 500;  # Number of time points to simulate</code></pre><p>The rand function generates both latent trajectories and corresponding observations</p><pre><code class="language- hljs">latents, observations = rand(rng, true_lds; tsteps=tSteps, ntrials=1);
nothing #hide</code></pre><h2 id="Plot-Vector-Field-of-Latent-Dynamics"><a class="docs-heading-anchor" href="#Plot-Vector-Field-of-Latent-Dynamics">Plot Vector Field of Latent Dynamics</a><a id="Plot-Vector-Field-of-Latent-Dynamics-1"></a><a class="docs-heading-anchor-permalink" href="#Plot-Vector-Field-of-Latent-Dynamics" title="Permalink"></a></h2><p>To better understand the dynamics encoded by our transition matrix <span>$\mathbf{A}$</span>, we&#39;ll create a vector field plot. This shows how the latent state would evolve from any starting point in the 2D latent space.</p><p>Create a grid of starting points and calculate the flow field</p><pre><code class="language-julia hljs">x = y = -3:0.5:3
X = repeat(x&#39;, length(y), 1)
Y = repeat(y, 1, length(x))

U = zeros(size(X))  # x-component of flow
V = zeros(size(Y))  # y-component of flow

for i in 1:size(X, 1), j in 1:size(X, 2)
    v = A * [X[i,j], Y[i,j]]
    U[i,j] = v[1] - X[i,j]  # Change in x
    V[i,j] = v[2] - Y[i,j]  # Change in y
end</code></pre><p>Normalize arrows for cleaner visualization</p><pre><code class="language-julia hljs">magnitude = @. sqrt(U^2 + V^2)
U_norm = U ./ magnitude
V_norm = V ./ magnitude;</code></pre><p>Create the vector field plot with the actual trajectory overlaid</p><pre><code class="language- hljs">p1 = quiver(X, Y, quiver=(U_norm, V_norm), color=:blue, alpha=0.3,
           linewidth=1, arrow=arrow(:closed, :head, 0.1, 0.1))
plot!(latents[1, :, 1], latents[2, :, 1], xlabel=L&quot;x_1&quot;, ylabel=L&quot;x_2&quot;,
      color=:black, linewidth=1.5, title=&quot;Latent Dynamics&quot;, legend=false)</code></pre><h2 id="Plot-Latent-States-and-Observations"><a class="docs-heading-anchor" href="#Plot-Latent-States-and-Observations">Plot Latent States and Observations</a><a id="Plot-Latent-States-and-Observations-1"></a><a class="docs-heading-anchor-permalink" href="#Plot-Latent-States-and-Observations" title="Permalink"></a></h2><p>Let&#39;s visualize both the latent states (which evolve smoothly according to our dynamics) and the observations (which are noisy linear combinations of the latents).</p><pre><code class="language- hljs">states = latents[:, :, 1]      # Extract the latent trajectory
emissions = observations[:, :, 1];  # Extract the observed data
nothing #hide</code></pre><p>Create a two-panel plot: latent states on top, observations below</p><pre><code class="language- hljs">lim_states = maximum(abs.(states))
lim_emissions = maximum(abs.(emissions))

p2 = plot(size=(800, 600), layout=@layout[a{0.3h}; b])

for d in 1:latent_dim
    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,
          linewidth=2, label=&quot;&quot;, subplot=1)
end

plot!(subplot=1, yticks=(lim_states .* (0:latent_dim-1), [L&quot;x_%$d&quot; for d in 1:latent_dim]),
      xticks=[], xlims=(0, tSteps), title=&quot;Simulated Latent States&quot;,
      yformatter=y-&gt;&quot;&quot;, tickfontsize=12);

for n in 1:obs_dim
    plot!(1:tSteps, emissions[n, :] .- lim_emissions * (n-1), color=:black,
          linewidth=2, label=&quot;&quot;, subplot=2); # Plot observations (offset vertically since there are many dimensions)

end

plot!(subplot=2, yticks=(-lim_emissions .* (obs_dim-1:-1:0), [L&quot;y_{%$n}&quot; for n in 1:obs_dim]),
      xlabel=&quot;time&quot;, xlims=(0, tSteps), title=&quot;Simulated Emissions&quot;,
      yformatter=y-&gt;&quot;&quot;, tickfontsize=12, left_margin=10Plots.mm)</code></pre><h2 id="The-Learning-Problem"><a class="docs-heading-anchor" href="#The-Learning-Problem">The Learning Problem</a><a id="The-Learning-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#The-Learning-Problem" title="Permalink"></a></h2><p>In real applications, we only observe <span>$y_t$</span> (the emissions) - the latent states <span>$x_t$</span> are hidden from us. Our challenge is to recover both:</p><ol><li>The system parameters (<span>$\mathbf{A}$</span>, <span>$\mathbf{Q}$</span>, <span>$\mathbf{C}$</span>, <span>$\mathbf{R}$</span>) that generated the data</li><li>The most likely latent state sequence given our observations</li></ol><p>This is a classic &quot;chicken and egg&quot; problem: if we knew the parameters, we could infer the states; if we knew the states, we could estimate the parameters. The EM algorithm elegantly solves this by alternating between these two problems.</p><p>Initialize with random parameters (this simulates not knowing the true system)</p><pre><code class="language-julia hljs">A_init = random_rotation_matrix(2, rng)    # Random rotation matrix for dynamics
Q_init = Matrix(0.1 * I(2))                # Same process noise variance
C_init = randn(rng, obs_dim, latent_dim)   # Random observation mapping
R_init = Matrix(0.5 * I(obs_dim))          # Same observation noise
x0_init = zeros(latent_dim)                # Start from origin
P0_init = Matrix(0.1 * I(latent_dim));      # Same initial uncertainty</code></pre><p>Our &quot;naive&quot; initialization uses random parameters, simulating a real scenario where we don&#39;t know the true system. The quality of initialization can affect convergence speed and which local optimum we find, but EM is generally robust to reasonable starting points.</p><pre><code class="language- hljs">gaussian_sm_init = GaussianStateModel(;A=A_init, Q=Q_init, x0=x0_init, P0=P0_init)
gaussian_om_init = GaussianObservationModel(;C=C_init, R=R_init)</code></pre><p>Assemble the complete naive system</p><pre><code class="language- hljs">naive_ssm = LinearDynamicalSystem(;
    state_model=gaussian_sm_init,
    obs_model=gaussian_om_init,
    latent_dim=latent_dim,
    obs_dim=obs_dim,
    fit_bool=fill(true, 6)  # We&#39;ll learn all parameters
);
nothing #hide</code></pre><p>Before fitting, let&#39;s see how well our randomly initialized model can infer the latent states using the smoothing algorithm.</p><pre><code class="language- hljs">x_smooth, p_smooth = StateSpaceDynamics.smooth(naive_ssm, observations);
nothing #hide</code></pre><p>Plot the true latent states vs. our initial (poor) estimates</p><pre><code class="language- hljs">p3 = plot()
for d in 1:latent_dim
    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,
          linewidth=2, label=(d==1 ? &quot;True&quot; : &quot;&quot;), alpha=0.8)
    plot!(1:tSteps, x_smooth[d, :, 1] .+ lim_states * (d-1), color=:firebrick,
          linewidth=2, label=(d==1 ? &quot;Predicted&quot; : &quot;&quot;), alpha=0.8)
end
plot!(yticks=(lim_states .* (0:latent_dim-1), [L&quot;x_%$d&quot; for d in 1:latent_dim]),
      xlabel=&quot;time&quot;, xlims=(0, tSteps), yformatter=y-&gt;&quot;&quot;, tickfontsize=12,
      title=&quot;True vs. Predicted Latent States (Pre-EM)&quot;,
      legend=:topright)</code></pre><h2 id="Understanding-the-EM-Algorithm"><a class="docs-heading-anchor" href="#Understanding-the-EM-Algorithm">Understanding the EM Algorithm</a><a id="Understanding-the-EM-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Understanding-the-EM-Algorithm" title="Permalink"></a></h2><p>EM alternates between two steps until convergence:</p><p><strong>E-step (Expectation)</strong>: Given current parameter estimates, compute the posterior distribution over latent states using the Kalman smoother. This gives us <span>$p(x_{1:T} | y_{1:T}, θ_{current})$</span>.</p><p><strong>M-step (Maximization)</strong>: Given the state estimates from the E-step, update the parameters to maximize the expected log-likelihood. This involves solving closed-form equations for <span>$\mathbf{A}$</span>, <span>$\mathbf{Q}$</span>, <span>$\mathbf{C}$</span>, and <span>$\mathbf{R}$</span>.</p><p>The Evidence Lower BOund (ELBO) measures how well our model explains the data. It&#39;s guaranteed to increase (or stay constant) at each iteration, ensuring convergence to at least a local optimum.</p><pre><code class="language-julia hljs">println(&quot;Starting EM algorithm to learn parameters...&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Starting EM algorithm to learn parameters...</code></pre><p>Suppress output and capture ELBO values</p><pre><code class="language- hljs">elbo, _ = fit!(naive_ssm, observations; max_iter=100, tol=1e-6);

println(&quot;EM converged after $(length(elbo)) iterations&quot;)</code></pre><p>After EM has converged, let&#39;s see how much better our latent state estimates are</p><pre><code class="language- hljs">x_smooth_post, p_smooth_post = StateSpaceDynamics.smooth(naive_ssm, observations);
nothing #hide</code></pre><p>Plot the results: true states vs. post-EM estimates</p><pre><code class="language- hljs">p4 = plot()
for d in 1:latent_dim
    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,
          linewidth=2, label=(d==1 ? &quot;True&quot; : &quot;&quot;), alpha=0.8)
    plot!(1:tSteps, x_smooth_post[d, :, 1] .+ lim_states * (d-1), color=:firebrick,
          linewidth=2, label=(d==1 ? &quot;Predicted&quot; : &quot;&quot;), alpha=0.8)
end
plot!(yticks=(lim_states .* (0:latent_dim-1), [L&quot;x_%$d&quot; for d in 1:latent_dim]),
      xlabel=&quot;time&quot;, xlims=(0, tSteps), yformatter=y-&gt;&quot;&quot;, tickfontsize=12,
      title=&quot;True vs. Predicted Latent States (Post-EM)&quot;,
      legend=:topright)</code></pre><h2 id="Model-Convergence-Analysis"><a class="docs-heading-anchor" href="#Model-Convergence-Analysis">Model Convergence Analysis</a><a id="Model-Convergence-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Model-Convergence-Analysis" title="Permalink"></a></h2><p>The Evidence Lower Bound (ELBO) measures how well our model explains the data. In EM, this should increase monotonically and plateau when the algorithm has converged to a local optimum.</p><pre><code class="language- hljs">p5 = plot(elbo, xlabel=&quot;Iteration&quot;, ylabel=&quot;ELBO&quot;,
          title=&quot;Model Convergence (ELBO)&quot;, legend=false,
          linewidth=2, color=:darkblue)</code></pre><h2 id="Interpreting-the-Results"><a class="docs-heading-anchor" href="#Interpreting-the-Results">Interpreting the Results</a><a id="Interpreting-the-Results-1"></a><a class="docs-heading-anchor-permalink" href="#Interpreting-the-Results" title="Permalink"></a></h2><p>The dramatic improvement in state estimation shows that EM successfully recovered the underlying dynamics. However, keep in mind:</p><ul><li>We may have found a local optimum, not the global one</li><li>The recovered parameters might differ from the true ones due to identifiability issues (multiple parameter sets can generate similar observations)</li><li>In practice, you&#39;d validate the model on held-out data to ensure generalization</li></ul><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><p>This tutorial demonstrated the complete workflow for fitting a Linear Dynamical System:</p><ol><li>We defined a true LDS with spiral dynamics and generated synthetic data</li><li>We initialized a naive model with random parameters</li><li>We used EM to iteratively improve our parameter estimates</li><li>We visualized the dramatic improvement in latent state inference</li></ol><p>The EM algorithm successfully recovered the underlying dynamics from observations alone, as evidenced by the improved match between true and estimated latent states and the monotonic convergence of the ELBO objective function.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../MixtureModels/">« Mixture Models</a><a class="docs-footer-nextpage" href="../poisson_latent_dynamics_example/">Poisson LDS Example »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 21 October 2025 19:36">Tuesday 21 October 2025</span>. Using Julia version 1.12.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
