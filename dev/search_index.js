var documenterSearchIndex = {"docs":
[{"location":"tutorials/poisson_mixture_model_example/#Simulating-and-Fitting-a-Poisson-Mixture-Model","page":"Poisson Mixture Model Example","title":"Simulating and Fitting a Poisson Mixture Model","text":"This tutorial demonstrates how to build and fit a Poisson Mixture Model (PMM) with StateSpaceDynamics.jl using the Expectation-Maximization (EM) algorithm. We'll cover simulation, fitting, diagnostics, interpretation, and practical considerations.","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#What-is-a-Poisson-Mixture-Model?","page":"Poisson Mixture Model Example","title":"What is a Poisson Mixture Model?","text":"A PMM assumes each observation x_i in 012ldots is drawn from one of k Poisson distributions with rates lambda_1ldotslambda_k. The component assignment is a latent categorical variable z_i in 1ldotsk with mixing weights pi_1ldotspi_k where sum_j pi_j = 1.\n\nGenerative process:\n\nDraw z_i sim textCategorical(boldsymbolpi)\nGiven z_i = j, draw x_i sim textPoisson(lambda_j)\n\nPMMs are useful for count data from heterogeneous sub-populations (e.g., spike counts from different neuron types, customer transaction counts from different segments, or event frequencies across different regimes).","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#EM-Algorithm-Overview","page":"Poisson Mixture Model Example","title":"EM Algorithm Overview","text":"EM maximizes the marginal log-likelihood log p(mathbfx  boldsymbolpi boldsymbollambda) by iterating:\n\nE-step: Compute responsibilities gamma_ij = P(z_i = j  x_i boldsymboltheta)\nM-step: Update parameters to maximize expected complete-data log-likelihood\n\nFor Poisson mixtures, the M-step has closed-form updates: pi_j leftarrow frac1n sum_i gamma_ij quad lambda_j leftarrow fracsum_i gamma_ij x_isum_i gamma_ij","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#Load-Required-Packages","page":"Poisson Mixture Model Example","title":"Load Required Packages","text":"using StateSpaceDynamics\nusing LinearAlgebra\nusing Random\nusing Plots\nusing StableRNGs\nusing StatsPlots\nusing Distributions\n\nFix RNG for reproducible simulation and k-means seeding\n\nrng = StableRNG(1234);\nnothing #hide","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#Create-True-Poisson-Mixture-Model","page":"Poisson Mixture Model Example","title":"Create True Poisson Mixture Model","text":"We'll simulate from a mixture of k=3 Poisson components with distinct rates and mixing weights. These parameters create well-separated components that should be recoverable by EM.\n\nk = 3\ntrue_λs = [5.0, 10.0, 25.0]   # Poisson rates per component\ntrue_πs = [0.25, 0.45, 0.30]  # Mixing weights (sum to 1)\n\ntrue_pmm = PoissonMixtureModel(k, true_λs, true_πs);\n\nprint(\"True model: k=$k components\\n\")\nfor i in 1:k\n    print(\"Component $i: λ=$(true_λs[i]), π=$(true_πs[i])\\n\")\nend","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#Generate-Synthetic-Data","page":"Poisson Mixture Model Example","title":"Generate Synthetic Data","text":"Draw n independent samples. The labels indicate true component membership for each observation (unknown in practice and must be inferred).\n\nn = 500\nlabels = rand(rng, Categorical(true_πs), n)\ndata = [rand(rng, Poisson(true_λs[labels[i]])) for i in 1:n];\n\nprint(\"Generated $n samples with count range [$(minimum(data)), $(maximum(data))]\\n\");\nnothing #hide\n\nVisualize samples by true component membership Components with larger lambda shift mass toward higher counts\n\np1 = histogram(data;\n    group=labels,\n    bins=0:1:maximum(data),\n    bar_position=:dodge,\n    xlabel=\"Count\", ylabel=\"Frequency\",\n    title=\"Poisson Mixture Samples by True Component\",\n    alpha=0.7, legend=:topright\n)","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#Fit-Poisson-Mixture-Model-with-EM","page":"Poisson Mixture Model Example","title":"Fit Poisson Mixture Model with EM","text":"Construct model with k components and fit using EM algorithm. Key options:\n\nmaxiter: Maximum EM iterations\ntol: Convergence tolerance (relative log-likelihood improvement)\ninitialize_kmeans=true: Use k-means for stable initialization\n\nfit_pmm = PoissonMixtureModel(k)\n_, lls = fit!(fit_pmm, data; maxiter=100, tol=1e-6, initialize_kmeans=true);\n\nprint(\"EM converged in $(length(lls)) iterations\\n\")\nprint(\"Log-likelihood improved by $(round(lls[end] - lls[1], digits=1))\\n\");\nnothing #hide\n\nDisplay learned parameters\n\nprint(\"Learned parameters:\\n\")\nfor i in 1:k\n    print(\"Component $i: λ=$(round(fit_pmm.λₖ[i], digits=2)), π=$(round(fit_pmm.πₖ[i], digits=3))\\n\")\nend","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#Monitor-EM-Convergence","page":"Poisson Mixture Model Example","title":"Monitor EM Convergence","text":"EM guarantees non-decreasing log-likelihood. Monotonic ascent indicates proper convergence.\n\np2 = plot(lls;\n    xlabel=\"Iteration\", ylabel=\"Log-Likelihood\",\n    title=\"EM Convergence\",\n    marker=:circle, markersize=3, lw=2,\n    legend=false, color=:darkblue\n)\n\nannotate!(p2, length(lls)*0.7, lls[end]*0.98,\n    text(\"Final LL: $(round(lls[end], digits=1))\", 10))","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#Visual-Model-Assessment","page":"Poisson Mixture Model Example","title":"Visual Model Assessment","text":"Overlay fitted component PMFs and overall mixture PMF on normalized histogram. Components should explain major modes and tail behavior in the data.\n\np3 = histogram(data;\n    bins=0:1:maximum(data), normalize=true, alpha=0.3,\n    xlabel=\"Count\", ylabel=\"Probability Density\",\n    title=\"Data vs. Fitted Mixture Components\",\n    label=\"Data\", color=:gray\n)\n\nx_range = collect(0:maximum(data))\ncolors = [:red, :green, :blue]\n\nPlot individual component PMFs\n\nfor i in 1:k\n    λᵢ = fit_pmm.λₖ[i]\n    πᵢ = fit_pmm.πₖ[i]\n    pmf_i = πᵢ .* pdf.(Poisson(λᵢ), x_range)\n    plot!(p3, x_range, pmf_i;\n        lw=2, color=colors[i],\n        label=\"Component $i (λ=$(round(λᵢ, digits=1)))\"\n    )\nend\n\nPlot overall mixture PMF\n\nmixture_pmf = reduce(+, (πᵢ .* pdf.(Poisson(λᵢ), x_range)\n                        for (λᵢ, πᵢ) in zip(fit_pmm.λₖ, fit_pmm.πₖ)))\nplot!(p3, x_range, mixture_pmf;\n    lw=3, linestyle=:dash, color=:black,\n    label=\"Mixture PMF\"\n)","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#Posterior-Responsibilities-(Soft-Clustering)","page":"Poisson Mixture Model Example","title":"Posterior Responsibilities (Soft Clustering)","text":"Responsibilities gamma_ij = P(z_i = j  x_i hatboldsymboltheta) quantify how likely each observation belongs to each component. These provide soft assignments and uncertainty quantification.\n\nfunction responsibilities_pmm(λs::AbstractVector, πs::AbstractVector, x::AbstractVector)\n    k, n = length(λs), length(x)\n    Γ = zeros(n, k)\n\n    for i in 1:n\n        for j in 1:k\n            Γ[i, j] = πs[j] * pdf(Poisson(λs[j]), x[i])\n        end\n\n        row_sum = sum(Γ[i, :]) # Normalize to get probabilities\n        if row_sum > 0\n            Γ[i, :] ./= row_sum\n        end\n    end\n    return Γ\nend\n\nΓ = responsibilities_pmm(fit_pmm.λₖ, fit_pmm.πₖ, data);\nnothing #hide\n\nHard assignments (if needed) are argmax over responsibilities\n\nhard_labels = [argmax(Γ[i, :]) for i in 1:n];\nnothing #hide\n\nCalculate assignment accuracy compared to true labels\n\naccuracy = mean(labels .== hard_labels)\nprint(\"Component assignment accuracy: $(round(accuracy*100, digits=1))%\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#Information-Criteria-for-Model-Selection","page":"Poisson Mixture Model Example","title":"Information Criteria for Model Selection","text":"When k is unknown, compare models using AIC/BIC:\n\nAIC = 2p - 2textLL\nBIC = p log(n) - 2textLL\n\nwhere parameter count p = (k-1) + k = 2k-1 (mixing weights + rates)\n\nfunction compute_ic(lls::AbstractVector, n::Int, k::Int)\n    ll = last(lls)\n    p = 2k - 1\n    return (AIC = 2p - 2ll, BIC = p*log(n) - 2ll)\nend\n\nic = compute_ic(lls, n, k)\nprint(\"Information criteria: AIC = $(round(ic.AIC, digits=1)), BIC = $(round(ic.BIC, digits=1))\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#Parameter-Recovery-Assessment","page":"Poisson Mixture Model Example","title":"Parameter Recovery Assessment","text":"print(\"\\n=== Parameter Recovery Assessment ===\\n\")\n\nλ_errors = [abs(true_λs[i] - fit_pmm.λₖ[i]) / true_λs[i] for i in 1:k]\nπ_errors = [abs(true_πs[i] - fit_pmm.πₖ[i]) for i in 1:k]\n\nprint(\"Rate recovery errors (%):\\n\")\nfor i in 1:k\n    print(\"Component $i: $(round(λ_errors[i]*100, digits=1))%\\n\")\nend\n\nprint(\"Mixing weight recovery errors:\\n\")\nfor i in 1:k\n    print(\"Component $i: $(round(π_errors[i], digits=3))\\n\")\nend","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#Model-Selection-Example","page":"Poisson Mixture Model Example","title":"Model Selection Example","text":"Demonstrate fitting multiple values of k and comparing via BIC\n\nprint(\"\\n=== Model Selection Demo ===\\n\")\n\nk_range = 1:5\nbic_scores = Float64[]\naic_scores = Float64[]\n\nfor k_test in k_range\n    pmm_test = PoissonMixtureModel(k_test)\n    _, lls_test = fit!(pmm_test, data; maxiter=50, tol=1e-6, initialize_kmeans=true)\n\n    ic_test = compute_ic(lls_test, n, k_test)\n    push!(aic_scores, ic_test.AIC)\n    push!(bic_scores, ic_test.BIC)\n\n    print(\"k=$k_test: AIC=$(round(ic_test.AIC, digits=1)), BIC=$(round(ic_test.BIC, digits=1))\\n\")\nend\n\nPlot information criteria vs number of components\n\np4 = plot(k_range, [aic_scores bic_scores];\n    xlabel=\"Number of Components (k)\", ylabel=\"Information Criterion\",\n    title=\"Model Selection via Information Criteria\",\n    label=[\"AIC\" \"BIC\"], marker=:circle, lw=2\n)\n\noptimal_k_aic = k_range[argmin(aic_scores)]\noptimal_k_bic = k_range[argmin(bic_scores)]\n\nprint(\"Optimal k: AIC suggests k=$optimal_k_aic, BIC suggests k=$optimal_k_bic\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/poisson_mixture_model_example/#Summary","page":"Poisson Mixture Model Example","title":"Summary","text":"This tutorial demonstrated the complete Poisson Mixture Model workflow:\n\nKey Concepts:\n\nDiscrete mixtures: Model count data as mixture of Poisson distributions\nEM algorithm: Iterative optimization with closed-form M-step updates\nSoft clustering: Posterior responsibilities provide probabilistic assignments\nModel selection: Information criteria help choose appropriate number of components\n\nApplications:\n\nSpike count analysis in neuroscience\nCustomer transaction modeling in business analytics\nEvent frequency analysis in reliability engineering\nGene expression count clustering in bioinformatics\n\nTechnical Insights:\n\nInitialization strategy significantly affects final solution quality\nLabel switching is a fundamental identifiability issue in mixture models\nInformation criteria provide principled approach to model complexity selection\nComponent separation quality affects parameter recovery accuracy\n\nExtensions:\n\nZero-inflated Poisson mixtures for excess zero counts\nNegative Binomial mixtures for overdispersed count data\nBayesian approaches for uncertainty quantification\nMixture regression models for count data with covariates\n\nPoisson mixture models provide a flexible framework for modeling heterogeneous count data, enabling both clustering and density estimation while maintaining interpretable probabilistic structure.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Simulating-and-Fitting-a-Switching-Linear-Dynamical-System-(SLDS)","page":"Switching Linear Dynamical System Example","title":"Simulating and Fitting a Switching Linear Dynamical System (SLDS)","text":"This tutorial demonstrates building, simulating, and fitting a Switching Linear Dynamical System (SLDS) with StateSpaceDynamics.jl. SLDS combines a discrete Hidden Markov Model over modes with linear-Gaussian state-space models, capturing time series that switch among distinct linear dynamics (e.g., alternating between slow and fast oscillatory behaviors).","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Model-Overview","page":"Switching Linear Dynamical System Example","title":"Model Overview","text":"The SLDS combines discrete and continuous latent structure:\n\nDiscrete mode z_t in 1ldotsK with Markov dynamics: P(z_t  z_t-1) = Az_t-1 z_t\nContinuous state mathbfx_t in mathbbR^d_x evolving as: mathbfx_t = mathbfA_z_t mathbfx_t-1 + mathbfb_z_t + boldsymbolvarepsilon_t\nObservations mathbfy_t in mathbbR^d_y via: mathbfy_t = mathbfC_z_t mathbfx_t + mathbfd_z_t + boldsymboleta_t\nProcess noise boldsymbolvarepsilon_t sim mathcalN(mathbf0 mathbfQ_z_t)\nObservation noise boldsymboleta_t sim mathcalN(mathbf0 mathbfR_z_t)\n\nInference: Exact EM is intractable due to exponential mode sequences. The fit! function uses variational Laplace EM (vLEM) combining HMM forward-backward with Laplace approximation for the continuous states.","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Load-Required-Packages","page":"Switching Linear Dynamical System Example","title":"Load Required Packages","text":"using StateSpaceDynamics\nusing LinearAlgebra\nusing Random\nusing Plots\nusing LaTeXStrings\nusing Statistics\nusing StableRNGs\n\nrng = StableRNG(1234);\nnothing #hide","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Create-and-Simulate-SLDS","page":"Switching Linear Dynamical System Example","title":"Create and Simulate SLDS","text":"","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Understanding-SLDS-Components","page":"Switching Linear Dynamical System Example","title":"Understanding SLDS Components","text":"An SLDS has several key components we need to specify:\n\nDiscrete State Dynamics:\n\nA: Transition matrix between discrete states (how likely to switch)\nπₖ: Initial distribution over discrete states\n\nContinuous State Dynamics (for each discrete state k):\n\nAₖ: State transition matrix (how the continuous state evolves)\nbₖ: State bias term\nQₖ: Process noise covariance (uncertainty in state evolution)\nCₖ: Observation matrix (how continuous states map to observations)\ndₖ: Observation bias term\nRₖ: Observation noise covariance\n\nFor our specific test case, we will create two distinct modes:\n\nMode 1: A slower oscillator with low process noise\nMode 2: A faster oscillator with higher process noise\n\nWe will multiply the dynamics matrices by a 0.95 scaling factor to provide stability (eigenvalues < 1). Mode 2 oscillates ~11x faster than Mode 1. The observation matrices C₁ and C₂ are different random projections. This means each discrete state not only has different dynamics, but also different ways of manifesting in the observed data.\n\nstate_dim = 2   # Latent state dimensionality\nobs_dim = 10    # Observation dimensionality\nK = 2           # Number of discrete modes\n\nHMM parameters for mode switching\n\nA_hmm = [0.92 0.08;    # Mode transitions: sticky dynamics\n         0.06 0.94]    # High probability of staying in current mode\nπₖ = [1.0, 0.0]        # Start in mode 1\n\nMode-specific continuous dynamics (two oscillators with different frequencies)\n\nA₁ = 0.95 * [cos(0.05) -sin(0.05); sin(0.05) cos(0.05)]  # Slow oscillator\nA₂ = 0.95 * [cos(0.55) -sin(0.55); sin(0.55) cos(0.55)]  # Fast oscillator\n\nMode-specific process noise (different noise levels)\n\nQ₁ = [0.001 0.0; 0.0 0.001]  # Low noise for mode 1\nQ₂ = [0.1   0.0; 0.0 0.1]    # Higher noise for mode 2\n\nShared initial state distribution\n\nx0 = [0.0, 0.0]\nP0 = [0.1 0.0; 0.0 0.1]\n\nState bias terms (zero for this example)\n\nb = zeros(state_dim)\n\nMode-specific observation models\n\nC₁ = randn(rng, obs_dim, state_dim)  # Random observation mapping for mode 1\nC₂ = randn(rng, obs_dim, state_dim)  # Different mapping for mode 2\nR = Matrix(0.1 * I(obs_dim))         # Shared observation noise\nd = zeros(obs_dim)                    # Observation bias (zero for this example)\n\nConstruct individual Linear Dynamical Systems for each mode\n\nlds1 = LinearDynamicalSystem(\n    GaussianStateModel(A₁, Q₁, b, x0, P0),\n    GaussianObservationModel(C₁, R, d)\n)\n\nlds2 = LinearDynamicalSystem(\n    GaussianStateModel(A₂, Q₂, b, x0, P0),\n    GaussianObservationModel(C₂, R, d)\n)\n\nConstruct the complete SLDS\n\nmodel = SLDS(\n    A=A_hmm,\n    πₖ=πₖ,\n    LDSs=[lds1, lds2]\n);\nnothing #hide","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Simulate-data","page":"Switching Linear Dynamical System Example","title":"Simulate data","text":"T = 1000\nz, x, y = rand(rng, model; tsteps=T, ntrials=1);\nnothing #hide\n\nThe simulation returns:\n\nz: discrete state sequence (T × 1 matrix)\nx: continuous latent states (state_dim × T × 1 array)\ny: observations (obs_dim × T × 1 array)\n\nNotice how the discrete states z create \"regimes\" in the continuous dynamics x.\n\nExtract single trial data for visualization\n\nz_vec = vec(z[:, 1])\nx_trial = x[:, :, 1]\ny_trial = y[:, :, 1];\nnothing #hide","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Visualize-Latent-Dynamics-with-Mode-Shading","page":"Switching Linear Dynamical System Example","title":"Visualize Latent Dynamics with Mode Shading","text":"The plot shows the continuous latent dynamics (x₁, x₂) with background shading indicating the active discrete state. Notice:\n\nLight blue regions: Mode 1 (slow, tight oscillations)\nLight yellow regions: Mode 2 (fast, wide oscillations)\nThe system \"remembers\" where it was when switching between modes\n\np1 = plot(1:T, x_trial[1, :], label=L\"x_1\", linewidth=1.5, color=:black)\nplot!(1:T, x_trial[2, :], label=L\"x_2\", linewidth=1.5, color=:blue)\n\ntransition_points = [1; findall(diff(z_vec) .!= 0) .+ 1; T + 1]\nfor i in 1:(length(transition_points) - 1)\n    start_idx = transition_points[i]\n    end_idx = transition_points[i + 1] - 1\n    state_val = z_vec[start_idx]\n    bg_color = state_val == 1 ? :lightblue : :lightyellow\n    vspan!([start_idx, end_idx], fillalpha=0.3, color=bg_color,\n           label=(i == 1 && start_idx < 100 ? \"Mode $state_val\" : \"\"))\nend\n\nplot!(title=\"Latent Dynamics with Mode Switching\",\n      xlabel=\"Time\", ylabel=\"State Value\",\n      ylims=(-3, 3), legend=:topright)","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Initialize-and-Fit-SLDS","page":"Switching Linear Dynamical System Example","title":"Initialize and Fit SLDS","text":"Initialize SLDS with reasonable but imperfect parameters, then use variational EM to learn.\n\nA_init = [0.9 0.1; 0.1 0.9] # Initialize HMM transition matrix (moderately sticky)\nA_init ./= sum(A_init, dims=2)  # Ensure row-stochastic\n\nπₖ_init = rand(rng, K) # Random initial state probabilities\nπₖ_init ./= sum(πₖ_init)\n\nRandom.seed!(rng, 456)  # Create initial LDS models with random parameters\nlds_init1 = LinearDynamicalSystem(\n    GaussianStateModel(\n        randn(rng, state_dim, state_dim) * 0.5,  # Random A\n        Matrix(0.1 * I(state_dim)),               # Q\n        zeros(state_dim),                          # b\n        zeros(state_dim),                          # x0\n        Matrix(0.1 * I(state_dim))                # P0\n    ),\n    GaussianObservationModel(\n        randn(rng, obs_dim, state_dim),           # Random C\n        Matrix(0.1 * I(obs_dim)),                 # R\n        zeros(obs_dim)                             # d\n    ),\n)\n\nlds_init2 = LinearDynamicalSystem(\n    GaussianStateModel(\n        randn(rng, state_dim, state_dim) * 0.5,  # Random A\n        Matrix(0.1 * I(state_dim)),               # Q\n        zeros(state_dim),                          # b\n        zeros(state_dim),                          # x0\n        Matrix(0.1 * I(state_dim))                # P0\n    ),\n    GaussianObservationModel(\n        randn(rng, obs_dim, state_dim),           # Random C\n        Matrix(0.1 * I(obs_dim)),                 # R\n        zeros(obs_dim)                             # d\n    ),\n)\n\nlearned_model = SLDS(\n    A=A_init,\n    πₖ=πₖ_init,\n    LDSs=[lds_init1, lds_init2]\n);\nnothing #hide\n\nFit using variational Laplace EM\n\nelbos = fit!(learned_model, y; max_iter=25, progress=true)","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Monitor-ELBO-Convergence","page":"Switching Linear Dynamical System Example","title":"Monitor ELBO Convergence","text":"Plot the Evidence Lower Bound (ELBO) to verify monotonic improvement. For SLDS, this tracks the variational approximation quality.\n\np2 = plot(elbos, xlabel=\"Iteration\", ylabel=\"ELBO\",\n          title=\"Variational EM Convergence\",\n          marker=:circle, markersize=3, lw=2,\n          legend=false, color=:darkgreen)\n\nannotate!(p2, length(elbos)*0.7, elbos[end]-abs(elbos[end])*0.05,\n    text(\"Final ELBO: $(round(elbos[end], digits=1))\", 10))","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Compare-True-vs-Learned-Latent-States","page":"Switching Linear Dynamical System Example","title":"Compare True vs Learned Latent States","text":"After fitting, we can extract the smoothed latent states. The learned model stores the most recent smoothed states from the last EM iteration.\n\nFor visualization, we need to run one more smoothing pass to get the final\n\ntfs = StateSpaceDynamics.initialize_FilterSmooth(learned_model.LDSs[1], T, 1)\nfbs = [StateSpaceDynamics.initialize_forward_backward(learned_model, T, Float64)]\n\nw_uniform = ones(Float64, K, T) ./ K # Initialize with uniform weights and smooth\nStateSpaceDynamics.smooth!(learned_model, tfs[1], y_trial, w_uniform)\n\nx_samples, _ = StateSpaceDynamics.sample_posterior(tfs, 1) # Sample and run one E-step to get final discrete state posteriors\nStateSpaceDynamics.estep!(learned_model, tfs, fbs, y, x_samples)\n\nlatents_learned = tfs[1].x_smooth; # Get the final smoothed continuous states\nnothing #hide\n\nPlot comparison with offset for clarity\n\np3 = plot(size=(900, 400))\noffset = 2.5\n\nplot!(1:T, x_trial[1, :] .+ offset, label=L\"x_1 \\text{ (true)}\",\n      linewidth=2, color=:black, alpha=0.8)\nplot!(1:T, x_trial[2, :] .- offset, label=L\"x_2 \\text{ (true)}\",\n      linewidth=2, color=:black, alpha=0.8)\n\nplot!(1:T, latents_learned[1, :] .+ offset, label=L\"x_1 \\text{ (learned)}\",\n      linewidth=1.5, color=:red, alpha=0.8)\nplot!(1:T, latents_learned[2, :] .- offset, label=L\"x_2 \\text{ (learned)}\",\n      linewidth=1.5, color=:blue, alpha=0.8)\n\nhline!([offset, -offset], color=:gray, alpha=0.3, linestyle=:dash, label=\"\")\n\nplot!(title=\"True vs. Learned Latent States\",\n      xlabel=\"Time\", ylabel=\"\",\n      yticks=([-offset, offset], [L\"x_2\", L\"x_1\"]),\n      xlims=(1, T), legend=:topright)","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Mode-Decoding-and-Accuracy-Assessment","page":"Switching Linear Dynamical System Example","title":"Mode Decoding and Accuracy Assessment","text":"Decode discrete modes using posterior responsibilities and assess accuracy.\n\nresponsibilities = exp.(fbs[1].γ)  # Convert from log-space (K × T)\nz_decoded = [argmax(responsibilities[:, t]) for t in 1:T];\nnothing #hide\n\nHandle label permutation by trying both assignments\n\nfunction align_labels_2way(z_true::AbstractVector, z_pred::AbstractVector)\n    acc_direct = mean(z_true .== z_pred)\n    z_flipped = 3 .- z_pred  # Flip 1↔2\n    acc_flipped = mean(z_true .== z_flipped)\n\n    if acc_flipped > acc_direct\n        return z_flipped, acc_flipped\n    else\n        return z_pred, acc_direct\n    end\nend\n\nz_aligned, accuracy = align_labels_2way(z_vec, z_decoded)\nprint(\"Mode decoding accuracy: $(round(accuracy*100, digits=1))%\\n\");\nnothing #hide\n\nVisualize mode assignments over time (first 200 time steps for clarity)\n\nt_subset = 1:200\ntrue_modes = reshape(z_vec[t_subset], 1, :)\ndecoded_modes = reshape(z_aligned[t_subset], 1, :);\n\np4 = plot(\n    heatmap(true_modes, colormap=:roma, title=\"True Mode Sequence\",\n           xticks=false, yticks=false, colorbar=false),\n    heatmap(decoded_modes, colormap=:roma, title=\"Decoded Mode Sequence\",\n           xlabel=\"Time Steps (1-200)\", yticks=false, colorbar=false),\n    layout=(2, 1), size=(800, 300)\n)","category":"section"},{"location":"tutorials/switching_linear_dynamical_system_example/#Summary","page":"Switching Linear Dynamical System Example","title":"Summary","text":"This tutorial demonstrated the complete Switching Linear Dynamical System workflow:\n\nKey Concepts:\n\nHybrid dynamics: Discrete mode switching combined with continuous state evolution\nVariational Laplace EM: Structured approximation handling intractable exact inference\nMode-specific parameters: Each discrete state has its own linear dynamics\nLaplace approximation: Gaussian approximation to the continuous state posterior\n\nTechnical Insights:\n\nELBO monitoring ensures proper variational approximation convergence\nLabel permutation requires careful accuracy assessment\nThe vLEM algorithm alternates between discrete (forward-backward) and continuous (Laplace) inference\nSingle sample Monte Carlo estimation of the ELBO\n\nModeling Power:\n\nCaptures complex time series with multiple dynamic regimes\nEnables automatic segmentation and regime detection\nProvides probabilistic framework for switching systems\nExtends both HMMs and LDS to richer model class\n\nApplications:\n\nNeuroscience: population dynamics across behavioral states\nFinance: regime-switching in market dynamics\nEngineering: fault detection in dynamical systems\nClimate: seasonal transitions and regime changes\n\nSLDS provides a powerful framework for modeling complex temporal data with multiple underlying dynamics, bridging discrete regime detection with continuous state-space modeling in a principled probabilistic framework.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"tutorials/lds_model_selection_example/#Choosing-Latent-Dimensionality-for-Linear-Dynamical-Systems-(LDS)","page":"LDS Model Selection Example","title":"Choosing Latent Dimensionality for Linear Dynamical Systems (LDS)","text":"One of the most critical decisions when fitting an LDS is selecting the latent dimensionality K. Cross-validation is the universal approach that works for ANY state-space model - Gaussian LDS, Poisson LDS, nonlinear SSMs, etc. This tutorial demonstrates robust CV-based model selection.\n\n# Load Required Packages\nusing StateSpaceDynamics\nusing LinearAlgebra\nusing Random\nusing Plots\nusing Statistics\nusing StableRNGs\nusing Printf\n\nFix RNG for reproducible results\n\nrng = StableRNG(1234);\n\n# Create a True Gaussian LDS System\n\nFor demonstration, we'll create a ground truth LDS with K=4 latent dimensions. This system will exhibit interesting dynamics like oscillations and decay patterns.\n\nK_true = 4  # True latent dimensionality\nD = 10       # Observation dimensionality\nT = 300;    # Number of time steps\nnothing #hide\n\nCreate interesting dynamics: oscillating + decaying modes\n\nθ = π/12  # Oscillation frequency\nλ = 0.92  # Decay rate\n\ntrue_A = [cos(θ) -sin(θ)  0.0    0.0;\n          sin(θ)  cos(θ)  0.0    0.0;\n          0.0     0.0     λ      0.0;\n          0.0     0.0     0.0    0.85*λ];\n\ntrue_Q = 0.05 * Matrix(I(K_true)); # Process noise covariance\ntrue_b = zeros(K_true)\n\nRandom.seed!(rng, 42) # Observation matrix - each latent dimension affects multiple observations\ntrue_C = randn(rng, D, K_true) * 0.6;\ntrue_d = zeros(D)\n\ntrue_R = 0.1 * Matrix(I(D)); # Observation noise covariance\n\ntrue_μ0 = zeros(K_true) # Initial state parameters\ntrue_Σ0 = 0.1 * Matrix(I(K_true));\n\ntrue_lds = LinearDynamicalSystem(\n    GaussianStateModel(true_A, true_Q, true_b, true_μ0, true_Σ0),\n    GaussianObservationModel(true_C, true_R, true_d),\n    K_true,\n    D,\n    fill(true, 6)\n);\n\nlatent_states, observations = rand(rng, true_lds; tsteps=T, ntrials=1); # Generate ground truth data\nnothing #hide\n\nVisualize the true latent dynamics and observations\n\np1 = plot(layout=(2,2), size=(1000, 600))\n\nplot!(1:T, latent_states[1, :], label=\"Latent 1 (cos)\",\n      linewidth=2, subplot=1, title=\"Oscillating Modes\")\nplot!(1:T, latent_states[2, :], label=\"Latent 2 (sin)\",\n      linewidth=2, subplot=1)\n\nplot!(1:T, latent_states[3, :], label=\"Latent 3 (decay)\",\n      linewidth=2, subplot=2, title=\"Decaying Modes\")\nplot!(1:T, latent_states[4, :], label=\"Latent 4 (decay)\",\n      linewidth=2, subplot=2)\n\nplot!(1:T, observations[1, :], label=\"Obs 1\", alpha=0.7, subplot=3, title=\"Observations 1-3\")\nplot!(1:T, observations[2, :], label=\"Obs 2\", alpha=0.7, subplot=3)\nplot!(1:T, observations[3, :], label=\"Obs 3\", alpha=0.7, subplot=3)\nplot!(1:T, observations[4, :], label=\"Obs 4\", alpha=0.7, subplot=4, title=\"Observations 4-6\")\nplot!(1:T, observations[5, :], label=\"Obs 5\", alpha=0.7, subplot=4)\nplot!(1:T, observations[6, :], label=\"Obs 6\", alpha=0.7, subplot=4)\n\n# Prepare Data for Cross-Validation\ny_data = reshape(observations, D, T, 1)  # (obs_dim, tsteps, ntrials)\n\n# Cross-Validation Setup\nK_candidates = 1:8  # Test latent dimensions from 1 to 8\nn_folds = 5         # Number of CV folds\nfold_size = T ÷ n_folds;\nnothing #hide\n\nStorage for CV results\n\ncv_scores = zeros(length(K_candidates), n_folds)\ncv_mean = zeros(length(K_candidates))\ncv_std = zeros(length(K_candidates));\n\nprintln(\"Starting Cross-Validation for Model Selection...\")\nprintln(\"=\"^60)\n\n# Perform K-Fold Cross-Validation\nfor (k_idx, K) in enumerate(K_candidates)\n    println(\"Testing K = $K...\")\n\n    fold_scores = zeros(n_folds)\n\n    for fold in 1:n_folds\n        val_start = (fold - 1) * fold_size + 1\n        val_end = min(fold * fold_size, T)\n\n        train_indices = vcat(1:(val_start-1), (val_end+1):T)\n        val_indices = val_start:val_end\n\n        y_train = y_data[:, train_indices, :]\n        y_val = y_data[:, val_indices, :]\n\n\n        A_init = 0.9 * Matrix(I(K)) + 0.1 * randn(rng, K, K)\n        Q_init = 0.1 * Matrix(I(K))\n        b_init = zeros(K)\n        C_init = randn(rng, D, K) * 0.5\n        R_init = 0.2 * Matrix(I(D))\n        d_init = zeros(D)\n        μ0_init = zeros(K)\n        Σ0_init = 0.1 * Matrix(I(K))\n\n        lds_candidate = LinearDynamicalSystem(\n            GaussianStateModel(A_init, Q_init, b_init, μ0_init, Σ0_init),\n            GaussianObservationModel(C_init, R_init, d_init),\n            K,\n            D,\n            fill(true, 6)  # Fit all parameters\n        )\n\n        try\n            lls, _ = fit!(lds_candidate, y_train; max_iter=200, tol=1e-6, progress=false);\n\n            x_val, _ = smooth(lds_candidate, y_val[:, :, 1])\n            val_ll = loglikelihood(x_val, lds_candidate, y_val[:, :, 1])\n\n            fold_scores[fold] = sum(val_ll) / length(val_indices)  # Normalize by sequence length\n\n        catch e\n            println(\"  Warning: Fold $fold failed for K=$K: $e\")\n            fold_scores[fold] = -Inf\n        end\n    end\n\n    cv_scores[k_idx, :] = fold_scores\n    cv_mean[k_idx] = mean(fold_scores)\n    cv_std[k_idx] = std(fold_scores)\n\n    @printf(\"  K=%d: CV Score = %.3f ± %.3f\\n\", K, cv_mean[k_idx], cv_std[k_idx])\nend\n\n# Find Optimal K\nbest_k_idx = argmax(cv_mean)\nbest_K = K_candidates[best_k_idx]\n\nprintln(\"\\n\" * \"=\"^60)\nprintln(\"CROSS-VALIDATION RESULTS:\")\nprintln(\"=\"^60)\n@printf(\"True K: %d\\n\", K_true)\n@printf(\"Best K: %d (CV Score: %.3f ± %.3f)\\n\", best_K, cv_mean[best_k_idx], cv_std[best_k_idx])\nprintln()\n\np2 = plot(K_candidates, cv_mean;\n    yerror = cv_std,\n    marker = :circle,\n    markersize = 6,\n    linewidth = 2,\n    xlabel = \"Latent Dimensionality (K)\",\n    ylabel = \"Cross-Validation Score\",\n    title  = \"Model Selection via Cross-Validation\",\n    legend = false,\n    size   = (800, 500),\n)\n\nvline!([K_true];  linestyle=:dash, color=:green, linewidth=2, label=\"\")\nvline!([best_K];  linestyle=:dot,  color=:red,   linewidth=2, label=\"\")\n\nyr = extrema(cv_mean)\ny1 = yr[2] - 0.05*(yr[2] - yr[1])\ny2 = yr[2] - 0.15*(yr[2] - yr[1])\n\nannotate!( (K_true,  y1, text(\"True K=$(K_true)\",     :green, 10)),\n           (best_K, y2, text(\"Selected K=$(best_K)\", :red,   10)) )\n\nInitialize final model\n\nA_final = 0.9 * Matrix(I(best_K)) + 0.1 * randn(rng, best_K, best_K)\nQ_final = 0.1 * Matrix(I(best_K))\nb_final = zeros(best_K)\nC_final = randn(rng, D, best_K) * 0.5\nR_final = 0.2 * Matrix(I(D))\nμ0_final = zeros(best_K)\nΣ0_final = 0.1 * Matrix(I(best_K))\n\nfinal_lds = LinearDynamicalSystem(\n    GaussianStateModel(A_final, Q_final, b_final, μ0_final, Σ0_final),\n    GaussianObservationModel(C_final, R_final, true_d),\n    best_K,\n    D,\n    fill(true, 6)\n)\n\nFit on full dataset\n\nfinal_lls, _ = fit!(final_lds, y_data; max_iter=500, tol=1e-8)\n\nCompare Learned vs True Dynamics Use the correct input format for smooth function (needs 3D array)\n\nx_learned, P_learned = smooth(final_lds, y_data)\n\nplt1 = plot(\n    1:length(final_lls), final_lls,\n    linewidth=2,\n    xlabel=\"EM Iteration\",\n    ylabel=\"Log-Likelihood\",\n    title=\"Learning Curve (Final Model)\"\n)\n\nn_plot = min(4, best_K, K_true)\ncolors = [:blue, :red, :green, :orange]\n\nplt2 = plot(title=\"True vs Learned Latent Dynamics\", xlabel=\"Time\", ylabel=\"Latent State Value\")\nfor i in 1:n_plot\n    if i <= size(latent_states, 1)\n        plot!(plt2, 1:T, latent_states[i, :],\n              label=\"True Latent $i\", color=colors[i],\n              linestyle=:solid, linewidth=2)\n    end\n    if i <= size(x_learned, 1)\n        plot!(plt2, 1:T, x_learned[i, :],\n              label=\"Learned Latent $i\", color=colors[i],\n              linestyle=:dash, linewidth=2)\n    end\nend\n\np3 = plot(plt1, plt2, layout = @layout([a; b]), size=(1000,600))\n\nCompute reconstruction error x_learned is now (latent_dim, tsteps, 1), so we need to handle the singleton trial dimension\n\nx_learned = x_learned[:, :, 1]\n\ny_pred = final_lds.obs_model.C * x_learned\nreconstruction_error = mean((observations - y_pred).^2)\n\n@printf(\"Reconstruction MSE: %.6f\\n\", reconstruction_error)\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"EmissionModels/#What-are-Emission-Models?","page":"Emission Models","title":"What are Emission Models?","text":"Emission models describe how observations are generated from latent states in a state space model. These models define the conditional distribution of the observed data given the hidden state or input features. In StateSpaceDynamics.jl, a flexible suite of emission models is supported, including both simple parametric distributions and regression-based models.\n\nAt a high level, emission models encode:\n\nThe distribution of observations (e.g., Gaussian, Poisson, Bernoulli)\nHow observations relate to inputs or latent states, either directly or via regression","category":"section"},{"location":"EmissionModels/#Gaussian-Emission-Model","page":"Emission Models","title":"Gaussian Emission Model","text":"The GaussianEmission is a basic model where the observations are drawn from a multivariate normal distribution with a fixed mean and covariance.\n\ny_t sim mathcalN(mu Sigma)\n\nThis emission model is often used when the observed data is real-valued and homoscedastic.","category":"section"},{"location":"EmissionModels/#Regression-Based-Emission-Models","page":"Emission Models","title":"Regression-Based Emission Models","text":"Regression-based emissions allow the output to depend on an input matrix Phi. The regression relationship is defined by a coefficient matrix beta, optionally with an intercept and regularization.","category":"section"},{"location":"EmissionModels/#Gaussian-Regression-Emission","page":"Emission Models","title":"Gaussian Regression Emission","text":"In the GaussianRegressionEmission, the outputs are real-valued and modeled via linear regression with additive Gaussian noise.\n\ny_t sim mathcalN(Phi_t beta Sigma)","category":"section"},{"location":"EmissionModels/#Bernoulli-Regression-Emission","page":"Emission Models","title":"Bernoulli Regression Emission","text":"The BernoulliRegressionEmission is appropriate for binary data. The probability of success is modeled via a logistic function.\n\np(y_t = 1 mid Phi_t) = sigma(Phi_t beta)\n\nWhere sigma(z) = 1  (1 + e^-z) is the logistic function.","category":"section"},{"location":"EmissionModels/#Poisson-Regression-Emission","page":"Emission Models","title":"Poisson Regression Emission","text":"The PoissonRegressionEmission is ideal for count data, such as spike counts in neuroscience. It models the intensity of the Poisson distribution as an exponential function of the linear predictors.\n\ny_t sim textPoisson(lambda_t) quad lambda_t = exp(Phi_t beta)","category":"section"},{"location":"EmissionModels/#Autoregressive-Emission-Models","page":"Emission Models","title":"Autoregressive Emission Models","text":"The AutoRegressionEmission models the observation at time t as depending on previous observations (i.e., an autoregressive structure), using a wrapped GaussianRegressionEmission.\n\ny_t sim mathcalN(sum_i=1^p A_i y_t-i Sigma)\n\nWhere p is the autoregressive order and A_i are regression weights.\n\nThis model is useful when modeling temporal dependencies in the emission process, independent of latent dynamics.","category":"section"},{"location":"EmissionModels/#Fitting-Regression-Emission-Models","page":"Emission Models","title":"Fitting Regression Emission Models","text":"All regression-based emissions can be fitted using maximum likelihood with optional weights and L2 regularization. Internally, StateSpaceDynamics.jl formulates this as an optimization problem, solved using gradient-based methods (e.g., LBFGS).","category":"section"},{"location":"EmissionModels/#StateSpaceDynamics.EmissionModel","page":"Emission Models","title":"StateSpaceDynamics.EmissionModel","text":"Base type hierarchy for emission models. Each emission model must implement:\n\nsample()\nloglikelihood()\nfit!()\n\n\n\n\n\n","category":"type"},{"location":"EmissionModels/#StateSpaceDynamics.RegressionEmission","page":"Emission Models","title":"StateSpaceDynamics.RegressionEmission","text":"Base type hierarchy for regression emission models.\n\n\n\n\n\n","category":"type"},{"location":"EmissionModels/#StateSpaceDynamics.GaussianEmission","page":"Emission Models","title":"StateSpaceDynamics.GaussianEmission","text":"mutable struct GaussianEmission <: EmissionModel\n\nGaussianEmission model with mean and covariance.\n\n\n\n\n\n","category":"type"},{"location":"EmissionModels/#StateSpaceDynamics.loglikelihood-Union{Tuple{T}, Tuple{GaussianEmission, AbstractMatrix{T}}} where T<:Real","page":"Emission Models","title":"StateSpaceDynamics.loglikelihood","text":"loglikelihood(model::GaussianEmission, Y::AbstractMatrix{T}) where {T<:Real}\n\nCalculate the log likelihood of the data Y given the Gaussian emission model.\n\n\n\n\n\n","category":"method"},{"location":"EmissionModels/#Base.rand-Tuple{GaussianEmission}","page":"Emission Models","title":"Base.rand","text":"Random.rand(model::GaussianEmission; kwargs...)\nRandom.rand(rng::AbstractRNG, model::GaussianEmission; n::Int=1)\n\nGenerate random samples from  a Gaussian emission model.\n\n\n\n\n\n","category":"method"},{"location":"EmissionModels/#StateSpaceDynamics.fit!-Union{Tuple{T}, Tuple{GaussianEmission, AbstractMatrix{T}}, Tuple{GaussianEmission, AbstractMatrix{T}, AbstractVector{T}}} where T<:Real","page":"Emission Models","title":"StateSpaceDynamics.fit!","text":"function fit!(model::GaussianEmission,\n        Y::AbstractMatrix{T},\n        w::AbstractVector{T}=ones(size(Y, 1))) where {T<:Real}\n\nFit a GaussianEmission model to the data Y weighted by weights w.\n\n\n\n\n\n","category":"method"},{"location":"EmissionModels/#StateSpaceDynamics.GaussianRegressionEmission","page":"Emission Models","title":"StateSpaceDynamics.GaussianRegressionEmission","text":"GaussianRegressionEmission\n\nStore a Gaussian regression Emission model.\n\nFields\n\ninput_dim::Int: Dimension of the input data.\noutput_dim::Int: Dimension of the output data.\ninclude_intercept::Bool: Whether to include an intercept term; if true, the first column   of β is assumed to be the intercept/bias.\nβ::AbstractMatrix{<:Real} = if include_intercept zeros(input_dim + 1, output_dim) else   zeros(input_dim, output_dim) end: Coefficient matrix of the model. Shape inputdim by   outputdim. The first row are the intercept terms, if included.\nΣ::AbstractMatrix{<:Real}: Covariance matrix of the model.\nλ:<Real: Regularization parameter.\n\n\n\n\n\n","category":"type"},{"location":"EmissionModels/#Base.rand-Tuple{GaussianRegressionEmission, Union{Matrix{<:Real}, Vector{<:Real}}}","page":"Emission Models","title":"Base.rand","text":"Random.rand(model::GaussianRegressionEmission, Φ::Union{Matrix{<:Real},Vector{<:Real}})\nRandom.rand(\n    rng::AbstractRNG,\n    model::GaussianRegressionEmission,\n    Φ::Union{Matrix{<:Real},Vector{<:Real}}\n)\n\nGenerate samples from a Gaussian regression model.\n\n\n\n\n\n","category":"method"},{"location":"EmissionModels/#StateSpaceDynamics.loglikelihood-Union{Tuple{T}, Tuple{GaussianRegressionEmission, AbstractMatrix{T}, AbstractMatrix{T}}, Tuple{GaussianRegressionEmission, AbstractMatrix{T}, AbstractMatrix{T}, Union{Nothing, AbstractVector{T}}}} where T<:Real","page":"Emission Models","title":"StateSpaceDynamics.loglikelihood","text":"loglikelihood(model::GaussianRegressionEmission,\n    Φ::AbstractMatrix{T},\n    Y::AbstractMatrix{T},\n    w::AbstractVector{T}=ones(size(Y, 1))) where {T<:Real}\n\nCalculate the log likelihood of the data Y given the Gaussian regression emission model and the input features Φ.\n\n\n\n\n\n","category":"method"},{"location":"EmissionModels/#StateSpaceDynamics.BernoulliRegressionEmission","page":"Emission Models","title":"StateSpaceDynamics.BernoulliRegressionEmission","text":"BernoulliRegressionEmission\n\nStore a Bernoulli regression model.\n\nFields\n\ninput_dim::Int: Dimensionality of the input data.\noutput_dim::Int: Dimensionality of the output data.\nβ::AbstractMatrix{<:Real}: Bernoulli regression coefficients.\ninclude_intercept::Bool: Whether to include an intercept term.\nλ<:Real: L2 Regularization parameter.\n\n```\n\n\n\n\n\n","category":"type"},{"location":"EmissionModels/#Base.rand-Tuple{BernoulliRegressionEmission, Union{Matrix{<:Real}, Vector{<:Real}}}","page":"Emission Models","title":"Base.rand","text":"Random.rand(\n    model::BernoulliRegressionEmission,\n    Φ::Union{Matrix{<:Real},Vector{<:Real}}\n)\nRandom.rand(\n    rng::AbstractRNG,\n    model::BernoulliRegressionEmission,\n    Φ::Union{Matrix{<:Real},Vector{<:Real}}\n)\n\nGenerate samples from a Bernoulli regression emission.\n\n\n\n\n\n","category":"method"},{"location":"EmissionModels/#StateSpaceDynamics.loglikelihood","page":"Emission Models","title":"StateSpaceDynamics.loglikelihood","text":"function loglikelihood(\n    model::BernoulliRegressionEmission,\n    Φ::AbstractMatrix{T1},\n    Y::AbstractMatrix{T2},\n    w::AbstractVector{T3}=ones(size(Y, 1))\n) where {T1<:Real, T2<:Real, T3<:Real}\n\nCalculate the log likelihood of the data Y given the Bernoulli regression emission model and the input features Φ. Optionally, a vector of weights w can be provided.\n\n\n\n\n\n","category":"function"},{"location":"EmissionModels/#StateSpaceDynamics.PoissonRegressionEmission","page":"Emission Models","title":"StateSpaceDynamics.PoissonRegressionEmission","text":"PoissonRegressionEmission\n\nA Poisson regression model.\n\nFields\n\ninput_dim::Int: Dimensionality of the input data.\noutput_dim::Int: Dimensionality of the output data.\nβ::AbstractMatrix{<:Real}: The regression coefficients matrix.\ninclude_intercept::Bool: Whether to include a regression intercept.\nλ::Real;: L2 Regularization parameter.\n\n\n\n\n\n","category":"type"},{"location":"EmissionModels/#Base.rand-Tuple{PoissonRegressionEmission, Union{Matrix{<:Real}, Vector{<:Real}}}","page":"Emission Models","title":"Base.rand","text":"Random.rand(\n    model::PoissonRegressionEmission,\n    Φ::Union{Matrix{<:Real},Vector{<:Real}}\n)\nRandom.rand(\n    rng::AbstractRNG,\n    model::PoissonRegressionEmission,\n    Φ::Union{Matrix{<:Real},Vector{<:Real}}\n)\n\nGenerate samples from a Poisson regression emission model.\n\n\n\n\n\n","category":"method"},{"location":"EmissionModels/#StateSpaceDynamics.loglikelihood-2","page":"Emission Models","title":"StateSpaceDynamics.loglikelihood","text":"loglikelihood(\n    model::PoissonRegressionEmission,\n    Φ::AbstractMatrix{T1},\n    Y::AbstractMatrix{T2},\n    w::AbstractVector{T3}=ones(size(Y, 1))\n) where {T1<:Real, T2<:Real, T3<:Real}\n\nCalculate the log-likelihood of a Poisson regression model.\n\n\n\n\n\n","category":"function"},{"location":"EmissionModels/#StateSpaceDynamics.AutoRegressionEmission","page":"Emission Models","title":"StateSpaceDynamics.AutoRegressionEmission","text":"AutoRegressionEmission <: EmissionModel\n\nStore an autoregressive emission model, which wraps around a GaussianRegressionEmission.\n\nFields\n\noutput_dim::Int: The dimensionality of the output data\norder::Int: The order of the Autoregressive process\ninnerGaussianRegression::GaussianRegressionEmission: The underlying Gaussian regression   model used for the emissions.\n\n\n\n\n\n","category":"type"},{"location":"EmissionModels/#Base.rand-Tuple{AutoRegressionEmission, Matrix{<:Real}}","page":"Emission Models","title":"Base.rand","text":"Random.rand(model::AutoRegressionEmission, X::Matrix{<:Real})\nRandom.rand(rng::AbstractRNG, model::AutoRegressionEmission, X::Matrix{<:Real})\n\nGenerate samples from an autoregressive emission model.\n\n\n\n\n\n","category":"method"},{"location":"EmissionModels/#StateSpaceDynamics.loglikelihood-Union{Tuple{T}, Tuple{AutoRegressionEmission, AbstractMatrix{T}, AbstractMatrix{T}}, Tuple{AutoRegressionEmission, AbstractMatrix{T}, AbstractMatrix{T}, Union{Nothing, AbstractVector{T}}}} where T<:Real","page":"Emission Models","title":"StateSpaceDynamics.loglikelihood","text":"loglikelihood(\n    model::AutoRegressionEmission,\n    X::AbstractMatrix{T},\n    Y::AbstractMatrix{T},\n    w::Vector{T}=ones(size(Y, 1))\n) where {T<:Real}\n\nCalculate the log likelihood of the data Y given the autoregressive emission model and the previous observations X.\n\n\n\n\n\n","category":"method"},{"location":"EmissionModels/#StateSpaceDynamics.fit!-Union{Tuple{T3}, Tuple{T2}, Tuple{T1}, Tuple{RegressionEmission, AbstractMatrix{T1}, AbstractMatrix{T2}}, Tuple{RegressionEmission, AbstractMatrix{T1}, AbstractMatrix{T2}, AbstractVector{T3}}} where {T1<:Real, T2<:Real, T3<:Real}","page":"Emission Models","title":"StateSpaceDynamics.fit!","text":"fit!(\n    model::RegressionEmission,\n    X::AbstractMatrix{T1},\n    y::AbstractMatrix{T2},\n    w::AbstractVector{T3}=ones(size(y, 1))\n) where {T1<:Real, T2<:Real, T3<:Real}\n\nFit a regression emission model give input data X, output data y, and weights w.\n\nArguments\n\n- `model::RegressionEmission`: A regression emission model.\n- `X::AbstractMatrix{<:Real}:`: Input data.\n- `y::AbstractMatrix{<:Real}`: Output data.\n- `w::AbstractVector{<:Real}`: Weights to define each point's contribution to the fit.\n\nReturns\n\n- `model::RegressionEmission`: The regression model with the newly updated parameters.\n\n\n\n\n\n","category":"method"},{"location":"LinearDynamicalSystems/#What-is-a-Linear-Dynamical-System?","page":"Linear Dynamical Systems","title":"What is a Linear Dynamical System?","text":"A Linear Dynamical System (LDS) is a mathematical model used to describe how a system evolves over time. These systems are a subset of state-space models, where the hidden state dynamics are continuous. What makes these models linear is that the latent dynamics evolve according to a linear function of the previous state. The observations, however, can be related to the hidden state through a nonlinear link function.\n\nAt its core, an LDS defines:\n\nA state transition function: how the internal state evolves from one time step to the next.\nAn observation function: how the internal state generates the observed data.","category":"section"},{"location":"LinearDynamicalSystems/#The-Gaussian-Linear-Dynamical-System","page":"Linear Dynamical Systems","title":"The Gaussian Linear Dynamical System","text":"The Gaussian Linear Dynamical System — typically just referred to as an LDS — is a specific type of linear dynamical system where both the state transition and observation functions are linear, and all noise is Gaussian.\n\nThe generative model is given by:\n\nbeginaligned\n    x_t sim mathcalN(A x_t-1 Q) \n    y_t sim mathcalN(C x_t R)\nendaligned\n\nWhere:\n\nx_t is the hidden state at time t\ny_t is the observed data at time t  \nA is the state transition matrix\nC is the observation matrix\nQ is the process noise covariance\nR is the observation noise covariance\nb and d are bias terms\n\nThis can equivalently be written in equation form:\n\nbeginaligned\n    x_t = A x_t-1 + b + epsilon_t \n    y_t = C x_t + d + eta_t\nendaligned\n\nWhere:\n\nε_t sim N(0 Q) is the process noise\nη_t sim N(0 R) is the observation noise","category":"section"},{"location":"LinearDynamicalSystems/#The-Poisson-Linear-Dynamical-System","page":"Linear Dynamical Systems","title":"The Poisson Linear Dynamical System","text":"The Poisson Linear Dynamical System is a variant of the LDS where the observations are modeled as counts. This is useful in fields like neuroscience where we are often interested in modeling spike count data. To relate the spiking data to the Gaussian latent variable, we use a nonlinear link function, specifically the exponential function. \n\nThe generative model is given by: \n\nbeginaligned\n    x_t sim mathcalN(A x_t-1 Q) \n    y_t sim textPoisson(exp(Cx_t + b))\nendaligned\n\nWhere b is a bias term.","category":"section"},{"location":"LinearDynamicalSystems/#Sampling-from-Linear-Dynamical-Systems","page":"Linear Dynamical Systems","title":"Sampling from Linear Dynamical Systems","text":"You can generate synthetic data from fitted LDS models:","category":"section"},{"location":"LinearDynamicalSystems/#Inference-in-Linear-Dynamical-Systems","page":"Linear Dynamical Systems","title":"Inference in Linear Dynamical Systems","text":"In StateSpaceDynamics.jl, we directly maximize the complete-data log-likelihood function with respect to the latent states given the data and the parameters of the model. In other words, the maximum a priori (MAP) estimate of the latent state path is:\n\nundersetxtextargmax  left log p(x_0) + sum_t=2^T log p(x_t mid x_t-1) + sum_t=1^T log p(y_t mid x_t) right\n\nThis MAP estimation approach has the same computational complexity as traditional Kalman filtering and smoothing — mathcalO(T) — but is significantly more flexible. Notably, it can handle nonlinear observations and non-Gaussian noise while still yielding exact MAP estimates, unlike approximate techniques such as the Extended Kalman Filter (EKF) or Unscented Kalman Filter (UKF).","category":"section"},{"location":"LinearDynamicalSystems/#Newton's-Method-for-Latent-State-Optimization","page":"Linear Dynamical Systems","title":"Newton's Method for Latent State Optimization","text":"To find the MAP trajectory, we iteratively optimize the latent states using Newton's method. The update equation at each iteration is:\n\nx^(i+1) = x^(i) - left nabla^2 mathcalL(x^(i)) right^-1 nabla mathcalL(x^(i))\n\nWhere:\n\nmathcalL(x) is the complete-data log-likelihood:\n\nmathcalL(x) = log p(x_0) + sum_t=2^T log p(x_t mid x_t-1) + sum_t=1^T log p(y_t mid x_t)\n\nnabla mathcalL(x) is the gradient of the full log-likelihood with respect to all latent states\nnabla^2 mathcalL(x) is the Hessian of the full log-likelihood\n\nThis update is performed over the entire latent state sequence x_1T, and repeated until convergence.\n\nFor Gaussian models, mathcalL(x) is quadratic and Newton's method converges in a single step — recovering the exact Kalman smoother solution. For non-Gaussian models, the Hessian is not constant and the optimization is more complex. However, the MAP estimate can still be computed efficiently using the same approach as the optimization problem is still convex.","category":"section"},{"location":"LinearDynamicalSystems/#Laplace-Approximation-of-Posterior-for-Non-Conjugate-Observation-Models","page":"Linear Dynamical Systems","title":"Laplace Approximation of Posterior for Non-Conjugate Observation Models","text":"In the case of non-Gaussian observations, we can use a Laplace approximation to compute the posterior distribution of the latent states. For Gaussian observations (which are conjugate with the Gaussian state model), the posterior is also Gaussian and is the exact posterior. However, for non-Gaussian observations, we can approximate the posterior using a Gaussian distribution centered at the MAP estimate of the latent states. This approximation is given by:\n\np(x mid y) approx mathcalN(x^* -left nabla^2 mathcalL(x^*) right^-1)\n\nWhere:\n\nx^* is the MAP estimate of the latent states\nnabla^2 mathcalL(x^*) is the Hessian of the log-likelihood at the MAP estimate\n\nDespite the requirement of inverting a Hessian of dimension (d times T) times (d times T), this is still computationally efficient, as the Markov structure of the model renders the Hessian block-tridiagonal, and thus the inversion is tractable.","category":"section"},{"location":"LinearDynamicalSystems/#Learning-in-Linear-Dynamical-Systems","page":"Linear Dynamical Systems","title":"Learning in Linear Dynamical Systems","text":"Given the latent structure of state-space models, we must rely on either the Expectation-Maximization (EM) or Variational Inference (VI) approaches to learn the parameters of the model. StateSpaceDynamics.jl supports both EM and VI. For LDS models, we can use Laplace EM, where we approximate the posterior of the latent state path using the Laplace approximation as outlined above. Using these approximate posteriors (or exact ones in the Gaussian case), we can apply closed-form updates for the model parameters.\n\nwarning: Identifiability caveats in LDS\nLDS parameters are not uniquely identifiable. For any invertible matrix S, the reparameterizationbeginaligned\nx_t = S x_t\nA = S A S^-1\nC = C S^-1\nQ = S Q S^top\nR = R\nendalignedyields the same likelihood. Practical consequences:Scale/rotation ambiguity: the latent space can be arbitrarily scaled/rotated.\nSign & permutation flips: columns of C (and corresponding rows/cols of A) can swap or flip signs with no change in fit.Common remediesFix a convention for the latent scale, e.g. set Q = I or constrain mathrmdiag(Q)=1.\nEncourage a canonical orientation, e.g. enforce orthonormal columns in C (up to sign) after each M-step. (Not yet implemented)\nWhen comparing fits across runs, align parameters via a Procrustes or Hungarian matching step.These issues affect parameter interpretability but not predictive performance; be cautious when interpreting individual entries of A, C, or Q.","category":"section"},{"location":"LinearDynamicalSystems/#Inverse-Wishart-Priors-on-Covariances-(MAP)","page":"Linear Dynamical Systems","title":"Inverse-Wishart Priors on Covariances (MAP)","text":"To encourage well-conditioned covariance estimates, StateSpaceDynamics.jl supports Inverse-Wishart (IW) priors on the covariance matrices of a Linear Dynamical System.   These can be used to impose shrinkage toward a target scale, yielding maximum a posteriori (MAP) estimates instead of pure MLEs.\n\nYou can attach an IW prior to:\n\nThe process noise covariance Q_prior\nThe initial state covariance P0_prior\nThe observation noise covariance R_prior (Gaussian models only)","category":"section"},{"location":"LinearDynamicalSystems/#Definition","page":"Linear Dynamical Systems","title":"Definition","text":"For a covariance matrix Sigma in mathbbR^dtimes d,\n\nSigma sim textIW(Psi nu)\nqquad\np(Sigma)propto Sigma^-(nu+d+1)2expBig-tfrac12operatornametr(PsiSigma^-1)Big\n\nPsi is the scale matrix (positive-definite).  \nnu is the degrees of freedom.   A proper mode exists when nu  d+1.\n\nGiven n effective samples and sample statistic S, the posterior is\n\nSigmamidtextdatasimtextIW(Psi+Snu+n)\n\nand the MAP (mode) update used internally is\n\nwidehatSigma_textMAP\n=fracPsi+Snu+n+d+1","category":"section"},{"location":"LinearDynamicalSystems/#Example:-Adding-IW-Priors-to-an-LDS","page":"Linear Dynamical Systems","title":"Example: Adding IW Priors to an LDS","text":"using LinearAlgebra, Random, StateSpaceDynamics\n\nrng = MersenneTwister(42)\nD, P = 3, 4\n\n# Proper SPD scale matrices (avoid UniformScaling)\nΨQ  = diagm(0 => fill(0.01, D))\nΨP0 = diagm(0 => fill(0.01, D))\nΨR  = diagm(0 => fill(0.01, P))\n\nQprior  = IWPrior(Ψ = ΨQ,  ν = D + 3.0)\nP0prior = IWPrior(Ψ = ΨP0, ν = D + 3.0)\nRprior  = IWPrior(Ψ = ΨR,  ν = P + 3.0)\n\n# Gaussian LDS\nA = 0.9I + 0.05randn(rng, D, D)\nQ = Matrix(I, D, D) .* 0.3\nb = zeros(D); x0 = zeros(D); P0 = Matrix(I, D, D) .* 0.8\n\nC = randn(rng, P, D)\nR = Matrix(I, P, P) .* 0.25\nd = 0.1 .* randn(rng, P)\n\ngsm = GaussianStateModel(A=A, Q=Q, b=b, x0=x0, P0=P0,\n                         Q_prior=Qprior, P0_prior=P0prior)\ngom = GaussianObservationModel(C=C, R=R, d=d, R_prior=Rprior)\nlds = LinearDynamicalSystem(gsm, gom)\n\nX, Y = rand(rng, lds; tsteps=100, ntrials=5)\nfit!(lds, Y; max_iter=20, progress=false)","category":"section"},{"location":"LinearDynamicalSystems/#Effect-on-Learning","page":"Linear Dynamical Systems","title":"Effect on Learning","text":"When a prior is present, the M-step uses the MAP mode formula above.  \nThe reported ELBO includes IW log-prior terms (up to constants), so convergence still tracks the true MAP objective.  \nWith small datasets or high-dimensional states, the priors keep Q, P_0, and R positive-definite and well-conditioned.","category":"section"},{"location":"LinearDynamicalSystems/#Choosing-\\Psi-and-\\nu","page":"Linear Dynamical Systems","title":"Choosing Psi and nu","text":"Goal Typical choice Notes\nMild shrinkage Psi = 001I, nu = d+3 Gentle pull toward small covariances\nStrong regularization Larger nu Acts like adding pseudo-samples\nData-scaled prior Psi ≈ empirical covariance Centers shrinkage around realistic scale\n\nTip: In Julia, I is a UniformScaling (not a matrix).   Use Matrix(I, d, d) or diagm(0 => fill(..., d)) to build Ψ.","category":"section"},{"location":"LinearDynamicalSystems/#StateSpaceDynamics.LinearDynamicalSystem","page":"Linear Dynamical Systems","title":"StateSpaceDynamics.LinearDynamicalSystem","text":"LinearDynamicalSystem{T<:Real, S<:AbstractStateModel{T}, O<:AbstractObservationModel{T}}\n\nRepresents a unified Linear Dynamical System with customizable state and observation models.\n\nFields\n\nstate_model::S: The state model (e.g., GaussianStateModel)\nobs_model::O: The observation model (e.g., GaussianObservationModel or   PoissonObservationModel)\nlatent_dim::Int: Dimension of the latent state\nobs_dim::Int: Dimension of the observations\nfit_bool::Vector{Bool}: Vector indicating which parameters to fit during optimization\n\n\n\n\n\n","category":"type"},{"location":"LinearDynamicalSystems/#StateSpaceDynamics.GaussianStateModel","page":"Linear Dynamical Systems","title":"StateSpaceDynamics.GaussianStateModel","text":"GaussianStateModel{T<:Real, M<:AbstractMatrix{T}, V<:AbstractVector{T}}\n\nRepresents the state model of a Linear Dynamical System with Gaussian noise.\n\nFields\n\nA::M: Transition matrix (size latent_dim × latent_dim).\nQ::M: Process noise covariance matrix.\nb::V: Bias vector (length latent_dim).\nx0::V: Initial state mean (length latent_dim).\nP0::M: Initial state covariance (size latent_dim × latent_dim).\nQ_prior::Union{Nothing,IWPrior{T}} = nothing: Optional Inverse-Wishart prior on Q. If set, MAP updates use its mode.\nP0_prior::Union{Nothing,IWPrior{T}} = nothing: Optional Inverse-Wishart prior on P0. If set, MAP updates use its mode.\n\n\n\n\n\n","category":"type"},{"location":"LinearDynamicalSystems/#StateSpaceDynamics.GaussianObservationModel","page":"Linear Dynamical Systems","title":"StateSpaceDynamics.GaussianObservationModel","text":"GaussianObservationModel{T<:Real, M<:AbstractMatrix{T}, V<:AbstractVector{T}}\n\nRepresents the observation model of a Linear Dynamical System with Gaussian noise.\n\nFields\n\nC::M: Observation matrix of size (obs_dim × latent_dim). Maps latent states into   observation space.\nR::M: Observation noise covariance of size (obs_dim × obs_dim).\nd::V: Bias vector of length (obs_dim).\nR_prior::Union{Nothing, IWPrior{T}} = nothing: Optional Inverse-Wishart prior for R.\n\n\n\n\n\n","category":"type"},{"location":"LinearDynamicalSystems/#StateSpaceDynamics.PoissonObservationModel","page":"Linear Dynamical Systems","title":"StateSpaceDynamics.PoissonObservationModel","text":"PoissonObservationModel{\n    T<:Real,\n    M<:AbstractMatrix{T},\n    V<:AbstractVector{T}\n} <: AbstractObservationModel{T}\n\nRepresents the observation model of a Linear Dynamical System with Poisson observations.\n\nFields\n\nC::AbstractMatrix{T}: Observation matrix of size (obs_dim × latent_dim). Maps latent   states into observation space.\nlog_d::AbstractVector{T}: Mean firing rate vector (log space) of length (obs_dim).\n\n\n\n\n\n","category":"type"},{"location":"LinearDynamicalSystems/#Base.rand-Tuple{LinearDynamicalSystem}","page":"Linear Dynamical Systems","title":"Base.rand","text":"Random.rand(lds::LinearDynamicalSystem; tsteps::Int, ntrials::Int)\nRandom.rand(rng::AbstractRNG, lds::LinearDynamicalSystem; tsteps::Int, ntrials::Int)\n\nSample from a Linear Dynamical System.\n\n\n\n\n\n","category":"method"},{"location":"LinearDynamicalSystems/#StateSpaceDynamics.smooth","page":"Linear Dynamical Systems","title":"StateSpaceDynamics.smooth","text":"smooth(lds, y::AbstractMatrix)\n\nDirect smoothing for a single trial.\n\nArguments\n\nlds::LinearDynamicalSystem: The model.\ny::AbstractMatrix: Observations (obs_dim × tsteps).\n\nReturns\n\nx_smooth::AbstractMatrix: Smoothed latent means (latent_dim × tsteps).\np_smooth::Array{T,3}: Smoothed latent covariances (latentdim × latentdim × tsteps).\n\n\n\n\n\n","category":"function"},{"location":"LinearDynamicalSystems/#StateSpaceDynamics.fit!-Union{Tuple{O}, Tuple{S}, Tuple{T}, Tuple{LinearDynamicalSystem{T, S, O}, AbstractArray{T, 3}}} where {T<:Real, S<:(GaussianStateModel{T, M, V} where {M<:AbstractMatrix{T}, V<:AbstractVector{T}}), O<:AbstractObservationModel{T}}","page":"Linear Dynamical Systems","title":"StateSpaceDynamics.fit!","text":"fit!(lds, y; max_iter::Int=1000, tol::Real=1e-12)\nwhere {T<:Real, S<:GaussianStateModel{T}, O<:GaussianObservationModel{T}}\n\nFit a Linear Dynamical System using the Expectation-Maximization (EM) algorithm with Kalman smoothing over multiple trials\n\nArguments\n\nlds::LinearDynamicalSystem{T,S,O}: The Linear Dynamical System to be fitted.\ny::AbstractArray{T,3}: Observed data, size(obsdim, Tsteps, n_trials)\n\nKeyword Arguments\n\nmax_iter::Int=1000: Maximum number of EM iterations.\ntol::T=1e-12: Convergence tolerance for log-likelihood change.\n\nReturns\n\nmls::Vector{T}: Vector of log-likelihood values for each iteration.\nparam_diff::Vector{T}: Vector of parameter deltas for each EM iteration.\n\n\n\n\n\n","category":"method"},{"location":"LinearDynamicalSystems/#StateSpaceDynamics.IWPrior","page":"Linear Dynamical Systems","title":"StateSpaceDynamics.IWPrior","text":"IWPrior{T<:Real, M<:AbstractMatrix}\n\nInverse-Wishart prior for a covariance matrix Σ ~ IW(Ψ, ν), with density p(Σ) ∝ |Σ|^{-(ν + d + 1)/2} exp(-½ tr(Ψ Σ^{-1})) for d = size(Σ,1).\n\nFields\n\nΨ::M: Scale matrix (d×d, SPD).\nν::T: Degrees of freedom (must satisfy ν > d + 1 for a proper mode).\n\nNotes\n\nThe MAP update for a posterior IW(Ψ + S, ν + n) is (Ψ + S) / (ν + n + d + 1).\n\n\n\n\n\n","category":"type"},{"location":"MixtureModels/#What-is-a-Mixture-Model?","page":"Mixture Models","title":"What is a Mixture Model?","text":"A mixture model is a probabilistic model that represents a population consisting of multiple subpopulations, where each observation is assumed to come from one of several component distributions. Mixture models are particularly useful for modeling data that exhibits multimodal behavior or comes from heterogeneous sources.\n\nFormally, a mixture model with K components is defined as:\n\nf_mix(x Theta pi) = sum_k=1^K pi_k f_k(x theta_k)\n\nWhere:\n\nf_k(x theta_k) is the k-th component distribution with parameters theta_k\npi_k is the mixing coefficient (or mixing weight) for component k\nTheta = theta_1 ldots theta_K are the component parameters\npi = pi_1 ldots pi_K are the mixing coefficients with sum_k=1^K pi_k = 1 and pi_k geq 0","category":"section"},{"location":"MixtureModels/#Generative-Process","page":"Mixture Models","title":"Generative Process","text":"The generative process for a mixture model can be described as follows:\n\nbeginalign*\n    z_i sim textCat(pi) \n    x_i mid z_i = k sim f_k(x theta_k)\nendalign*\n\nWhere:\n\nz_i is a latent assignment variable indicating which component generated observation x_i\nz_i = k means observation x_i was generated by component k\ntextCat(pi) is the categorical distribution with probabilities pi\n\nThis two-step process first selects a component according to the mixing weights, then generates an observation from that component's distribution.","category":"section"},{"location":"MixtureModels/#Key-Properties","page":"Mixture Models","title":"Key Properties","text":"Identifiability: Mixture models are generally identifiable up to permutation of the component labels. This means that swapping component labels and their associated parameters yields an equivalent model.\n\nModel Selection: The number of components K is typically unknown and must be determined using model selection criteria such as AIC, BIC, or cross-validation.\n\nLatent Structure: The latent variables z_i provide a natural clustering interpretation, where observations are probabilistically assigned to components.","category":"section"},{"location":"MixtureModels/#Gaussian-Mixture-Model","page":"Mixture Models","title":"Gaussian Mixture Model","text":"A Gaussian Mixture Model (GMM) is a mixture model where each component is a multivariate Gaussian distribution. GMMs are among the most widely used mixture models due to their mathematical tractability and flexibility in modeling continuous data.","category":"section"},{"location":"MixtureModels/#Mathematical-Formulation","page":"Mixture Models","title":"Mathematical Formulation","text":"For a GMM with K components in D dimensions, the mixture density is:\n\nf_GMM(x Theta pi) = sum_k=1^K pi_k mathcalN(x mu_k Sigma_k)\n\nWhere each component is a multivariate Gaussian:\n\nmathcalN(x mu_k Sigma_k) = frac1(2pi)^D2 Sigma_k^12 expleft(-frac12(x - mu_k)^T Sigma_k^-1 (x - mu_k)right)\n\nThe parameters for each component k are:\n\nmu_k in mathbbR^D: the mean vector\nSigma_k in mathbbR^D times D: the covariance matrix (positive definite)","category":"section"},{"location":"MixtureModels/#Applications","page":"Mixture Models","title":"Applications","text":"GMMs are particularly effective for:\n\nDensity estimation for continuous multimodal data\nSoft clustering where observations can belong to multiple clusters with different probabilities\nDimensionality reduction when combined with factor analysis\nAnomaly detection by identifying low-probability regions","category":"section"},{"location":"MixtureModels/#Poisson-Mixture-Model","page":"Mixture Models","title":"Poisson Mixture Model","text":"A Poisson Mixture Model (PMM) is designed for modeling count data that exhibits overdispersion or multimodality. Each component follows a Poisson distribution, making it suitable for discrete, non-negative integer observations.","category":"section"},{"location":"MixtureModels/#Mathematical-Formulation-2","page":"Mixture Models","title":"Mathematical Formulation","text":"For a PMM with K components, the mixture density is:\n\nf_PMM(x lambda pi) = sum_k=1^K pi_k textPoisson(x lambda_k)\n\nWhere each component is a Poisson distribution:\n\ntextPoisson(x lambda_k) = fraclambda_k^x e^-lambda_kx\n\nThe parameter for each component k is:\n\nlambda_k  0\n: the rate parameter (both mean and variance of the Poisson distribution)","category":"section"},{"location":"MixtureModels/#Applications-2","page":"Mixture Models","title":"Applications","text":"PMMs are commonly used for:\n\nCount data modeling with heterogeneous populations\nModeling overdispersed count data where variance exceeds the mean\nAnalyzing arrival processes with multiple underlying rates\nBiological applications such as modeling gene expression counts","category":"section"},{"location":"MixtureModels/#Learning-in-Mixture-Models","page":"Mixture Models","title":"Learning in Mixture Models","text":"StateSpaceDynamics.jl implements the Expectation-Maximization (EM) algorithm for parameter estimation in mixture models. EM is an iterative algorithm that finds maximum likelihood estimates in the presence of latent variables.","category":"section"},{"location":"MixtureModels/#Expectation-Maximization-Algorithm","page":"Mixture Models","title":"Expectation-Maximization Algorithm","text":"The EM algorithm alternates between two steps:","category":"section"},{"location":"MixtureModels/#Expectation-Step-(E-step)","page":"Mixture Models","title":"Expectation Step (E-step)","text":"Calculate the posterior probabilities (responsibilities) that each observation belongs to each component:\n\ngamma_ik = p(z_i = k mid x_i theta^(t)) = fracpi_k^(t) f_k(x_i theta_k^(t))sum_j=1^K pi_j^(t) f_j(x_i theta_j^(t))\n\nWhere gamma_ik represents the responsibility of component k for observation x_i.","category":"section"},{"location":"MixtureModels/#Maximization-Step-(M-step)","page":"Mixture Models","title":"Maximization Step (M-step)","text":"Update the parameters by maximizing the expected complete data log-likelihood:\n\nMixing coefficients:\n\npi_k^(t+1) = frac1N sum_i=1^N gamma_ik\n\nFor Gaussian components:\n\nbeginalign*\nmu_k^(t+1) = fracsum_i=1^N gamma_ik x_isum_i=1^N gamma_ik \nSigma_k^(t+1) = fracsum_i=1^N gamma_ik (x_i - mu_k^(t+1))(x_i - mu_k^(t+1))^Tsum_i=1^N gamma_ik\nendalign*\n\nFor Poisson components:\n\nlambda_k^(t+1) = fracsum_i=1^N gamma_ik x_isum_i=1^N gamma_ik","category":"section"},{"location":"MixtureModels/#Convergence-and-Initialization","page":"Mixture Models","title":"Convergence and Initialization","text":"The EM algorithm is guaranteed to converge to a local maximum of the likelihood function. However, the quality of the solution depends heavily on initialization:\n\nRandom initialization: Parameters are randomly initialized\nK-means initialization: Use K-means clustering to initialize component means and mixing weights\nMultiple random starts: Run EM from multiple random initializations and select the best solution","category":"section"},{"location":"MixtureModels/#Model-Evaluation-and-Selection","page":"Mixture Models","title":"Model Evaluation and Selection","text":"","category":"section"},{"location":"MixtureModels/#Log-Likelihood","page":"Mixture Models","title":"Log-Likelihood","text":"The log-likelihood of the data under the fitted model provides a measure of model fit:\n\nell(Theta pi) = sum_i=1^N log left( sum_k=1^K pi_k f_k(x_i theta_k) right)","category":"section"},{"location":"MixtureModels/#Information-Criteria","page":"Mixture Models","title":"Information Criteria","text":"For model selection (choosing the optimal number of components K):\n\nAkaike Information Criterion (AIC):\n\ntextAIC = -2ell(hatTheta hatpi) + 2p\n\nBayesian Information Criterion (BIC):\n\ntextBIC = -2ell(hatTheta hatpi) + p log(N)\n\nWhere p is the number of free parameters in the model.","category":"section"},{"location":"MixtureModels/#Inference-and-Applications","page":"Mixture Models","title":"Inference and Applications","text":"","category":"section"},{"location":"MixtureModels/#Posterior-Probabilities","page":"Mixture Models","title":"Posterior Probabilities","text":"After fitting, the posterior probability that observation x_i belongs to component k is:\n\np(z_i = k mid x_i hatTheta hatpi) = frachatpi_k f_k(x_i hattheta_k)sum_j=1^K hatpi_j f_j(x_i hattheta_j)","category":"section"},{"location":"MixtureModels/#Hard-Assignment","page":"Mixture Models","title":"Hard Assignment","text":"For clustering applications, observations can be assigned to their most likely component:\n\nhatz_i = argmax_k p(z_i = k mid x_i hatTheta hatpi)","category":"section"},{"location":"MixtureModels/#Sampling","page":"Mixture Models","title":"Sampling","text":"New observations can be generated from the fitted mixture model by:\n\nSampling a component k sim textCat(hatpi)\nSampling from that component: x sim f_k(x hattheta_k)","category":"section"},{"location":"MixtureModels/#Practical-Considerations","page":"Mixture Models","title":"Practical Considerations","text":"","category":"section"},{"location":"MixtureModels/#Computational-Complexity","page":"Mixture Models","title":"Computational Complexity","text":"Time complexity: O(NKD cdot textiterations) where N is the number of observations, K is the number of components, and D is the dimensionality\nSpace complexity: O(NK + KD^2) for storing responsibilities and covariance matrices (GMM)","category":"section"},{"location":"MixtureModels/#Common-Issues","page":"Mixture Models","title":"Common Issues","text":"Singular covariance matrices: In GMMs, components may collapse to single points, leading to singular covariance matrices. Regularization techniques include adding a small value to the diagonal.\n\nEmpty components: Some components may receive very little probability mass during EM iterations. This can be addressed by reinitializing empty components.\n\nConvergence to local optima: EM is sensitive to initialization. Multiple random starts and careful initialization strategies are recommended.","category":"section"},{"location":"MixtureModels/#Reference","page":"Mixture Models","title":"Reference","text":"For comprehensive mathematical foundations and advanced topics in mixture models, we recommend:\n\nPattern Recognition and Machine Learning, Chapter 9 by Christopher Bishop\nThe Elements of Statistical Learning, Chapter 6 by Hastie, Tibshirani, and Friedman\nFinite Mixture Models by Geoffrey McLachlan and David Peel","category":"section"},{"location":"MixtureModels/#StateSpaceDynamics.GaussianMixtureModel","page":"Mixture Models","title":"StateSpaceDynamics.GaussianMixtureModel","text":"GaussianMixtureModel\n\nA Gaussian Mixture Model for clustering and density estimation.\n\n\n\n\n\n","category":"type"},{"location":"MixtureModels/#StateSpaceDynamics.GaussianMixtureModel-Tuple{Int64, Int64}","page":"Mixture Models","title":"StateSpaceDynamics.GaussianMixtureModel","text":"GaussianMixtureModel(k::Int, data_dim::Int)\n\nConstructor for GaussianMixtureModel. Initializes Σₖ's covariance matrices to the identity, πₖ to a uniform distribution, and μₖ's means to zeros.\n\n\n\n\n\n","category":"method"},{"location":"MixtureModels/#StateSpaceDynamics.PoissonMixtureModel","page":"Mixture Models","title":"StateSpaceDynamics.PoissonMixtureModel","text":"PoissonMixtureModel\n\nA Poisson Mixture Model for clustering and density estimation.\n\nFields\n\nk::Int: Number of poisson-distributed clusters.\nλₖ::Vector{Float64}: Means of each cluster.\nπₖ::Vector{Float64}: Mixing coefficients for each cluster.\n\n\n\n\n\n","category":"type"},{"location":"MixtureModels/#StateSpaceDynamics.PoissonMixtureModel-Tuple{Int64}","page":"Mixture Models","title":"StateSpaceDynamics.PoissonMixtureModel","text":"PoissonMixtureModel(k::Int)\n\nConstructor for PoissonMixtureModel. Initializes λₖ's means to ones and πₖ to a uniform distribution.\n\n\n\n\n\n","category":"method"},{"location":"MixtureModels/#StateSpaceDynamics.fit!-Tuple{GaussianMixtureModel, Matrix{<:Real}}","page":"Mixture Models","title":"StateSpaceDynamics.fit!","text":"fit!(gmm::GaussianMixtureModel, data::AbstractMatrix{<:Real}; <keyword arguments>)\n\nFits a Gaussian Mixture Model (GMM) to the given data using the Expectation-Maximization (EM) algorithm.\n\nArguments\n\ngmm::GaussianMixtureModel: The Gaussian Mixture Model to be fitted.\ndata::AbstractMatrix{<:Real}: The dataset on which the model will be fitted, where each   row represents a data point.\nmaxiter::Int=50: The maximum number of iterations for the EM algorithm (default: 50).\ntol::Float64=1e-3: The tolerance for convergence. The algorithm stops if the change in   log-likelihood between iterations is less than this value (default: 1e-3).\ninitialize_kmeans::Bool=false: If true, initializes the means of the GMM using K-means++   initialization (default: false).\n\nReturns\n\nclass_probabilities: A matrix where each entry (i, k) represents the probability of the   i-th data point belonging to the k-th component of the mixture model.\n\n\n\n\n\n","category":"method"},{"location":"MixtureModels/#StateSpaceDynamics.fit!-Tuple{PoissonMixtureModel, Matrix{Int64}}","page":"Mixture Models","title":"StateSpaceDynamics.fit!","text":"fit!(\n    pmm::PoissonMixtureModel, data::AbstractMatrix{<:Integer};\n    maxiter::Int=50, tol::Float64=1e-3, initialize_kmeans::Bool=false,\n)\n\nFits a Poisson Mixture Model (PMM) to the given data using the Expectation-Maximization (EM) algorithm.\n\nArguments\n\npmm::PoissonMixtureModel: The Poisson Mixture Model to be fitted.\ndata::AbstractMatrix{<:Integer}: The dataset on which the model will be fitted, where   each row represents a data point.\n\nKeyword Arguments\n\nmaxiter::Int=50: The maximum number of iterations for the EM algorithm (default: 50).\ntol::Float64=1e-3: The tolerance for convergence. The algorithm stops if the change in   log-likelihood between iterations is less than this value (default: 1e-3).\ninitialize_kmeans::Bool=false: If true, initializes the means of the PMM using K-means++   initialization (default: false).\n\nReturns\n\nclass_probabilities: A matrix where each entry (i, k) represents the probability of the   i-th data point belonging to the k-th component of the mixture model.\n\n\n\n\n\n","category":"method"},{"location":"MixtureModels/#StateSpaceDynamics.loglikelihood-Tuple{GaussianMixtureModel, Matrix{<:Real}}","page":"Mixture Models","title":"StateSpaceDynamics.loglikelihood","text":"loglikelihood(gmm::GaussianMixtureModel, data::AbstractMatrix{<:Real})\n\nCompute the log-likelihood of the data given the Gaussian Mixture Model (GMM). The data matrix should be of shape (# observations, # features).\n\nArguments\n\ngmm::GaussianMixtureModel: The Gaussian Mixture Model instance\ndata::AbstractMatrix{<:Real}: data matrix to calculate the Log-Likelihood\n\nReturns\n\nFloat64: The log-likelihood of the data given the model.\n\n\n\n\n\n","category":"method"},{"location":"MixtureModels/#StateSpaceDynamics.loglikelihood-Tuple{PoissonMixtureModel, Matrix{Int64}}","page":"Mixture Models","title":"StateSpaceDynamics.loglikelihood","text":"loglikelihood(pmm::PoissonMixtureModel, data::AbstractMatrix{<:Integer})\n\nCompute the log-likelihood of the data given the Poisson Mixture Model (PMM). The data matrix should be of shape (# features, # obs).\n\nReturns\n\nFloat64: The log-likelihood of the data given the model.\n\n\n\n\n\n","category":"method"},{"location":"tutorials/hmm_identifiability_example/#Understanding-Non-Identifiability-in-Hidden-Markov-Models","page":"HMM Identifiability","title":"Understanding Non-Identifiability in Hidden Markov Models","text":"This hands-on literate tutorial mirrors the LDS/SSM label-indeterminacy example but for HMMs. We will:\n\nBuild a reference HMM and synthesize data.\nShow permutation invariance of the likelihood (log-likelihood is unchanged under state relabelings).\nFit from multiple random initializations to surface label switching.\nAlign states post‑hoc to a reference ordering and outline a simple canonicalization.\nSummarize diagnostics and clarify what is and is not identifiable.\n\nTakeaway. In mixture models and HMMs, state labels are arbitrary. Without constraints or post‑hoc alignment, EM fits from different starts can represent the same model up to a permutation of labels.","category":"section"},{"location":"tutorials/hmm_identifiability_example/#Load-Required-Packages","page":"HMM Identifiability","title":"Load Required Packages","text":"We’ll use StateSpaceDynamics.jl for HMM construction and EM fitting. StableRNGs gives bit‑reproducibility across runs.\n\nusing StateSpaceDynamics\nusing Random\nusing LinearAlgebra\nusing Statistics\nusing StableRNGs\nusing Printf\nusing Distributions\n\nrng = StableRNG(12345);\nnothing #hide","category":"section"},{"location":"tutorials/hmm_identifiability_example/#Create-a-Reference-(\"True\")-Gaussian-Emission-HMM","page":"HMM Identifiability","title":"Create a Reference (\"True\") Gaussian-Emission HMM","text":"We define a simple 3‑state, 1D Gaussian‑emission HMM with well‑separated means. The transition matrix is near‑symmetric with strong self‑transition probability, making states persist for stretches—this helps visualize label switching cleanly.\n\nK = 3\nD = 1\nT = 400\n\nπ_true = fill(1/3, K)  # uniform prior\n\nρ = 0.88                # near-symmetric transitions with strong self-prob\nA_true = fill((1-ρ)/(K-1), K, K)\nfor i in 1:K\n    A_true[i,i] = ρ\nend\n\nμ_true  = [-2.5, 0.0, 2.5]\nσ2_true = fill(0.1, K)\nΣ_true  = [fill(σ2_true[k], D, D) for k in 1:K]\n\nemissions = [GaussianEmission(1, [μ_true[k]], Σ_true[k]) for k in 1:K]\ntrue_hmm = HiddenMarkovModel(A_true, emissions, π_true, K)\n\nGenerate data\n\ns_true, x_true = rand(rng, true_hmm; n=T)","category":"section"},{"location":"tutorials/hmm_identifiability_example/#Permutation-(Label)-Invariance:-Likelihood-is-Unchanged","page":"HMM Identifiability","title":"Permutation (Label) Invariance: Likelihood is Unchanged","text":"The HMM likelihood is invariant to permutation of state labels. If we apply a permutation matrix P to the transition matrix and reorder emissions accordingly, the joint distribution (and hence log-likelihood on data) is identical. We implement a helper permute_states! and verify that the log-likelihood difference is numerically ~0.\n\nfunction permute_states!(m::HiddenMarkovModel, perm::Vector{Int})\n    K = length(perm)\n    P = zeros(eltype(m.A), K, K)\n    for (i,j) in enumerate(perm)   # new i  <- old j\n        P[i,j] = 1\n    end\n    m.A  .= P * m.A * P'\n    m.πₖ .= P * m.πₖ\n    m.B   = m.B[perm]\n    return m\nend\n\nmtest = deepcopy(true_hmm)\nll0   = StateSpaceDynamics.loglikelihood(mtest, x_true)\nperm  = [2,3,1]  # arbitrary relabeling\npermute_states!(mtest, perm)\nll1   = StateSpaceDynamics.loglikelihood(mtest, x_true)\n\n@printf(\"\\nPermutation invariance: ΔLL = %.3e (should be ~0)\\n\", abs(ll0 - ll1))","category":"section"},{"location":"tutorials/hmm_identifiability_example/#Multi-Start-EM:-Label-Switching-in-Practice","page":"HMM Identifiability","title":"Multi-Start EM: Label Switching in Practice","text":"Because the likelihood has multiple symmetric optima (one per permutation of labels), EM can converge to any of these equivalent solutions depending on initialization. Running EM from several random starts reveals this “label switching”.\n\nfunction random_init_model(Y::AbstractMatrix; K::Int, D::Int, rng)\n    A0 = zeros(Float64, K, K)\n    for i in 1:K\n        v = rand(rng, Dirichlet(ones(K)))\n        A0[i, :] .= v ./ sum(v)\n    end\n    π0 = rand(rng, Dirichlet(ones(K)))\n    μ0s = rand(mean(Y) .+ (-1.0:0.1:1.0), K)  # spread out over data range\n    Σ0s = [fill(0.5, D, D) for _ in 1:K]\n    B0  = [GaussianEmission(D, [μ0s[k]], Σ0s[k]) for k in 1:K]\n\n    HiddenMarkovModel(A0, B0, π0, K)\nend\n\nM = 5  # number of independent starts\nfits = Vector{HiddenMarkovModel}(undef, M)\nlls  = zeros(Float64, M)\n\nfor m in 1:M\n    m0 = random_init_model(x_true; K=K, D=D, rng=StableRNG(10_000 + m))\n    hist = fit!(m0, x_true; max_iters=100, tol=1e-6)\n    fits[m] = m0\n    lls[m]  = last(hist)\nend\n\nfitted_means = [[fits[m].B[k].μ[1] for k in 1:K] for m in 1:M]\nprint(\"\\nFitted emission means per run (unordered):\\n\")\nfor row in fitted_means\n    @printf(\"  %s\\n\", string(round.(row, digits=3)))\nend","category":"section"},{"location":"tutorials/hmm_identifiability_example/#Post-hoc-Alignment:-Best-Permutation-to-a-Reference","page":"HMM Identifiability","title":"Post-hoc Alignment: Best Permutation to a Reference","text":"To compare runs or build averaged summaries, we need a consistent label convention. A simple approach is to choose a target ordering (e.g., increasing emission mean) and, for each fitted model, find the permutation that best matches that ordering using a cost (e.g., squared error in means). Below we brute‑force all permutations (fine for small K) and permute models.\n\nfunction all_permutations(K::Int)\n    K == 1 && return [[1]]\n    out = Vector{Vector{Int}}()\n    for p in all_permutations(K-1)\n        for i in 0:(K-1)\n            q = copy(p)\n            insert!(q, i+1, K)\n            push!(out, q)\n        end\n    end\n    return out\nend\n\nMatch a model to a target ordering by minimizing squared error of emission means (D=1)\n\nfunction best_perm_by_means(model::HiddenMarkovModel, μ_target::Vector{Float64})\n    perms = all_permutations(length(μ_target))\n    best_i, best_cost = 1, Inf\n    for (i, p) in enumerate(perms)\n        s = 0.0\n        for k in 1:length(p)\n            μk = model.B[p[k]].μ[1]\n            s += (μk - μ_target[k])^2\n        end\n        if s < best_cost\n            best_cost = s; best_i = i\n        end\n    end\n    return perms[best_i]\nend\n\nμ_target = sort(μ_true)               # choose an ordering convention (ascending mean)\naligned  = deepcopy(fits)\nfor m in 1:M\n    p = best_perm_by_means(aligned[m], μ_target)\n    permute_states!(aligned[m], p)\nend\n\naligned_means = [[aligned[m].B[k].μ[1] for k in 1:K] for m in 1:M]\nprint(\"\\nAligned emission means per run (ascending):\\n\")\nfor row in aligned_means\n    @printf(\"  %s\\n\", string(round.(row, digits=3)))\nend","category":"section"},{"location":"tutorials/hmm_identifiability_example/#What-*is*-Identifiable?","page":"HMM Identifiability","title":"What is Identifiable?","text":"Transition structure up to permutation. Eigenvalues of A and invariants like the stationary distribution are identifiable, but the rows/columns correspond to states whose labels are arbitrary.\nEmission parameters up to permutation. Means/variances (or their analogues) are identifiable modulo label permutations; if components overlap heavily, practical identifiability degrades.\nState sequence itself is not identifiable without constraints: we interpret distributions over sequences (e.g., smoothed posteriors), and these too are label‑ambiguous.","category":"section"},{"location":"tutorials/hmm_identifiability_example/#How-is-this-different-from-non-convexity?","page":"HMM Identifiability","title":"How is this different from non-convexity?","text":"Label symmetry (non‑identifiability) and non‑convexity can both yield multiple optima, but for different reasons and with different remedies.\n\nLabel symmetry (non‑identifiability). The objective is exactly invariant under a finite group of permutations (K! relabelings). All these optima are mathematically equivalent—they represent the same distribution after permuting state labels. You can move between them by explicitly permuting parameters (A, π, emissions).\nSymptoms: Equal (up to numerical noise) log‑likelihoods; parameters across runs are permutations of each other; posteriors match after relabeling.\nHandling: Choose a canonicalization (e.g., sort states by a statistic) or use identifying priors/constraints; always align models post‑hoc before comparison.\nNon‑convexity (true multimodality). The objective has distinct local maxima not related by symmetry. Fits may differ in likelihood and yield different predictions even after optimal alignment.\nSymptoms: Unequal log‑likelihoods across runs; differences persist after trying all label permutations; predictive metrics (e.g., held‑out log‑lik) differ.\nHandling: Use multiple restarts, better initializations, continuation/annealing, regularization, longer EM runs or alternative optimizers, and cross‑validation.\n\nBoth can co‑exist. You may have several families of solutions: each family contains K! symmetric copies (label switching), and there can be several distinct families due to non‑convexity. Our alignment step removes the symmetry so you can then compare true local optima.\n\nPractical checklist\n\nAlign by permutations → do likelihoods/predictions match? If yes, it was label symmetry.\nIf not, you’re seeing non‑convexity; compare held‑out performance and pick the best (or ensemble, if appropriate).","category":"section"},{"location":"tutorials/hmm_identifiability_example/#Diagnostics-and-Practical-Tips","page":"HMM Identifiability","title":"Diagnostics & Practical Tips","text":"Check invariance. Recompute log‑likelihood after permuting fitted models—differences should be ~0.\nUse multiple random starts. If runs converge to permuted solutions with similar likelihoods, that’s expected; if you see materially different likelihoods, you may have local maxima worth investigating.\nAlign before comparing. Always align models (or posterior state marginals) before averaging, plotting, or computing distances.\nStability tricks. Increase T, separate emissions more, or regularize covariances to improve practical identifiability.","category":"section"},{"location":"tutorials/hmm_identifiability_example/#Reproducibility","page":"HMM Identifiability","title":"Reproducibility","text":"All random draws are made with fixed seeds via StableRNGs, so your numbers should match the tutorial outputs. If you change K, dimensionality, or the emission family, expect small edits to the alignment cost and canonicalization rules.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"SLDS/#What-is-a-Switching-Linear-Dynamical-System?","page":"Switching Linear Dynamical Systems","title":"What is a Switching Linear Dynamical System?","text":"A Switching Linear Dynamical System (SLDS) is a powerful probabilistic model that combines the temporal structure of linear dynamical systems with the discrete switching behavior of Hidden Markov Models. SLDS can model complex time series data that exhibits multiple dynamical regimes, where the system can switch between different linear dynamics over time.\n\nAn SLDS extends the standard Linear Dynamical System (LDS) by introducing a discrete latent state that determines which linear dynamics are active at each time step. This makes SLDS particularly suitable for modeling systems with:\n\nMultiple operational modes (e.g., different flight phases of an aircraft)\nRegime changes (e.g., economic cycles, behavioral states)\nNon-stationary dynamics where linear dynamics change over time\nHybrid systems combining discrete and continuous states","category":"section"},{"location":"SLDS/#Mathematical-Formulation","page":"Switching Linear Dynamical Systems","title":"Mathematical Formulation","text":"An SLDS with K discrete states is defined by the following generative model:\n\nbeginalign*\n    z_1 sim textCat(pi_k) \n    x_1 sim mathcalN(mu_0 P_0) \n    z_t mid z_t-1 sim textCat(A_z_t-1 ) \n    x_t mid x_t-1 z_t sim mathcalN(F_z_t x_t-1 + b_z_t Q_z_t) \n    y_t mid x_t z_t sim mathcalN(C_z_t x_t + d_z_t R_z_t)\nendalign*\n\nWhere:\n\nz_t  1 2  K is the discrete switching state at time t\nx_t  ℝᴰ is the continuous latent state at time t\ny_t  ℝᴾ is the observed data at time t\nπ_k is the initial discrete state distribution\nA is the discrete state transition matrix\nF_z_t is the state-dependent dynamics matrix for discrete state z_t\nQ_z_t is the state-dependent process noise covariance for discrete state z_t\nC_z_t is the state-dependent observation matrix for discrete state z_t\nR_z_t is the state-dependent observation noise covariance for discrete state z_t\nb_z_t and d_z_t is the state-dependent biases for discrete state z_t","category":"section"},{"location":"SLDS/#Implementation-Structure","page":"Switching Linear Dynamical Systems","title":"Implementation Structure","text":"In StateSpaceDynamics.jl, an SLDS is represented as:\n\nmutable struct SLDS{\n    T<:Real,\n    S<:AbstractStateModel,\n    O<:AbstractObservationModel,\n    TM<:AbstractMatrix{T},\n    ISV<:AbstractVector{T},\n} <: AbstractHMM\n    A::TM # Transition matrix\n    πₖ::ISV # Initial state distribution\n    LDSs::Vector{LinearDynamicalSystem{T,S,O}} # Vector of LDS models\nend\n\nEach mode in the LDSs vector contains its own LinearDynamicalSystem with:\n\nState model: Defines the continuous latent dynamics F_k, Q_k\nObservation model: Defines the emission process. Currently supports Gaussian and Poisson emission models.","category":"section"},{"location":"SLDS/#Sampling-from-SLDS","page":"Switching Linear Dynamical Systems","title":"Sampling from SLDS","text":"You can generate synthetic data from an SLDS to test algorithms or create simulated datasets:\n\nThe sampling process follows the generative model:\n\nInitialize: Sample initial discrete state from pi_k and initial continuous state\nFor each time step:\nSample next discrete state based on current state and transition matrix A\nSample continuous state using the dynamics of the current discrete state\nGenerate observation using the observation model of the current discrete state","category":"section"},{"location":"SLDS/#Learning-in-SLDS:-Variational-Laplace-EM-(vLEM)","page":"Switching Linear Dynamical Systems","title":"Learning in SLDS: Variational Laplace EM (vLEM)","text":"StateSpaceDynamics.jl implements a Variational Laplace Expectation-Maximization (vLEM) algorithm for parameter estimation in SLDS. This approach efficiently handles the challenging interaction between discrete and continuous latent variables through a structured variational approximation.","category":"section"},{"location":"SLDS/#The-vLEM-Algorithm","page":"Switching Linear Dynamical Systems","title":"The vLEM Algorithm","text":"The vLEM algorithm maximizes the Evidence Lower Bound (ELBO) instead of the intractable marginal likelihood. The key insight is to use a structured variational approximation that factorizes as:\n\nq(z_1T x_1T) = q(z_1T) prod_k=1^K q(x_1T  z_1T = k)^mathbbIz_1T = k\n\nThis factorization allows efficient inference by alternating between updating discrete and continuous posteriors.","category":"section"},{"location":"SLDS/#Variational-Laplace-Expectation-Step","page":"Switching Linear Dynamical Systems","title":"Variational Laplace Expectation Step","text":"0. Initialization: Initialize with uniform discrete state posteriors and perform an initial smoothing pass using provided parameter values. This establishes the starting point for iterative refinement.\n\n1. Update Continuous State Posterior (q(x_1T  z_1T)): For each discrete state sequence k, run Kalman smoothing weighted by the current discrete posterior:\n\nq(x_1T mid z_1T = k) = prod_t=1^T mathcalN(x_t hatx_tT^(k) P_tT^(k))\n\nTo handle expectations efficiently, we use a single Monte Carlo sample from this posterior for subsequent computations.\n\n2. Update Discrete State Posterior (q(z_1T)): Run forward-backward algorithm with modified observation likelihoods that incorporate the current continuous posterior:\n\ntildep(y_t  z_t = k) = int p(y_t  x_t z_t = k) q(x_t  z_t = k) dx_t\n\nThis yields the discrete posterior marginals:\n\nq(z_t = k) = gamma_t(k) = p(z_t = k mid y_1T q(x_1T))","category":"section"},{"location":"SLDS/#Maximization-Step","page":"Switching Linear Dynamical Systems","title":"Maximization Step","text":"The M-step updates all parameters using expectations from the E-step:\n\nDiscrete State Parameters:\n\nInitial distribution: pi_k^(textnew) = gamma_1(k)\nTransition matrix: A_ij^(textnew) = fracsum_t=1^T-1 xi_tt+1(ij)sum_t=1^T-1 gamma_t(i)\n\nwhere xi_tt+1(ij) = p(z_t = i z_t+1 = j  y_1T) are the two-slice marginals.\n\nContinuous State Parameters for each mode k:\n\nUsing weighted sufficient statistics from the smoothed posteriors:\n\nDynamics matrix: F_k^(textnew) from weighted least squares\nProcess covariance: Q_k^(textnew) from weighted innovation covariance\nObservation matrix: C_k^(textnew) from weighted observation regression\nObservation covariance: R_k^(textnew) from weighted observation residuals\nInitial parameters: mu_0^(k) P_0^(k) from weighted initial state statistics\n\nThe weights are given by the discrete posterior probabilities gamma_t(k).","category":"section"},{"location":"SLDS/#Evidence-Lower-Bound-(ELBO)","page":"Switching Linear Dynamical Systems","title":"Evidence Lower Bound (ELBO)","text":"The ELBO decomposes into discrete and continuous components:\n\nmathcalL(q) = underbracemathbbE_q(z_1T)log p(z_1T) - mathbbE_q(z_1T)log q(z_1T)_textDiscrete HMM entropy + sum_k=1^K gamma_t(k) underbraceleft( mathbbE_q(x_1Tk)log p(y_1T x_1T  z_1T=k) + Hq(x_1Tk) right)_textWeighted LDS contribution for mode  k","category":"section"},{"location":"SLDS/#References","page":"Switching Linear Dynamical Systems","title":"References","text":"For theoretical foundations and algorithmic details:\n\n\"A general recurrent state space framework for modeling neural dynamics during decision-making\" by David Zoltowski, Jonathon Pillow, and Scott Linderman (2020)\n\"Variational Learning for Switching State-Space Models\" by Zoubin Ghahramani and Geoffrey Hinton (1998)\n\"Probabilistic Machine Learning: Advanced Topics, Chapter 29\" by Kevin Murphy\n\"A Unifying Review of Linear Gaussian Models\" by Sam Roweis and Zoubin Ghahramani","category":"section"},{"location":"SLDS/#StateSpaceDynamics.SLDS","page":"Switching Linear Dynamical Systems","title":"StateSpaceDynamics.SLDS","text":"SLDS{T,S,O,TM,ISV}\n\nA Switching Linear Dynamical System (SLDS). A hierarchical time-series model of the form:\n\nz_t  z_t-1  Categorical(A_z_t-1 )\nx_t  x_t-1 z_t  N(A^(z_t) x_t-1 + b^(z_t) Q^(z_t))\ny_t  x_t z_t  N(C^(z_t) x_t + d^(z_t) R^(z_t))\n\nFields\n\nA::TM: Transition matrix for the discrete states (K x K)\nπₖ::ISV: Initial state distribution for the discrete states (K-dimensional vector)\nLDSs::Vector{LinearDynamicalSystem{T,S,O}}: Vector of K Linear Dynamical Systems, one for each discrete state\n\n\n\n\n\n","category":"type"},{"location":"SLDS/#Base.rand-Tuple{AbstractRNG, SLDS}","page":"Switching Linear Dynamical Systems","title":"Base.rand","text":"rand(rng::AbstractRNG, slds::SLDS{T,S,O}; tsteps::Int, ntrials::Int=1) where {T<:Real, S<:AbstractStateModel, O<:AbstractObservationModel}\n\nSample from a Switching Linear Dynamical System (SLDS). Returns a tuple (z, x, y) where:\n\nz is a matrix of discrete states of size (tsteps, ntrials)\nx is a 3D array of continuous latent states of size (latent_dim, tsteps, ntrials)\ny is a 3D array of observations of size (obs_dim, tsteps, ntrials)\n\n\n\n\n\n","category":"method"},{"location":"SLDS/#StateSpaceDynamics.fit!-Union{Tuple{O}, Tuple{S}, Tuple{T}, Tuple{SLDS{T, S, O, TM, ISV} where {TM<:AbstractMatrix{T}, ISV<:AbstractVector{T}}, AbstractArray{T, 3}}} where {T<:Real, S<:AbstractStateModel, O<:AbstractObservationModel}","page":"Switching Linear Dynamical Systems","title":"StateSpaceDynamics.fit!","text":"fit!(slds::SLDS{T,S,O}, y::AbstractArray{T,3}; max_iter::Int=50, progress::Bool=true\n    ) where {T<:Real,S<:AbstractStateModel,O<:AbstractObservationModel}\n\nFit SLDS using variational Laplace EM algorithm with stochastic ELBO estimates. Runs for exactly max_iter iterations (no early stopping due to stochastic estimates).\n\n\n\n\n\n","category":"method"},{"location":"tutorials/gaussian_latent_dynamics_example/#Simulating-and-Fitting-a-Linear-Dynamical-System","page":"Gaussian LDS Example","title":"Simulating and Fitting a Linear Dynamical System","text":"This tutorial demonstrates how to use StateSpaceDynamics.jl to simulate a latent linear dynamical system and fit it using the EM algorithm. We'll walk through the complete workflow: defining a true model, generating synthetic data, initializing a naive model, and then learning the parameters through iterative optimization.","category":"section"},{"location":"tutorials/gaussian_latent_dynamics_example/#Load-Required-Packages","page":"Gaussian LDS Example","title":"Load Required Packages","text":"using StateSpaceDynamics\nusing LinearAlgebra\nusing Random\nusing Plots\nusing LaTeXStrings\nusing StableRNGs\n\nSet a stable random number generator for reproducible results\n\nrng = StableRNG(123);\nnothing #hide","category":"section"},{"location":"tutorials/gaussian_latent_dynamics_example/#Create-a-State-Space-Model","page":"Gaussian LDS Example","title":"Create a State-Space Model","text":"","category":"section"},{"location":"tutorials/gaussian_latent_dynamics_example/#Mathematical-Foundation-of-Linear-Dynamical-Systems","page":"Gaussian LDS Example","title":"Mathematical Foundation of Linear Dynamical Systems","text":"A Linear Dynamical System describes how a hidden state evolves over time and generates observations through two key equations:\n\nState Evolution: x_t+1 = mathbfA  x_t + ε_t,  where ε_t sim N(0 mathbfQ) \\\nObservation: y_t = mathbfC  x_t + η_t,  where η_t sim N(0 mathbfR)\n\nThe beauty of this formulation is that it separates the underlying dynamics (governed by mathbfA) from what we can actually measure (governed by mathbfC). The noise terms boldsymbolepsilon and boldsymboleta represent our uncertainty about the process and measurements.\n\nobs_dim = 10      # Number of observed variables at each time step\nlatent_dim = 2;   # Number of latent state variables\nnothing #hide\n\nDefine the state transition matrix mathbfA. This matrix governs how the latent state evolves from one time step to the next: mathbfx_t+1 = mathbfA mathbfx_t + boldsymbolepsilon. The rotation angle of 0.25 radians (≈14.3°) creates a gentle spiral, while the 0.95 scaling ensures the system is stable (eigenvalues < 1). Without the scaling factor, trajectories would spiral outward indefinitely. This particular combination creates visually appealing dynamics that are easy to interpret.\n\nA = 0.95 * [cos(0.25) -sin(0.25); sin(0.25) cos(0.25)];\nb = zeros(latent_dim) # bias\n\nProcess noise covariance mathbfQ controls how much random variation we add to the latent state transitions. A smaller mathbfQ means more predictable dynamics.\n\nQ = Matrix(0.1 * I(2));\nnothing #hide\n\nInitial state parameters: where the latent trajectory starts and how uncertain we are about this initial position.\n\nx0 = [0.0; 0.0]           # Mean of initial state\nP0 = Matrix(0.1 * I(2));  # Covariance of initial state\nnothing #hide\n\nObservation parameters: how the latent states map to observed data. mathbfC is the observation matrix (latent-to-observed mapping), and mathbfR is the observation noise covariance.\n\nC = randn(rng, obs_dim, latent_dim)  # Random linear mapping from 2D latent to 10D observed\nd = zeros(obs_dim)                   # bias\nR = Matrix(0.5 * I(obs_dim));         # Independent noise on each observation dimension\nnothing #hide\n\nConstruct the state and observation model components\n\ntrue_gaussian_sm = GaussianStateModel(;A=A, b=b, Q=Q, x0=x0, P0=P0)\ntrue_gaussian_om = GaussianObservationModel(;C=C, d=d, R=R);\nnothing #hide\n\nCombine them into a complete Linear Dynamical System The fit_bool parameter indicates which parameters should be learned during fitting\n\ntrue_lds = LinearDynamicalSystem(;\n    state_model=true_gaussian_sm,\n    obs_model=true_gaussian_om,\n    latent_dim=latent_dim,\n    obs_dim=obs_dim,\n    fit_bool=fill(true, 6)  # Fit all 6 parameter matrices: A, Q, C, R, x0, P0\n);\nnothing #hide","category":"section"},{"location":"tutorials/gaussian_latent_dynamics_example/#Simulate-Latent-and-Observed-Data","page":"Gaussian LDS Example","title":"Simulate Latent and Observed Data","text":"Now we generate synthetic data from our true model. This gives us both the latent states (which we'll later try to recover) and the observations (which is all a real algorithm would see).\n\ntSteps = 500;  # Number of time points to simulate\nnothing #hide\n\nThe rand function generates both latent trajectories and corresponding observations\n\nlatents, observations = rand(rng, true_lds; tsteps=tSteps, ntrials=1);\nnothing #hide","category":"section"},{"location":"tutorials/gaussian_latent_dynamics_example/#Plot-Vector-Field-of-Latent-Dynamics","page":"Gaussian LDS Example","title":"Plot Vector Field of Latent Dynamics","text":"To better understand the dynamics encoded by our transition matrix mathbfA, we'll create a vector field plot. This shows how the latent state would evolve from any starting point in the 2D latent space.\n\nCreate a grid of starting points and calculate the flow field\n\nx = y = -3:0.5:3\nX = repeat(x', length(y), 1)\nY = repeat(y, 1, length(x))\n\nU = zeros(size(X))  # x-component of flow\nV = zeros(size(Y))  # y-component of flow\n\nfor i in 1:size(X, 1), j in 1:size(X, 2)\n    v = A * [X[i,j], Y[i,j]]\n    U[i,j] = v[1] - X[i,j]  # Change in x\n    V[i,j] = v[2] - Y[i,j]  # Change in y\nend\n\nmagnitude = @. sqrt(U^2 + V^2)\nU_norm = U ./ magnitude\nV_norm = V ./ magnitude;\nnothing #hide\n\nCreate the vector field plot with the actual trajectory overlaid\n\np1 = quiver(X, Y, quiver=(U_norm, V_norm), color=:blue, alpha=0.3,\n           linewidth=1, arrow=arrow(:closed, :head, 0.1, 0.1))\nplot!(latents[1, :, 1], latents[2, :, 1], xlabel=L\"x_1\", ylabel=L\"x_2\",\n      color=:black, linewidth=1.5, title=\"Latent Dynamics\", legend=false)\n\np1","category":"section"},{"location":"tutorials/gaussian_latent_dynamics_example/#Plot-Latent-States-and-Observations","page":"Gaussian LDS Example","title":"Plot Latent States and Observations","text":"Let's visualize both the latent states (which evolve smoothly according to our dynamics) and the observations (which are noisy linear combinations of the latents).\n\nstates = latents[:, :, 1]      # Extract the latent trajectory\nemissions = observations[:, :, 1];  # Extract the observed data\nnothing #hide\n\nCreate a two-panel plot: latent states on top, observations below\n\nlim_states = maximum(abs.(states))\nlim_emissions = maximum(abs.(emissions))\n\np2 = plot(size=(800, 600), layout=@layout[a{0.3h}; b])\n\nfor d in 1:latent_dim\n    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,\n          linewidth=2, label=\"\", subplot=1)\nend\n\nplot!(subplot=1, yticks=(lim_states .* (0:latent_dim-1), [L\"x_%$d\" for d in 1:latent_dim]),\n      xticks=[], xlims=(0, tSteps), title=\"Simulated Latent States\",\n      yformatter=y->\"\", tickfontsize=12);\n\nfor n in 1:obs_dim\n    plot!(1:tSteps, emissions[n, :] .- lim_emissions * (n-1), color=:black,\n          linewidth=2, label=\"\", subplot=2); # Plot observations (offset vertically since there are many dimensions)\n\nend\n\nplot!(subplot=2, yticks=(-lim_emissions .* (obs_dim-1:-1:0), [L\"y_{%$n}\" for n in 1:obs_dim]),\n      xlabel=\"time\", xlims=(0, tSteps), title=\"Simulated Emissions\",\n      yformatter=y->\"\", tickfontsize=12, left_margin=10Plots.mm)\n\np2","category":"section"},{"location":"tutorials/gaussian_latent_dynamics_example/#The-Learning-Problem","page":"Gaussian LDS Example","title":"The Learning Problem","text":"In real applications, we only observe y_t (the emissions) - the latent states x_t are hidden from us. Our challenge is to recover both:\n\nThe system parameters (mathbfA, mathbfQ, mathbfC, mathbfR) that generated the data\nThe most likely latent state sequence given our observations\n\nThis is a classic \"chicken and egg\" problem: if we knew the parameters, we could infer the states; if we knew the states, we could estimate the parameters. The EM algorithm elegantly solves this by alternating between these two problems.\n\nInitialize with random parameters (this simulates not knowing the true system)\n\nA_init = random_rotation_matrix(2, rng)    # Random rotation matrix for dynamics\nQ_init = Matrix(0.1 * I(2))                # Same process noise variance\nC_init = randn(rng, obs_dim, latent_dim)   # Random observation mapping\nR_init = Matrix(0.5 * I(obs_dim))          # Same observation noise\nx0_init = zeros(latent_dim)                # Start from origin\nP0_init = Matrix(0.1 * I(latent_dim));      # Same initial uncertainty\nnothing #hide\n\nOur \"naive\" initialization uses random parameters, simulating a real scenario where we don't know the true system. The quality of initialization can affect convergence speed and which local optimum we find, but EM is generally robust to reasonable starting points.\n\ngaussian_sm_init = GaussianStateModel(;A=A_init, b=b, Q=Q_init, x0=x0_init, P0=P0_init)\ngaussian_om_init = GaussianObservationModel(;C=C_init, d=d, R=R_init)\n\nAssemble the complete naive system\n\nnaive_ssm = LinearDynamicalSystem(;\n    state_model=gaussian_sm_init,\n    obs_model=gaussian_om_init,\n    latent_dim=latent_dim,\n    obs_dim=obs_dim,\n    fit_bool=fill(true, 6)  # We'll learn all parameters\n);\nnothing #hide\n\nBefore fitting, let's see how well our randomly initialized model can infer the latent states using the smoothing algorithm.\n\nx_smooth, p_smooth = StateSpaceDynamics.smooth(naive_ssm, observations);\nnothing #hide\n\nPlot the true latent states vs. our initial (poor) estimates\n\np3 = plot()\nfor d in 1:latent_dim\n    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,\n          linewidth=2, label=(d==1 ? \"True\" : \"\"), alpha=0.8)\n    plot!(1:tSteps, x_smooth[d, :, 1] .+ lim_states * (d-1), color=:firebrick,\n          linewidth=2, label=(d==1 ? \"Predicted\" : \"\"), alpha=0.8)\nend\nplot!(yticks=(lim_states .* (0:latent_dim-1), [L\"x_%$d\" for d in 1:latent_dim]),\n      xlabel=\"time\", xlims=(0, tSteps), yformatter=y->\"\", tickfontsize=12,\n      title=\"True vs. Predicted Latent States (Pre-EM)\",\n      legend=:topright)\n\np3","category":"section"},{"location":"tutorials/gaussian_latent_dynamics_example/#Understanding-the-EM-Algorithm","page":"Gaussian LDS Example","title":"Understanding the EM Algorithm","text":"EM alternates between two steps until convergence:\n\nE-step (Expectation): Given current parameter estimates, compute the posterior distribution over latent states using the Kalman smoother. This gives us p(x_1T  y_1T θ_current).\n\nM-step (Maximization): Given the state estimates from the E-step, update the parameters to maximize the expected log-likelihood. This involves solving closed-form equations for mathbfA, mathbfQ, mathbfC, and mathbfR.\n\nThe Evidence Lower BOund (ELBO) measures how well our model explains the data. It's guaranteed to increase (or stay constant) at each iteration, ensuring convergence to at least a local optimum.\n\nprintln(\"Starting EM algorithm to learn parameters...\")\n\nSuppress output and capture ELBO values\n\nelbo, _ = fit!(naive_ssm, observations; max_iter=100, tol=1e-6);\n\nprintln(\"EM converged after $(length(elbo)) iterations\")\n\nAfter EM has converged, let's see how much better our latent state estimates are\n\nx_smooth_post, p_smooth_post = StateSpaceDynamics.smooth(naive_ssm, observations);\nnothing #hide\n\nPlot the results: true states vs. post-EM estimates\n\np4 = plot()\nfor d in 1:latent_dim\n    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,\n          linewidth=2, label=(d==1 ? \"True\" : \"\"), alpha=0.8)\n    plot!(1:tSteps, x_smooth_post[d, :, 1] .+ lim_states * (d-1), color=:firebrick,\n          linewidth=2, label=(d==1 ? \"Predicted\" : \"\"), alpha=0.8)\nend\nplot!(yticks=(lim_states .* (0:latent_dim-1), [L\"x_%$d\" for d in 1:latent_dim]),\n      xlabel=\"time\", xlims=(0, tSteps), yformatter=y->\"\", tickfontsize=12,\n      title=\"True vs. Predicted Latent States (Post-EM)\",\n      legend=:topright)\n\np4","category":"section"},{"location":"tutorials/gaussian_latent_dynamics_example/#Model-Convergence-Analysis","page":"Gaussian LDS Example","title":"Model Convergence Analysis","text":"The Evidence Lower Bound (ELBO) measures how well our model explains the data. In EM, this should increase monotonically and plateau when the algorithm has converged to a local optimum.\n\np5 = plot(elbo, xlabel=\"Iteration\", ylabel=\"ELBO\",\n          title=\"Model Convergence (ELBO)\", legend=false,\n          linewidth=2, color=:darkblue)\n\np5","category":"section"},{"location":"tutorials/gaussian_latent_dynamics_example/#Interpreting-the-Results","page":"Gaussian LDS Example","title":"Interpreting the Results","text":"The dramatic improvement in state estimation shows that EM successfully recovered the underlying dynamics. However, keep in mind:\n\nWe may have found a local optimum, not the global one\nThe recovered parameters might differ from the true ones due to identifiability issues (multiple parameter sets can generate similar observations)\nIn practice, you'd validate the model on held-out data to ensure generalization","category":"section"},{"location":"tutorials/gaussian_latent_dynamics_example/#Summary","page":"Gaussian LDS Example","title":"Summary","text":"This tutorial demonstrated the complete workflow for fitting a Linear Dynamical System:\n\nWe defined a true LDS with spiral dynamics and generated synthetic data\nWe initialized a naive model with random parameters\nWe used EM to iteratively improve our parameter estimates\nWe visualized the dramatic improvement in latent state inference\n\nThe EM algorithm successfully recovered the underlying dynamics from observations alone, as evidenced by the improved match between true and estimated latent states and the monotonic convergence of the ELBO objective function.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Simulating-and-Fitting-a-Hidden-Markov-Model","page":"Gaussian GLM-HMM Example","title":"Simulating and Fitting a Hidden Markov Model","text":"This tutorial demonstrates how to use StateSpaceDynamics.jl to create, sample from, and fit Hidden Markov Models (HMMs). Unlike Linear Dynamical Systems which have continuous latent states, HMMs have discrete latent states that switch between a finite number of modes. This makes them ideal for modeling data with distinct behavioral regimes, switching dynamics, or categorical latent structure.\n\nWe'll focus on a Gaussian generalized linear model HMM (GLM-HMM), where each hidden state corresponds to a different regression relationship between inputs and outputs. This is particularly useful for modeling data where the input-output relationship changes over time in discrete jumps.","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Load-Required-Packages","page":"Gaussian GLM-HMM Example","title":"Load Required Packages","text":"using LinearAlgebra\nusing Plots\nusing Random\nusing StateSpaceDynamics\nusing StableRNGs\nusing Statistics: mean\n\nSet up reproducible random number generation\n\nrng = StableRNG(1234);\nnothing #hide","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Create-a-Gaussian-GLM-HMM","page":"Gaussian GLM-HMM Example","title":"Create a Gaussian GLM-HMM","text":"In a GLM-HMM, each hidden state defines a different regression model. The system switches between these regression models according to Markovian dynamics. This is useful for modeling scenarios where the relationship between predictors and outcomes changes over time. In this example, we will demonstrate how to use StateSpaceDynamics.jl to create a GLM-HMM, generate synthetic data, fit the model using the EM algorithm, and perform state inference with the Viterbi algorithm.\n\nWe will start by defining a simple GLM-HMM with two hidden states. State 1: Positive relationship between input and output\n\nemission_1 = GaussianRegressionEmission(\n    input_dim=3,                                    # Number of input features\n    output_dim=1,                                   # Number of output dimensions\n    include_intercept=true,                         # Include intercept term\n    β=reshape([3.0, 2.0, 2.0, 3.0], :, 1),        # Regression coefficients [intercept, β₁, β₂, β₃]\n    Σ=[1.0;;],                                     # Observation noise variance\n    λ=0.0                                          # Regularization parameter\n);\nnothing #hide\n\nState 2: Different relationship (negative intercept, different slopes)\n\nemission_2 = GaussianRegressionEmission(\n    input_dim=3,\n    output_dim=1,\n    include_intercept=true,\n    β=reshape([-4.0, -2.0, 3.0, 2.0], :, 1),      # Different regression coefficients\n    Σ=[1.0;;],                                     # Same noise level\n    λ=0.0\n);\nnothing #hide\n\nDefine the state transition matrix mathbfA: A_ij = P(textstate_t = j mid textstate_t-1 = i)\n\nDiagonal elements are high (states are persistent)\n\nA = [0.99 0.01;    # From state 1: 99% stay, 1% switch to state 2\n     0.05 0.95];    # From state 2: 5% switch to state 1, 95% stay\nnothing #hide\n\nInitial state distribution: pi_k = P(textstate_1 = k)\n\nπₖ = [0.8; 0.2];    # 80% chance of starting in state 1, 20% in state 2\nnothing #hide\n\nNow that we have defined our emission models, we can construct the complete GLM-HMM.\n\ntrue_model = HiddenMarkovModel(\n    K=2,                        # Number of hidden states\n    A=A,                        # Transition matrix\n    πₖ=πₖ,                     # Initial state distribution\n    B=[emission_1, emission_2]  # Emission models for each state\n);\n\nprint(\"Created GLM-HMM with regression models:\\n\")\nprint(\"State 1: y = 3.0 + 2.0x₁ + 2.0x₂ + 3.0x₃ + ε\\n\")\nprint(\"State 2: y = -4.0 - 2.0x₁ + 3.0x₂ + 2.0x₃ + ε\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Sample-from-the-GLM-HMM","page":"Gaussian GLM-HMM Example","title":"Sample from the GLM-HMM","text":"Generate synthetic data from our true model. To do this, we must define the inputs to the model. Then, sampling will yield the outputs nad the true hidden state sequence.\n\nn = 20000  # Number of time points\n\nΦ = randn(rng, 3, n);  # Generate random input features (predictors)\n\ntrue_labels, data = rand(rng, true_model, Φ, n=n);  # Sample from the HMM: returns both hidden states and observations\n\nprint(\"Generated $(n) samples: State 1 ($(round(mean(true_labels .== 1)*100, digits=1))%), State 2 ($(round(mean(true_labels .== 2)*100, digits=1))%)\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Visualize-the-Sampled-Dataset","page":"Gaussian GLM-HMM Example","title":"Visualize the Sampled Dataset","text":"Here, we create a scatter plot to show how the input-output relationship differs between the two hidden states. We plot feature 1 vs output, with points colored by true state. State 1 (blue) has a positive slope, while State 2 (red) has a negative slopes. In addition to the scatter plot, we overlay the true regression lines for each state.\n\ncolors = [:dodgerblue, :crimson]  # Blue for state 1, red for state 2\n\np1 = scatter(Φ[1, :], vec(data);\n    color = colors[true_labels],\n    ms = 2,\n    alpha = 0.4,\n    label = \"\",\n    xlabel = \"Input Feature 1\",\n    ylabel = \"Output\",\n    title = \"GLM-HMM Data (colored by true state)\"\n)\n\nxvals = range(extrema(Φ[1, :])..., length=100) # Overlay true regression lines (holding other features at 0)\n\nβ1 = emission_1.β[:, 1]\ny_pred_1 = β1[1] .+ β1[2] .* xvals  # intercept + slope*x₁\nplot!(xvals, y_pred_1;\n    color = :dodgerblue,\n    lw = 3,\n    label = \"State 1 regression\"\n)\n\nβ2 = emission_2.β[:, 1]\ny_pred_2 = β2[1] .+ β2[2] .* xvals  # intercept + slope*x₁\nplot!(xvals, y_pred_2;\n    color = :crimson,\n    lw = 3,\n    label = \"State 2 regression\",\n    legend = :topright\n)","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Initialize-and-Fit-HMM-with-EM","page":"Gaussian GLM-HMM Example","title":"Initialize and Fit HMM with EM","text":"In a realistic scenario, we would not have access to the latent states; we would only observe the inputs and outputs. We can use the Expectation-Maximization (EM) algorithm to learn the model parameters and infer the hidden states from the observed data alone.\n\nTo demonstrate this process, we start with a randomly initialized GLM-HMM with different parameters than the true model.\n\nA_init = [0.8 0.2; 0.1 0.9]     # Different transition probabilities\nπₖ_init = [0.6; 0.4]            # Different initial distribution\n\nemission_1_init = GaussianRegressionEmission(\n    input_dim=3, output_dim=1, include_intercept=true,\n    β=reshape([2.0, -1.0, 1.0, 2.0], :, 1),    # Random coefficients\n    Σ=[2.0;;], λ=0.0\n);\n\nemission_2_init = GaussianRegressionEmission(\n    input_dim=3, output_dim=1, include_intercept=true,\n    β=reshape([-2.5, -1.0, 3.5, 3.0], :, 1),   # Random coefficients\n    Σ=[0.5;;], λ=0.0\n);\n\n\ntest_model = HiddenMarkovModel(K=2, A=A_init, πₖ=πₖ_init, B=[emission_1_init, emission_2_init])\n\nNow that we have definedour test model, we can fit it to the data using the EM algorithm.\n\nlls = fit!(test_model, data, Φ);\n\nprint(\"EM converged after $(length(lls)) iterations\\n\")\nprint(\"Log-likelihood improved by $(round(lls[end] - lls[1], digits=1))\\n\");\nnothing #hide\n\nPlot EM convergence\n\np2 = plot(lls, xlabel=\"EM Iteration\", ylabel=\"Log-Likelihood\",\n          title=\"Model Convergence\", legend=false, lw=2, color=:darkblue)","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Visualize-Learned-vs-True-Regression-Models","page":"Gaussian GLM-HMM Example","title":"Visualize Learned vs True Regression Models","text":"Now that we have done parameter learning, we can visualize how well the learned regression models match the true models. We plot the data again, colored by true state, and overlay both the true and learned regression lines. As you can see, the learned models (dashed lines) closely match the true models (solid lines).\n\np3 = scatter(Φ[1, :], vec(data);\n    color = colors[true_labels],\n    ms = 2,\n    alpha = 0.3,\n    label = \"\",\n    xlabel = \"Input Feature 1\",\n    ylabel = \"Output\",\n    title = \"True vs. Learned Regression Models\"\n)\n\nxvals = range(extrema(Φ[1, :])..., length=100)\n\nplot!(xvals, β1[1] .+ β1[2] .* xvals;\n    color = :green, lw = 3, linestyle = :solid, label = \"State 1 (true)\"\n)\nplot!(xvals, β2[1] .+ β2[2] .* xvals;\n    color = :orange, lw = 3, linestyle = :solid, label = \"State 2 (true)\"\n)\n\nβ1_learned = test_model.B[1].β[:, 1]\nβ2_learned = test_model.B[2].β[:, 1]\nplot!(xvals, β1_learned[1] .+ β1_learned[2] .* xvals;\n    color = :yellow, lw = 3, linestyle = :dash, label = \"State 1 (learned)\"\n)\nplot!(xvals, β2_learned[1] .+ β2_learned[2] .* xvals;\n    color = :purple, lw = 3, linestyle = :dash, label = \"State 2 (learned)\",\n    legend = :topright\n)","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Hidden-State-Decoding-with-Viterbi-Algorithm","page":"Gaussian GLM-HMM Example","title":"Hidden State Decoding with Viterbi Algorithm","text":"Now we use the Viterbi algorithm to find the most likely sequence of hidden states given the observed data. We'll compare true vs predicted state sequences.\n\npred_labels = viterbi(test_model, data, Φ);\n\naccuracy = mean(true_labels .== pred_labels)\nprint(\"Hidden state prediction accuracy: $(round(accuracy*100, digits=1))%\\n\");\nnothing #hide\n\nWe can also visualize the true and predicted state sequences as heatmaps (first 1000 time points).\n\nn_display = 1000\ntrue_seq = reshape(true_labels[1:n_display], 1, :)\npred_seq = reshape(pred_labels[1:n_display], 1, :)\n\np4 = plot(\n    heatmap(true_seq, colormap=:roma, title=\"True State Sequence\",\n           xticks=false, yticks=false, colorbar=false),\n    heatmap(pred_seq, colormap=:roma, title=\"Predicted State Sequence (Viterbi)\",\n           xlabel=\"Time Steps (1-$n_display)\", xticks=0:200:n_display,\n           yticks=false, colorbar=false),\n    layout=(2, 1), size=(800, 300)\n)","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Multiple-Independent-Trials","page":"Gaussian GLM-HMM Example","title":"Multiple Independent Trials","text":"Real-world scenarios often involve multiple independent sequences. Here, we generate multiple trials of synthetic data and show how to fit GLM-HMMs to this data structure using StateSpaceDynamics.jl.\n\nnum_trials = 100   # Number of independent sequences\nn_trial = 1000;    # Length of each sequence\n\nprint(\"Generating $num_trials independent trials of length $n_trial...\\n\")\n\nall_data = Vector{Matrix{Float64}}()\nΦ_total = Vector{Matrix{Float64}}()\nall_true_labels = Vector{Vector{Int64}}()\n\nfor i in 1:num_trials  # Generate multiple trials from our ground truth model\n    Φ_trial = randn(rng, 3, n_trial)\n    true_labels_trial, data_trial = rand(rng, true_model, Φ_trial, n=n_trial)\n    push!(all_true_labels, true_labels_trial)\n    push!(all_data, data_trial)\n    push!(Φ_total, Φ_trial)\nend\n\nprint(\"Total data points: $(num_trials * n_trial)\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Fitting-HMM-to-Multiple-Trials","page":"Gaussian GLM-HMM Example","title":"Fitting HMM to Multiple Trials","text":"When we have multiple independent sequences, EM accounts for each sequence starting fresh from the initial distribution, providing more robust estimates. To fit models of this kind, simply create a test model as before and call fit! with the data and inputs as vectors of the independent sequences! We will use the same random initialization as before.\n\ntest_model_multi = HiddenMarkovModel(\n    K=2, A=A_init, πₖ=πₖ_init,\n    B=[deepcopy(emission_1_init), deepcopy(emission_2_init)]\n)  # Initialize fresh model for multi-trial fitting\n\nlls_multi = fit!(test_model_multi, all_data, Φ_total);\n\nprint(\"Multi-trial EM converged after $(length(lls_multi)) iterations\\n\")\nprint(\"Log-likelihood improved by $(round(lls_multi[end] - lls_multi[1], digits=1))\\n\");\nnothing #hide\n\nPlot multi-trial convergence\n\np5 = plot(lls_multi, xlabel=\"EM Iteration\", ylabel=\"Log-Likelihood\",\n          title=\"Multi-Trial Model Convergence\", legend=false, lw=2, color=:darkgreen)","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Multi-Trial-State-Decoding","page":"Gaussian GLM-HMM Example","title":"Multi-Trial State Decoding","text":"Decode hidden states for all trials and visualize as a multi-trial heatmap.\n\nall_pred_labels = viterbi(test_model_multi, all_data, Φ_total);\nnothing #hide\n\nCalculate overall accuracy across all trials\n\nall_true_matrix = hcat(all_true_labels...);\nall_pred_matrix = hcat(all_pred_labels...);\ntotal_accuracy = mean(all_true_matrix .== all_pred_matrix);\n\nprint(\"Overall state prediction accuracy: $(round(total_accuracy*100, digits=1))%\\n\");\nnothing #hide\n\nVisualize subset of trials (first 10 trials, first 500 time points)\n\nn_trials_display = 10\nn_time_display = 500\n\ntrue_subset = hcat(all_true_labels[1:n_trials_display]...)'[:, 1:n_time_display]\npred_subset = hcat(all_pred_labels[1:n_trials_display]...)'[:, 1:n_time_display]\n\np6 = plot(\n    heatmap(true_subset, colormap=:roma, title=\"True States ($n_trials_display trials)\",\n           xticks=false, ylabel=\"Trial\", colorbar=false),\n    heatmap(pred_subset, colormap=:roma, title=\"Predicted States (Viterbi)\",\n           xlabel=\"Time Steps\", ylabel=\"Trial\", colorbar=false),\n    layout=(2, 1), size=(900, 400)\n)","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Model-Assessment-Summary","page":"Gaussian GLM-HMM Example","title":"Model Assessment Summary","text":"Compare learned parameters with true parameters\n\ntrue_A_orig = [0.99 0.01; 0.05 0.95]\nA_error = norm(true_A_orig - test_model_multi.A) / norm(true_A_orig)\nprint(\"Transition matrix relative error: $(round(A_error, digits=4))\\n\")\n\ntrue_π_orig = [0.8; 0.2]\nπ_error = norm(true_π_orig - test_model_multi.πₖ) / norm(true_π_orig)\nprint(\"Initial distribution relative error: $(round(π_error, digits=4))\\n\")\n\nprint(\"\\nRegression Coefficient Recovery:\\n\")\nprint(\"State 1 - True β:    [3.0, 2.0, 2.0, 3.0]\\n\")\nprint(\"State 1 - Learned β: $(round.(test_model_multi.B[1].β[:, 1], digits=2))\\n\")\nprint(\"State 2 - True β:    [-4.0, -2.0, 3.0, 2.0]\\n\")\nprint(\"State 2 - Learned β: $(round.(test_model_multi.B[2].β[:, 1], digits=2))\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/gaussian_glm_hmm_example/#Summary","page":"Gaussian GLM-HMM Example","title":"Summary","text":"This tutorial demonstrated the complete workflow for Hidden Markov Models with regression emissions:\n\nKey Concepts:\n\nDiscrete latent states with different regression relationships in each state\nMarkovian dynamics governing state transitions over time\nEM algorithm for joint parameter learning and state inference\nViterbi decoding for finding most likely state sequences\n\nApplications:\n\nModeling switching dynamics and regime changes\nContext-dependent input-output relationships\nMultiple independent trial analysis\nRobust parameter estimation across sequences\n\nGLM-HMMs provide a powerful framework for modeling data with discrete latent structure, making them valuable for neuroscience, economics, and other domains with switching behaviors.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Simulating-and-Fitting-a-Hidden-Markov-Model-with-Gaussian-Emissions","page":"Hidden Markov Model Example","title":"Simulating and Fitting a Hidden Markov Model with Gaussian Emissions","text":"This tutorial demonstrates how to use StateSpaceDynamics.jl to create, sample from, and fit Hidden Markov Models (HMMs) with Gaussian emission distributions. This is the classical HMM formulation where each hidden state generates observations from a different multivariate Gaussian distribution.\n\nUnlike GLM-HMMs, this model doesn't use input features - each state simply emits observations from its own characteristic Gaussian distribution. This makes it ideal for clustering time series data, identifying behavioral regimes, or modeling switching dynamics where each state has a distinct statistical signature.","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Load-Required-Packages","page":"Hidden Markov Model Example","title":"Load Required Packages","text":"using LinearAlgebra\nusing Plots\nusing Random\nusing StateSpaceDynamics\nusing StableRNGs\nusing Statistics: mean, std\nusing LaTeXStrings\n\nSet up reproducible random number generation\n\nrng = StableRNG(1234);\nnothing #hide","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Create-a-Gaussian-Emission-HMM","page":"Hidden Markov Model Example","title":"Create a Gaussian Emission HMM","text":"We'll create an HMM with two hidden states, each emitting 2D Gaussian observations. This creates a simple but illustrative model where hidden states correspond to different regions in the observation space.\n\noutput_dim = 2;  # Each observation is a 2D vector\nnothing #hide\n\nDefine state transition dynamics: A_ij = P(textstate_t = j mid textstate_t-1 = i)  \\\nHigh diagonal values mean states are \"sticky\" (tend to persist)\n\nA = [0.99 0.01;    # From state 1: 99% stay, 1% switch to state 2\n     0.05 0.95];   # From state 2: 5% switch to state 1, 95% stay\nnothing #hide\n\nInitial state probabilities: pi_k = P(textstate_1 = k)\n\nπₖ = [0.5; 0.5];\nnothing #hide\n\nDefine emission distributions for each hidden state State 1: Centered at (-1, -1) with small variance (tight cluster)\n\nμ_1 = [-1.0, -1.0]\nΣ_1 = 0.1 * Matrix{Float64}(I, output_dim, output_dim)\nemission_1 = GaussianEmission(output_dim=output_dim, μ=μ_1, Σ=Σ_1);\nnothing #hide\n\nState 2: Centered at (1, 1) with larger variance (more spread out)\n\nμ_2 = [1.0, 1.0]\nΣ_2 = 0.2 * Matrix{Float64}(I, output_dim, output_dim)\nemission_2 = GaussianEmission(output_dim=output_dim, μ=μ_2, Σ=Σ_2);\nnothing #hide\n\nConstruct the complete HMM\n\nmodel = HiddenMarkovModel(\n    K=2,                        # Number of hidden states\n    B=[emission_1, emission_2], # Emission distributions\n    A=A,                        # State transition matrix\n    πₖ=πₖ                      # Initial state distribution\n);\n\nprint(\"Created Gaussian HMM with 2 states:\\n\")\nprint(\"State 1: μ = $μ_1, σ² = $(Σ_1[1,1]) (tight cluster)\\n\")\nprint(\"State 2: μ = $μ_2, σ² = $(Σ_2[1,1]) (looser cluster)\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Sample-from-the-HMM","page":"Hidden Markov Model Example","title":"Sample from the HMM","text":"Generate synthetic data from our true model. Each state generates observations from its own Gaussian distribution without requiring input features. The rand function samples both the hidden state sequence and the corresponding observations.\n\nnum_samples = 10000;\ntrue_labels, data = rand(rng, model, n=num_samples);\nnothing #hide","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Visualize-the-Sampled-Dataset","page":"Hidden Markov Model Example","title":"Visualize the Sampled Dataset","text":"Create a 2D scatter plot showing observations colored by their true hidden state. This illustrates how each state generates observations from a distinct region of space. We will also plot a trajectory line to show the temporal evolution for the first 1000 timepoints.\n\nx_vals = data[1, 1:num_samples]\ny_vals = data[2, 1:num_samples]\nlabels_slice = true_labels[1:num_samples]\n\nstate_colors = [:dodgerblue, :crimson]\n\np1 = plot()\n\nfor state in 1:2\n    idx = findall(labels_slice .== state)\n    scatter!(x_vals[idx], y_vals[idx];\n        color=state_colors[state],\n        label=\"State $state\",\n        markersize=3,\n        alpha=0.6)\nend\n\nplot!(x_vals[1:1000], y_vals[1:1000];\n    color=:gray, lw=1, alpha=0.3, label=\"Trajectory\")\n\nscatter!([x_vals[1]], [y_vals[1]]; marker=:star5, markersize=8,\n         color=:green, label=\"Start\")\nscatter!([x_vals[end]], [y_vals[end]]; marker=:diamond, markersize=6,\n         color=:black, label=\"End\")\n\nplot!(xlabel=L\"x_1\", ylabel=L\"x_2\",\n      title=\"HMM Emissions by True Hidden State\",\n      legend=:topleft)","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Initialize-and-Fit-HMM-with-EM","page":"Hidden Markov Model Example","title":"Initialize and Fit HMM with EM","text":"In reality, we only observe the data, not the hidden states. The goal of fitting is to learn the latent state sequence and the model parameters that best explain the data. We will initialize a new HMM with incorrect parameters and use the Expectation-Maximization (EM) algorithm to iteratively refine the parameters and infer the hidden states.\n\nμ_1_init = [-0.25, -0.25]  # Closer to center than true\nΣ_1_init = 0.3 * Matrix{Float64}(I, output_dim, output_dim)  # Larger variance\nemission_1_init = GaussianEmission(output_dim=output_dim, μ=μ_1_init, Σ=Σ_1_init);\n\nμ_2_init = [0.25, 0.25]    # Closer to center than true\nΣ_2_init = 0.5 * Matrix{Float64}(I, output_dim, output_dim)  # Much larger variance\nemission_2_init = GaussianEmission(output_dim=output_dim, μ=μ_2_init, Σ=Σ_2_init);\n\nA_init = [0.8 0.2; 0.05 0.95]  # Less persistent than true model\nπₖ_init = [0.6, 0.4];           # Biased toward state 1\n\ntest_model = HiddenMarkovModel(K=2, B=[emission_1_init, emission_2_init],\n                              A=A_init, πₖ=πₖ_init);\nnothing #hide\n\nFit using Expectation-Maximization\n\nlls = fit!(test_model, data);\n\nprint(\"EM converged in $(length(lls)) iterations\\n\")\nprint(\"Log-likelihood improved by $(round(lls[end] - lls[1], digits=1))\\n\");\nnothing #hide\n\nPlot EM convergence\n\np2 = plot(lls, xlabel=\"EM Iteration\", ylabel=\"Log-Likelihood\",\n          title=\"EM Algorithm Convergence\", legend=false,\n          marker=:circle, markersize=3, lw=2, color=:darkblue)\n\np2","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Hidden-State-Decoding-with-Viterbi","page":"Hidden Markov Model Example","title":"Hidden State Decoding with Viterbi","text":"Now that we have learned the model parameters from the observed data, we can decode the most likely sequence of hidden states using the Viterbi algorithm. Then, in this toy example where we know the true latent state path, we can assess the accuracy of our state predictions.\n\npred_labels = viterbi(test_model, data);\n\naccuracy = mean(true_labels .== pred_labels)\n\nCalling a specific set of parameters \"state 1\" and \"state 2\" is arbitrary and does not affect the correctness of the model. The EM algorithm can converge with the states swapped from our original convention. We check for this and correct it if necessary.\n\nswapped_pred = 3 .- pred_labels  # Convert 1→2, 2→1\nswapped_accuracy = mean(true_labels .== swapped_pred)\n\nif swapped_accuracy > accuracy\n    pred_labels = swapped_pred\n    accuracy = swapped_accuracy\n    print(\"Detected and corrected label switching\\n\")\nend\n\nprint(\"State prediction accuracy: $(round(accuracy*100, digits=1))%\\n\");\nnothing #hide\n\nOur model looks like it is doing pretty well! Let's visualize the predicted and true state sequences as heatmaps (first 1000 timepoints)\n\nn_display = 1000\ntrue_seq = reshape(true_labels[1:n_display], 1, :)\npred_seq = reshape(pred_labels[1:n_display], 1, :)\n\np3 = plot(\n    heatmap(true_seq, colormap=:roma, title=\"True State Sequence\",\n           xticks=false, yticks=false, colorbar=false),\n    heatmap(pred_seq, colormap=:roma, title=\"Predicted State Sequence (Viterbi)\",\n           xlabel=\"Time Steps (1-$n_display)\", xticks=0:200:n_display,\n           yticks=false, colorbar=false),\n    layout=(2, 1), size=(800, 300)\n)","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Multiple-Independent-Trials","page":"Hidden Markov Model Example","title":"Multiple Independent Trials","text":"Many real applications involve multiple independent sequences (e.g., multiple subjects, sessions, or trials). In StateSpaceDynamics.jl, it is easy to incorporate data from multiple trials in parameters learning. Once again, we will generate a synthetic dataset from our ground truth model to illustrate this process.\n\nn_trials = 100    # Number of independent sequences\nn_samples = 1000  # Length of each sequence\n\nall_true_labels = Vector{Vector{Int}}(undef, n_trials);\nall_data = Vector{Matrix{Float64}}(undef, n_trials);\n\nfor i in 1:n_trials  # Sample each trial independently\n    labels_trial, data_trial = rand(rng, model, n=n_samples)\n    all_true_labels[i] = labels_trial\n    all_data[i] = data_trial\nend\n\ntotal_state1_prop = mean([mean(labels .== 1) for labels in all_true_labels])\nprint(\"Average State 1 proportion: $(round(total_state1_prop, digits=3))\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Multi-Trial-HMM-Fitting","page":"Hidden Markov Model Example","title":"Multi-Trial HMM Fitting","text":"When fitting to multiple independent sequences, EM accounts for each sequence starting independently from the initial state distribution. Here, we initialize a new model and fit it to all trials simultaneously.\n\ntest_model_multi = HiddenMarkovModel(\n    K=2,\n    B=[deepcopy(emission_1_init), deepcopy(emission_2_init)],\n    A=A_init, πₖ=πₖ_init\n)\n\nlls_multi = fit!(test_model_multi, all_data);\nnothing #hide\n\nLet's check on how our training went and what parameters we learned.\n\nprint(\"Multi-trial EM converged in $(length(lls_multi)) iterations\\n\")\nprint(\"Log-likelihood improved by $(round(lls_multi[end] - lls_multi[1], digits=1))\\n\");\nprint(\"Multi-trial learned parameters:\\n\")\nprint(\"State 1: μ = $(round.(test_model_multi.B[1].μ, digits=3)), σ² = $(round(test_model_multi.B[1].Σ[1,1], digits=3))\\n\")\nprint(\"State 2: μ = $(round.(test_model_multi.B[2].μ, digits=3)), σ² = $(round(test_model_multi.B[2].Σ[1,1], digits=3))\\n\");\nnothing #hide\n\nVisualize multi-trial EM convergence\n\np4 = plot(lls_multi, xlabel=\"EM Iteration\", ylabel=\"Log-Likelihood\",\n          title=\"Multi-Trial EM Convergence\", legend=false,\n          marker=:circle, markersize=3, lw=2, color=:darkgreen)","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Multi-Trial-State-Decoding","page":"Hidden Markov Model Example","title":"Multi-Trial State Decoding","text":"Now that we have done parameter learning, we can use Viterbi to find the most likely hidden state sequence for each trial with a single function call.\n\nall_pred_labels_vec = viterbi(test_model_multi, all_data);\n\nall_pred_labels = hcat(all_pred_labels_vec...)';      # trials × time\nall_true_labels_matrix = hcat(all_true_labels...)';   # trials × time\n\nCalculate overall accuracy across all trials accounting for label switching\n\noverall_accuracy = mean(all_true_labels_matrix .== all_pred_labels);\n\nswapped_pred_all = 3 .- all_pred_labels;\nswapped_accuracy_all = mean(all_true_labels_matrix .== swapped_pred_all);\n\nif swapped_accuracy_all > overall_accuracy\n    all_pred_labels = swapped_pred_all\n    overall_accuracy = swapped_accuracy_all\n    print(\"Corrected label switching in multi-trial analysis\\n\")\nend\n\nprint(\"Overall state prediction accuracy: $(round(overall_accuracy*100, digits=1))%\\n\");\nnothing #hide\n\nWe can also look at per-trial accuracies to see how consistent the model is across trials.\n\ntrial_accuracies = [mean(all_true_labels_matrix[i, :] .== all_pred_labels[i, :]) for i in 1:n_trials]\nprint(\"Per-trial accuracy: $(round(mean(trial_accuracies)*100, digits=1))% ± $(round(std(trial_accuracies)*100, digits=1))%\\n\");\nnothing #hide\n\nVisualize subset of trials (first 10 trials, first 500 timepoints)\n\nn_trials_display = 10\nn_time_display = 500\n\ntrue_subset = all_true_labels_matrix[1:n_trials_display, 1:n_time_display]\npred_subset = all_pred_labels[1:n_trials_display, 1:n_time_display]\n\np5 = plot(\n    heatmap(true_subset, colormap=:roma, title=\"True States ($n_trials_display trials)\",\n           xticks=false, ylabel=\"Trial\", colorbar=false),\n    heatmap(pred_subset, colormap=:roma, title=\"Predicted States (Viterbi)\",\n           xlabel=\"Time Steps\", ylabel=\"Trial\", colorbar=false),\n    layout=(2, 1), size=(900, 400)\n)","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Parameter-Recovery-Assessment","page":"Hidden Markov Model Example","title":"Parameter Recovery Assessment","text":"Since we have access to the true model parameters, we can quantitatively assess how well the multi-trial fitting procedure recovered them.\n\ntrue_μ1_orig, true_μ2_orig = [-1.0, -1.0], [1.0, 1.0]\nlearned_μ1 = test_model_multi.B[1].μ\nlearned_μ2 = test_model_multi.B[2].μ\n\nCompare emission model mean vectors\n\nμ1_error = norm(true_μ1_orig - learned_μ1) / norm(true_μ1_orig)\nμ2_error = norm(true_μ2_orig - learned_μ2) / norm(true_μ2_orig)\n\nprint(\"Mean vector recovery errors:\\n\")\nprint(\"State 1: $(round(μ1_error*100, digits=1))%, State 2: $(round(μ2_error*100, digits=1))%\\n\")\n\nCompare covariance matrices\n\ntrue_Σ1_orig, true_Σ2_orig = 0.1, 0.2\nlearned_Σ1 = test_model_multi.B[1].Σ[1,1]\nlearned_Σ2 = test_model_multi.B[2].Σ[1,1]\n\nΣ1_error = abs(true_Σ1_orig - learned_Σ1) / true_Σ1_orig\nΣ2_error = abs(true_Σ2_orig - learned_Σ2) / true_Σ2_orig\n\nprint(\"Variance recovery errors:\\n\")\nprint(\"State 1: $(round(Σ1_error*100, digits=1))%, State 2: $(round(Σ2_error*100, digits=1))%\\n\");\nnothing #hide\n\nCompare transition matrices\n\ntrue_A_orig = [0.99 0.01; 0.05 0.95]\nA_error = norm(true_A_orig - test_model_multi.A) / norm(true_A_orig)\nprint(\"Transition matrix error: $(round(A_error*100, digits=1))%\\n\")","category":"section"},{"location":"tutorials/hidden_markov_model_example/#Summary","page":"Hidden Markov Model Example","title":"Summary","text":"This tutorial demonstrated the complete workflow for Gaussian emission Hidden Markov Models. We covered how to create, sample from, fit, and perform state inference with HMMs using StateSpaceDynamics.jl.\n\nKey Concepts:\n\nDiscrete hidden states with Gaussian emission distributions\nTemporal dependencies through Markovian state transitions\nEM algorithm for joint parameter learning and state inference\nViterbi decoding for finding most likely state sequences\n\nTechnical Insights:\n\nLabel switching is a common identifiability issue requiring detection and correction\nMulti-trial analysis provides more robust parameter estimates than single sequences\nParameter recovery quality depends on state separation and sequence length\nConvergence monitoring through log-likelihood plots ensures proper algorithm behavior\n\nApplications:\n\nTime series clustering and regime detection\nBehavioral state analysis in sequential data\nExploratory analysis of temporal datasets with latent structure\nFoundation for more complex state-space models\n\nGaussian HMMs provide a fundamental framework for modeling sequential data with discrete latent structure, serving as both standalone models and building blocks for more sophisticated probabilistic time series methods.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#Simulating-and-Fitting-a-Probabilistic-PCA-(PPCA)-Model","page":"Probabilistic PCA Example","title":"Simulating and Fitting a Probabilistic PCA (PPCA) Model","text":"This tutorial demonstrates Probabilistic PCA (PPCA) in StateSpaceDynamics.jl: simulating data, fitting with EM, and interpreting results. PPCA is a maximum-likelihood, probabilistic version of PCA with an explicit latent-variable generative model and noise model.","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#The-PPCA-Model","page":"Probabilistic PCA Example","title":"The PPCA Model","text":"The generative model for observations mathbfx in mathbbR^D with k latent factors: mathbfz sim mathcalN(mathbf0 mathbfI_k) quad mathbfx  mathbfz sim mathcalN(boldsymbolmu + mathbfWmathbfz sigma^2 mathbfI_D)\n\nwhere mathbfW in mathbbR^D times k (factor loadings), boldsymbolmu in mathbbR^D (mean), and sigma^2  0 (isotropic noise variance).\n\nKey properties:\n\nMarginal covariance: textCov(mathbfx) = mathbfWmathbfW^T + sigma^2 mathbfI\nAs sigma^2 to 0, PPCA approaches standard PCA\nRotational non-identifiability: mathbfWmathbfR for orthogonal mathbfR spans same subspace\n\nPosterior over latents: Given observation mathbfx, the posterior is Gaussian with: mathbfM = mathbfI_k + frac1sigma^2mathbfW^TmathbfW quad mathbbEmathbfzmathbfx = mathbfM^-1mathbfW^T(mathbfx-boldsymbolmu)sigma^2","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#Load-Required-Packages","page":"Probabilistic PCA Example","title":"Load Required Packages","text":"using StateSpaceDynamics\nusing LinearAlgebra\nusing Random\nusing Plots\nusing StatsPlots\nusing StableRNGs\nusing Distributions\nusing LaTeXStrings\n\nSet reproducible randomness for simulation and initialization\n\nrng = StableRNG(1234);\nnothing #hide","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#Create-and-Simulate-PPCA-Model","page":"Probabilistic PCA Example","title":"Create and Simulate PPCA Model","text":"We'll work in 2D with two latent factors for easy visualization and interpretation.\n\nD = 2  # Observation dimensionality\nk = 2  # Number of latent factors\n\nTrue parameters for data generation\n\nW_true = [-1.64  0.2;   # Factor loading matrix\n           0.9  -2.8]\nσ²_true = 0.5           # Noise variance\nμ_true = [1.65, -1.3];  # Mean vector\n\nppca = ProbabilisticPCA(W_true, σ²_true, μ_true)\n\nGenerate synthetic data\n\nnum_obs = 500\nX, z = rand(rng, ppca, num_obs);\n\nprint(\"Generated $num_obs observations in $D dimensions with $k latent factors\\n\")\nprint(\"Data range: X₁ ∈ [$(round(minimum(X[1,:]), digits=2)), $(round(maximum(X[1,:]), digits=2))], \")\nprint(\"X₂ ∈ [$(round(minimum(X[2,:]), digits=2)), $(round(maximum(X[2,:]), digits=2))]\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#Visualize-Simulated-Data","page":"Probabilistic PCA Example","title":"Visualize Simulated Data","text":"Color points by dominant latent dimension for intuition (latent variables are unobserved in practice)\n\nx1, x2 = X[1, :], X[2, :]\nlabels = [abs(z[1,i]) > abs(z[2,i]) ? 1 : 2 for i in 1:size(z,2)]\n\np1 = scatter(x1, x2;\n    group=labels, xlabel=L\"X_1\", ylabel=L\"X_2\",\n    title=\"Simulated Data (colored by dominant latent factor)\",\n    markersize=4, alpha=0.7,\n    palette=[:dodgerblue, :crimson],\n    legend=:topright\n)","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#Fit-PPCA-Using-EM-Algorithm","page":"Probabilistic PCA Example","title":"Fit PPCA Using EM Algorithm","text":"Start from random initialization and use EM to learn parameters. The algorithm maximizes the marginal log-likelihood of the observed data.\n\nInitialize with random parameters\n\nW_init = randn(rng, D, k)\nσ²_init = 0.5\nμ_init = randn(rng, D)\n\nfit_ppca = ProbabilisticPCA(W_init, σ²_init, μ_init)\n\nprint(\"Running EM algorithm...\")\n\nFit with EM - returns log-likelihood trace for convergence monitoring\n\nlls = fit!(fit_ppca, X);\n\nprint(\"EM converged in $(length(lls)) iterations\\n\")\nprint(\"Log-likelihood improved by $(round(lls[end] - lls[1], digits=1))\\n\");\nnothing #hide\n\nMonitor EM convergence - should show monotonic increase\n\np2 = plot(lls;\n    xlabel=\"Iteration\", ylabel=\"Log-Likelihood\",\n    title=\"EM Convergence\", marker=:circle, markersize=3,\n    lw=2, legend=false, color=:darkblue\n)","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#Visualize-Learned-Loading-Directions","page":"Probabilistic PCA Example","title":"Visualize Learned Loading Directions","text":"The columns of mathbfW span the principal subspace (up to rotation). We'll plot these loading vectors from the learned mean.\n\nμ_fit = fit_ppca.μ\nW_fit = fit_ppca.W\nw1, w2 = W_fit[:, 1], W_fit[:, 2]\n\np3 = scatter(x1, x2;\n    xlabel=L\"X_1\", ylabel=L\"X_2\",\n    title=\"Data with Learned PPCA Loading Directions\",\n    label=\"Data\", alpha=0.5, markersize=3, color=:gray\n)\n\nscale = 2.0  # Scale for better visualization\nquiver!(p3, [μ_fit[1]], [μ_fit[2]];\n    quiver=([scale*w1[1]], [scale*w1[2]]),\n    arrow=:arrow, lw=3, color=:red, label=\"W₁\")\nquiver!(p3, [μ_fit[1]], [μ_fit[2]];\n    quiver=([-scale*w1[1]], [-scale*w1[2]]),\n    arrow=:arrow, lw=3, color=:red, label=\"\")\nquiver!(p3, [μ_fit[1]], [μ_fit[2]];\n    quiver=([scale*w2[1]], [scale*w2[2]]),\n    arrow=:arrow, lw=3, color=:green, label=\"W₂\")\nquiver!(p3, [μ_fit[1]], [μ_fit[2]];\n    quiver=([-scale*w2[1]], [-scale*w2[2]]),\n    arrow=:arrow, lw=3, color=:green, label=\"\")","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#Posterior-Inference-and-Reconstruction","page":"Probabilistic PCA Example","title":"Posterior Inference and Reconstruction","text":"Compute posterior means mathbbEmathbfzmathbfx and reconstructions hatmathbfx = boldsymbolmu + mathbfWmathbbEmathbfzmathbfx\n\nfunction ppca_posterior_means(W::AbstractMatrix, σ²::Real, μ::AbstractVector, X::AbstractMatrix)\n    k = size(W, 2)\n    M = I(k) + (W' * W) / σ²            # Posterior precision matrix\n    B = M \\ (W' / σ²)                   # Efficient computation of M⁻¹W^T/σ²\n    Z_mean = B * (X .- μ)               # Posterior means\n    return Z_mean\nend\n\nCompute posterior latent means and reconstructions\n\nẐ = ppca_posterior_means(W_fit, fit_ppca.σ², μ_fit, X)\nX̂ = μ_fit .+ W_fit * Ẑ\n\nCalculate reconstruction error\n\nrecon_mse = mean(sum((X - X̂).^2, dims=1)) / D\nprint(\"Reconstruction MSE: $(round(recon_mse, digits=4))\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#Variance-Explained-Analysis","page":"Probabilistic PCA Example","title":"Variance Explained Analysis","text":"Compare sample covariance eigenvalues to PPCA model structure. PPCA should capture top-k eigenvalues via mathbfWmathbfW^T and approximate remainder with isotropic noise sigma^2.\n\nΣ_sample = cov(X, dims=2)  # Sample covariance matrix\nλs = sort(eigvals(Σ_sample), rev=true)  # Eigenvalues in descending order\n\nProportion of variance explained by top-k eigenvalues\n\npve_sample = sum(λs[1:k]) / sum(λs)\n\nPPCA-implied variance components\n\ntotal_var_ppca = tr(W_fit * W_fit') + D * fit_ppca.σ²\nexplained_var_ppca = tr(W_fit * W_fit')\npve_ppca = explained_var_ppca / total_var_ppca\n\nprint(\"Variance Analysis:\\n\")\nprint(\"Sample eigenvalues: $(round.(λs, digits=3))\\n\")\nprint(\"PVE (sample top-$k): $(round(pve_sample*100, digits=1))%\\n\")\nprint(\"PVE (PPCA model): $(round(pve_ppca*100, digits=1))%\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#Parameter-Recovery-Assessment","page":"Probabilistic PCA Example","title":"Parameter Recovery Assessment","text":"print(\"\\n=== Parameter Recovery Assessment ===\\n\")\n\nCompare true vs learned parameters\n\nW_error = norm(W_true - W_fit) / norm(W_true)\nμ_error = norm(μ_true - μ_fit) / norm(μ_true)\nσ²_error = abs(σ²_true - fit_ppca.σ²) / σ²_true\n\nprint(\"Parameter recovery errors:\\n\")\nprint(\"Loading matrix W: $(round(W_error*100, digits=1))%\\n\")\nprint(\"Mean vector μ: $(round(μ_error*100, digits=1))%\\n\")\nprint(\"Noise variance σ²: $(round(σ²_error*100, digits=1))%\\n\")\n\nprint(\"True parameters:\\n\")\nprint(\"W = $(round.(W_true, digits=2))\\n\")\nprint(\"μ = $(round.(μ_true, digits=2)), σ² = $(σ²_true)\\n\")\n\nprint(\"Learned parameters:\\n\")\nprint(\"W = $(round.(W_fit, digits=2))\\n\")\nprint(\"μ = $(round.(μ_fit, digits=2)), σ² = $(round(fit_ppca.σ², digits=2))\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#Model-Selection-Example","page":"Probabilistic PCA Example","title":"Model Selection Example","text":"Demonstrate fitting models with different numbers of latent factors and comparing via information criteria.\n\nfunction compute_aic_bic(ll::Real, n_params::Int, n_obs::Int)\n    aic = 2*n_params - 2*ll\n    bic = n_params*log(n_obs) - 2*ll\n    return (aic, bic)\nend\n\nprint(\"\\n=== Model Selection Demo ===\\n\")\n\nk_range = 1:min(D, 4)\naic_scores = Float64[]\nbic_scores = Float64[]\nlls_final = Float64[]\n\nfor k_test in k_range\n    W_test = randn(rng, D, k_test) # Initialize and fit model with k_test factors\n    ppca_test = ProbabilisticPCA(W_test, 0.5, zeros(D))\n    lls_test = fit!(ppca_test, X)\n\n    n_params = D * k_test + D + 1 # Parameter count: D*k_test (W) + D (μ) + 1 (σ²)\n    ll_final = lls_test[end]\n    aic, bic = compute_aic_bic(ll_final, n_params, num_obs)  # Calculate information criteria\n\n    push!(aic_scores, aic)\n    push!(bic_scores, bic)\n    push!(lls_final, ll_final)\n\n    print(\"k=$k_test: LL=$(round(ll_final, digits=1)), AIC=$(round(aic, digits=1)), BIC=$(round(bic, digits=1))\\n\")\nend\n\nPlot information criteria\n\np4 = plot(k_range, [aic_scores bic_scores];\n    xlabel=\"Number of Latent Factors (k)\", ylabel=\"Information Criterion\",\n    title=\"Model Selection via Information Criteria\",\n    label=[\"AIC\" \"BIC\"], marker=:circle, lw=2\n)\n\noptimal_k = k_range[argmin(bic_scores)]\nprint(\"BIC suggests optimal k = $optimal_k\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/Probabilistic_PCA_example/#Summary","page":"Probabilistic PCA Example","title":"Summary","text":"This tutorial demonstrated the complete Probabilistic PCA workflow:\n\nKey Concepts:\n\nProbabilistic framework: Explicit generative model with latent factors and noise\nEM algorithm: Iterative maximum-likelihood parameter estimation\nPosterior inference: Probabilistic latent variable estimates and reconstructions\nModel selection: Information criteria for choosing appropriate number of factors\n\nAdvantages over Standard PCA:\n\nPrincipled handling of missing data and noise\nProbabilistic interpretation enables uncertainty quantification\nNatural framework for model selection and comparison\nSeamless extension to more complex latent variable models\n\nApplications:\n\nDimensionality reduction for high-dimensional data\nExploratory data analysis and visualization\nFeature extraction for machine learning pipelines\nFoundation for more complex factor models and state-space models\n\nTechnical Insights:\n\nLoading matrix mathbfW captures principal directions of variation\nNoise parameter sigma^2 quantifies unexplained variance\nRotational non-identifiability requires care in interpretation\nEM convergence monitoring ensures reliable parameter estimates\n\nPPCA provides a flexible, probabilistic approach to factor analysis that bridges classical multivariate statistics with modern latent variable modeling, serving as both a standalone technique and building block for more sophisticated models.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"HiddenMarkovModels/#What-is-a-Hidden-Markov-Model?","page":"Hidden Markov Models","title":"What is a Hidden Markov Model?","text":"A Hidden Markov Model (HMM) is a graphical model that describes how systems change over time. When modeling a time series with T observations using an HMM, we assume that the observed data y_1T depends on hidden states x_1T that are not observed. Specifically, an HMM is a type of state-space model in which the hidden states are discrete.\n\nThe three components of an HMM are as follows:\n\nAn initial state distribution (pi): which hidden states we are likely to start in.\nA transition matrix (A): how the hidden states evolve over time.\nAn emission model: how the hidden states generate the observed data.\n\nThe generative model is given by:\n\nbeginalign*\n    x_1 sim textCat(pi) \n    x_t mid x_t-1 sim textCat(A_x_t-1 ) \n    y_t mid x_t sim p(y_t mid theta_x_t)\nendalign*\n\nWhere:\n\nx_t is the hidden (discrete) state at time t\ny_t is the observed data at time t\npi is the initial state distribution\nmathbfA is the state transition matrix\ntheta_x_t are the parameters of the emission distribution for state x_t\n\nThe emission model can take many forms: Gaussian, Poisson, Bernoulli, categorical, etc... In the case of a Gaussian emission distribution, this becomes:\n\ny_t mid (x_t = k) sim mathcalN(mu_k Sigma_k)\n\nWhere:\n\nmu_k is the mean of the emission distribution for state k\nSigma_k is the covariance of the emission distribution for state k","category":"section"},{"location":"HiddenMarkovModels/#What-is-a-Generalized-Linear-Model-Hidden-Markov-Model","page":"Hidden Markov Models","title":"What is a Generalized Linear Model - Hidden Markov Model","text":"A Hidden Markov Model - Generalized Linear Model (GLM-HMM) - also known as Switching Regression Model - is an extension to classic HMMs where the emission models are state-dependent GLMs that link an observed input to an observed output. This formulation allows each hidden state to define its own regression relationship between inputs and outputs, enabling the model to capture complex, state-dependent dynamics in the data. Currently, StateSpaceDynamics.jl support Gaussian, Bernoulli, Poisson, and Autoregressive GLMs as emission models.\n\nThe generative model is as follows:\n\nbeginalign*\n    x_1 sim textCat(pi) \n    x_t mid x_t-1 sim textCat(A_x_t-1 ) \n    y_t mid x_t u_t sim p(y_t mid theta_x_t u_t)\nendalign*\n\nWhere:\n\nx_t is the hidden (discrete) state at time t\ny_t is the observed output at time t\nu_t is the observed input (covariate) at time t\ntheta_x_t are the parameters of the GLM emission model for state x_t","category":"section"},{"location":"HiddenMarkovModels/#Example-Emission-Models","page":"Hidden Markov Models","title":"Example Emission Models","text":"For example, if the emission is a Gaussian GLM:\n\ny_t mid (x_t = k) u_t sim mathcalN(mu_k + beta_k^top u_t sigma_k^2)\n\nWhere:\n\nbeta_k are the regression weights for state k\nsigma_k^2 is the state-dependent variance\nmu_k is the state-dependent bias\n\nIf the emission is Bernoulli (for binary outputs):\n\ny_t mid (x_t = k) u_t sim textBernoulli left( sigma left( mu_k + beta_k^top u_t right) right)\n\nWhere:\n\nbeta_k are the regression weights for state k\nsigma(cdot) is the logistic sigmoid function for binary outputs\nmu_k is the state-dependent bias","category":"section"},{"location":"HiddenMarkovModels/#Sampling-from-an-HMM","page":"Hidden Markov Models","title":"Sampling from an HMM","text":"You can generate synthetic data from an HMM:","category":"section"},{"location":"HiddenMarkovModels/#Learning-in-an-HMM","page":"Hidden Markov Models","title":"Learning in an HMM","text":"StateSpaceDynamics.jl implements Expectation-Maximization (EM) for parameter learning in both HMMs and GLM-HMMs. EM is an iterative method for finding maximum likelihood estimates of the parameters in graphical models with hidden variables. \n\nwarning: Identifiability caveats in HMMs (and GLM-HMMs)\nHMM parameters are not uniquely identifiable. For any permutation matrix P that relabels the K hidden states, the reparameterizationbeginaligned\npi = Ppi\nA = PAP^top\ntheta_k = theta_P^top k\nendalignedyields the same likelihood. Consequences:Label switching: state indices are arbitrary; EM runs can return permuted states.\nDegenerate solutions: with Gaussian emissions, likelihood can blow up by shrinking a component’s variance onto a few points; with GLM emissions, separation or collinearity can make parameters diverge.\nNon-unique GLM parametrizations: standard GLM identifiability issues apply (e.g., intercept vs. redundant dummy variables, collinear covariates).Practical remediesCanonicalize state order after each fit (or each EM iteration) using a criterion such as descending stationary probability, mean emission value, or a chosen scalar summary.\nPost-hoc alignment across runs: match states with a Hungarian/Procrustes step using emission statistics or posterior state occupancies.\nRegularize emissions:   Gaussian: add priors/penalties, variance floors, tied/diagonal Sigma_k;   GLM: L_2L_1 penalties, remove/orthogonalize collinear features, use reference coding.\nStabilize transitions: Dirichlet priors or pseudocounts on pi and A; avoid zero rows/columns.\nReport with uncertainty: prefer state-invariant summaries (likelihood, predictive metrics). When interpreting parameters, note that labels are arbitrary.","category":"section"},{"location":"HiddenMarkovModels/#Expectation-Step-(E-step)","page":"Hidden Markov Models","title":"Expectation Step (E-step)","text":"In the expectation step (E-step), we calculate the posterior distribution of the latent states given the current parameters of the model:\n\np(X mid Y theta_textold)\n\nWe use dynamic programming to efficiently calculate this posterior using the forward and backward recursions for HMMs. This posterior is then used to construct the expectation of the complete data log-likelihood, also known as the Q-function:\n\nQ(theta theta_textold) = sum_X p(X mid Y theta_textold) ln p(Y X mid theta)","category":"section"},{"location":"HiddenMarkovModels/#Maximization-Step-(M-step)","page":"Hidden Markov Models","title":"Maximization Step (M-step)","text":"In the maximization step (M-step), we maximize this expectation with respect to the parameters theta. Specifically:\n\nFor the initial state distribution and the transition matrix, we use analytical updates for the parameters, derived using Lagrange multipliers.\nFor emission models in the case of HMMs, we also implement analytical updates.\nIf the emission model is a GLM, we use Optim.jl to numerically optimize the objective function.","category":"section"},{"location":"HiddenMarkovModels/#Inference-in-an-HMM","page":"Hidden Markov Models","title":"Inference in an HMM","text":"For state inference in Hidden Markov Models (HMMs), we implement two common algorithms:","category":"section"},{"location":"HiddenMarkovModels/#Forward-Backward-Algorithm","page":"Hidden Markov Models","title":"Forward-Backward Algorithm","text":"The Forward-Backward algorithm is used to compute the posterior state probabilities at each time step. Given the observed data, it calculates the probability of being in each possible hidden state at each time step, marginalizing over all possible state sequences.","category":"section"},{"location":"HiddenMarkovModels/#Viterbi-Algorithm","page":"Hidden Markov Models","title":"Viterbi Algorithm","text":"The Viterbi algorithm is used for best state sequence labeling. It finds the most likely sequence of hidden states given the observed data. This is done by dynamically computing the highest probability path through the state space, which maximizes the likelihood of the observed sequence.","category":"section"},{"location":"HiddenMarkovModels/#Reference","page":"Hidden Markov Models","title":"Reference","text":"For a complete mathematical formulation of the relevant HMM and HMM-GLM learning and inference algorithms, we recommend Pattern Recognition and Machine Learning, Chapter 13 by Christopher Bishop.","category":"section"},{"location":"HiddenMarkovModels/#StateSpaceDynamics.HiddenMarkovModel","page":"Hidden Markov Models","title":"StateSpaceDynamics.HiddenMarkovModel","text":"HiddenMarkovModel\n\nStore a Hidden Markov Model (HMM) with custom emissions.\n\nFields\n\nA::AbstractMatrix{<:Real}: Transition matrix.\nB::AbstractVector{<:EmissionModel}: State-dependent emission models.\nπₖ::AbstractVector{<:Real}: Initial state distribution.\nK::Int: Number of states.\n\n\n\n\n\n","category":"type"},{"location":"HiddenMarkovModels/#Base.rand","page":"Hidden Markov Models","title":"Base.rand","text":"Random.rand(\n    rng::AbstractRNG,\n    model::HiddenMarkovModel,\n    X::Union{Matrix{<:Real}, Nothing}=nothing;\n    n::Int,\n    autoregressive::Bool=false\n)\n\nGenerate n samples from a Hidden Markov Model. Returns a tuple of the state sequence and the observation sequence.\n\nArguments\n\nrng::AbstractRNG: The seed.\nmodel::HiddenMarkovModel: The Hidden Markov Model to sample from.\nX: The input data for switching regression models.\nn::Int: The number of samples to generate.\n\nReturns\n\nstate_sequence::Vector{Int}: The state sequence, where each element is an integer 1:K.\nobservation_sequence::Matrix{Float64}: The observation sequence. This takes the form of   the emission model's output.\n\n\n\n\n\n","category":"function"},{"location":"HiddenMarkovModels/#StateSpaceDynamics.fit!-Union{Tuple{T}, Tuple{HiddenMarkovModel, AbstractMatrix{T}}, Tuple{HiddenMarkovModel, AbstractMatrix{T}, Union{Nothing, AbstractMatrix{<:Real}}}} where T<:Real","page":"Hidden Markov Models","title":"StateSpaceDynamics.fit!","text":"fit!(\n    model::HiddenMarkovModel,\n    Y::Matrix{<:Real},\n    X::Union{Matrix{<:Real}, Nothing}=nothing\n    ;\n    max_iters::Int=100,\n    tol::Float64=1e-6\n)\n\nFit the Hidden Markov Model using the EM algorithm.\n\nArguments\n\nmodel::HiddenMarkovModel: The Hidden Markov Model to fit.\nY::Matrix{<:Real}: The emission data.\nX::Union{Matrix{<:Real}, Nothing}=nothing: Optional input data for fitting Switching   Regression Models\nmax_iters::Int=100: The maximum number of iterations to run the EM algorithm.\ntol::Float64=1e-6: When the log likelihood is improving by less than this value, the   algorithm will stop.\n\n\n\n\n\n","category":"method"},{"location":"HiddenMarkovModels/#StateSpaceDynamics.class_probabilities-Union{Tuple{T}, Tuple{HiddenMarkovModel, AbstractMatrix{T}}, Tuple{HiddenMarkovModel, AbstractMatrix{T}, Union{Nothing, AbstractMatrix{<:Real}}}} where T<:Real","page":"Hidden Markov Models","title":"StateSpaceDynamics.class_probabilities","text":"class_probabilities(\n    model::HiddenMarkovModel,\n    Y::Matrix{<:Real},\n    X::Union{Matrix{<:Real},Nothing}=nothing;\n)\n\nCalculate the class probabilities at each time point using forward backward algorithm\n\nArguments\n\nmodel::HiddenMarkovModel: The Hidden Markov Model to fit.\nY::Matrix{<:Real}: The emission data\nX::Union{Matrix{<:Real},Nothing}=nothing: Optional input data for fitting Switching   Regression Models\n\nReturns\n\nclass_probabilities::Matrix{Float64}: The class probabilities at each timepoint\n\n\n\n\n\n","category":"method"},{"location":"HiddenMarkovModels/#StateSpaceDynamics.viterbi-Union{Tuple{T}, Tuple{HiddenMarkovModel, AbstractMatrix{T}}, Tuple{HiddenMarkovModel, AbstractMatrix{T}, Union{Nothing, AbstractMatrix{<:Real}}}} where T<:Real","page":"Hidden Markov Models","title":"StateSpaceDynamics.viterbi","text":"viterbi(\n    model::HiddenMarkovModel,\n    Y::Matrix{<:Real},\n    X::Union{Matrix{<:Real},Nothing}=nothing\n)\n\nGet most likely class labels using the Viterbi algorithm\n\nArguments\n\nmodel::HiddenMarkovModel: The Hidden Markov Model to fit.\nY::Matrix{<:Real}: The emission data\nX::Union{Matrix{<:Real},Nothing}=nothing: Optional input data for fitting Switching   Regression Models\n\nReturns\n\nbest_path::Vector{Float64}: The most likely state label at each timepoint\n\n\n\n\n\n","category":"method"},{"location":"tutorials/lds_identifiability_example/#Understanding-Non-Identifiability-in-Linear-Dynamical-Systems","page":"Non-Identifiability in LDS Models","title":"Understanding Non-Identifiability in Linear Dynamical Systems","text":"This tutorial walks through the fundamental non-identifiability issues in Linear Dynamical Systems (LDS), shows them numerically, and adds Procrustes alignment so we can compare models \"apples to apples\". It follows a simple pattern:\n\nbuild a reference LDS and data; 2) generate equivalent models via similarity transforms; 3) show identical likelihood/predictions; 4) align states/parameters with Procrustes; 5) summarize diagnostics and discuss what is identifiable.","category":"section"},{"location":"tutorials/lds_identifiability_example/#Load-Required-Packages","page":"Non-Identifiability in LDS Models","title":"Load Required Packages","text":"using StateSpaceDynamics\nusing LinearAlgebra\nusing Random\nusing Plots\nusing Statistics\nusing StableRNGs\nusing Printf\n\nrng = StableRNG(12345);\nnothing #hide","category":"section"},{"location":"tutorials/lds_identifiability_example/#Create-a-Reference-(\"True\")-LDS","page":"Non-Identifiability in LDS Models","title":"Create a Reference (\"True\") LDS","text":"K_true = 3  # latent dimensionality\nD      = 8  # observation dimensionality\nT      = 200;  # time steps for training/demo\nnothing #hide\n\nStable but nontrivial dynamics\n\nA_true = [0.9  0.1  0.0;\n          -0.1 0.8  0.2;\n           0.0 0.0  0.7];\n\nb_true = zeros(K_true)\n\nQ_true = 0.05 * Matrix(I(K_true));\nnothing #hide\n\nObservation matrix with interpretable rows\n\nC_true = [1.0  0.5  0.0;   # Obs 1: mainly latent dim 1\n          0.8  0.3  0.1;   # Obs 2: mix of dims 1 & 2\n          0.2  1.0  0.0;   # Obs 3: mainly latent dim 2\n          0.0  0.7  0.4;   # Obs 4: dims 2 & 3\n          0.1  0.2  0.9;   # Obs 5: mainly latent dim 3\n          0.3  0.0  0.8;   # Obs 6: dims 1 & 3\n          0.6  0.4  0.2;   # Obs 7: mixture\n          0.4  0.6  0.5]   # Obs 8: mixture\nd_true = zeros(D)\n\nR_true  = 0.1 * Matrix(I(D))\nx0_true = zeros(K_true)\nP0_true = 0.2 * Matrix(I(K_true))\n\ntrue_lds = LinearDynamicalSystem(\n    GaussianStateModel(A_true, Q_true, b_true, x0_true, P0_true),\n    GaussianObservationModel(C_true, R_true, d_true),\n    K_true, D, fill(true, 6)\n);\nnothing #hide\n\nGenerate data from the reference model\n\nx_true, y_true = rand(rng, true_lds; tsteps=T, ntrials=1)\n\nprint(\"Generated data from reference LDS model\n\")\nprint(\"True latent dynamics eigenvalues: \", round.(eigvals(A_true), digits=3), \"\n\")\nprint(\"Data variance explained by each latent dim: \", round.(var(x_true[:,:,1], dims=2)[:], digits=3), \"\n\")","category":"section"},{"location":"tutorials/lds_identifiability_example/#Non-Identifiability:-Similarity-(Rotation)-Invariance","page":"Non-Identifiability in LDS Models","title":"Non-Identifiability: Similarity (Rotation) Invariance","text":"For any invertible matrix R, the transformation produces an equivalent model:   A' = RAR⁻¹,   C' = CR⁻¹,   Q' = RQRᵀ,   x₀' = Rx₀,   P₀' = RP₀Rᵀ Such models yield identical likelihoods and predictions.\n\nA helper to build transformed copies\n\nfunction rotate_lds(lds, R)\n    A_rot = R * lds.state_model.A * inv(R)\n    Q_rot = R * lds.state_model.Q * R'\n    C_rot = lds.obs_model.C * inv(R)\n    x0_rot = R * lds.state_model.x0\n    P0_rot = R * lds.state_model.P0 * R'\n    return LinearDynamicalSystem(\n        GaussianStateModel(A_rot, Q_rot, b_true, x0_rot, P0_rot),\n        GaussianObservationModel(C_rot, lds.obs_model.R, d_true),\n        size(A_rot, 1), size(C_rot, 1), fill(true, 6)\n    )\nend\n\nA small mix of orthogonal and non-orthogonal transforms\n\nrotations = [\n    [cos(π/4) -sin(π/4) 0.0;  sin(π/4) cos(π/4) 0.0;  0.0 0.0 1.0],     # R1: rot in (1,2)\n    [1.0 0.0 0.0;              0.0 cos(π/2) -sin(π/2); 0.0 sin(π/2) cos(π/2)],  # R2: rot in (2,3) 90°\n    Matrix(qr(randn(rng, K_true, K_true)).Q),                             # R3: random orthogonal\n    [0.0 0.0 1.0; 0.0 1.0 0.0; 1.0 0.0 0.0],                              # R4: axis swap (1↔3)\n    Diagonal([2.0, 0.5, -1.2]) |> Matrix,                                 # R5: scaling + sign flip\n    [0.0 1.0 0.0; 1.0 0.0 0.0; 0.0 0.0 1.0]                               # R6: permutation (1↔2)\n]\n\nrot_names = [\n    \"R1: rot(1,2, 45°)\",\n    \"R2: rot(2,3, 90°)\",\n    \"R3: random orthogonal\",\n    \"R4: axis swap (1↔3)\",\n    \"R5: scaling+sign\",\n    \"R6: permutation (1↔2)\"\n]\n\nHelper diagnostics\n\nisorthogonal(R; atol=1e-10) = isapprox(R' * R, I(size(R,1)), atol=atol)\n\nfunction subspace_angles_deg(C1, C2)\n    Q1 = qr(C1).Q[:, 1:size(C1,2)]\n    Q2 = qr(C2).Q[:, 1:size(C2,2)]\n    σ = svdvals(Q1' * Q2)\n    σ = clamp.(σ, -1.0, 1.0)           # numerical safety\n    θ = acos.(σ)\n    return θ .* (180/π)\nend\n\nBuild rotated models\n\nrotated_models = [rotate_lds(true_lds, R) for R in rotations]\n\nCompute likelihoods: should match (up to numerical tolerance)\n\ny_data = reshape(y_true, D, T, 1)\nx_smooth_orig, _ = smooth(true_lds, y_data)\nll_orig = loglikelihood(x_smooth_orig[:,:,1], true_lds, y_true[:,:,1])\n\nprint(\"\n\" * \"=\"^60 * \"\n\")\nprint(\"ROTATION / SIMILARITY INVARIANCE DEMONSTRATION\n\")\nprint(\"=\"^60 * \"\n\")\n@printf(\"Original model likelihood: %.6f\n\", sum(ll_orig))\n\nfor (name, R, model) in zip(rot_names, rotations, rotated_models)\n    x_s_rot, _ = smooth(model, y_data)\n    ll_rot = loglikelihood(x_s_rot[:,:,1], model, y_true[:,:,1])\n    @printf(\"%-24s  LL: %.6f  ΔLL: %.3e  cond(R): %-8.2f  orth? %s\n\",\n            name, sum(ll_rot), sum(abs.(ll_rot - ll_orig)), cond(R), isorthogonal(R) ? \"yes\" : \"no\")\nend","category":"section"},{"location":"tutorials/lds_identifiability_example/#Visualize-Parameter-Differences-(Before-Alignment)","page":"Non-Identifiability in LDS Models","title":"Visualize Parameter Differences (Before Alignment)","text":"p1 = plot(layout=(2,2), size=(1000, 800))\nheatmap!(A_true, title=\"Original A\", color=:RdBu, subplot=1, aspect_ratio=:equal)\nheatmap!(rotated_models[3].state_model.A, title=\"Rotated A (R3)\", color=:RdBu, subplot=2, aspect_ratio=:equal)\nheatmap!(C_true, title=\"Original C\", color=:RdBu, subplot=3, aspect_ratio=:equal)\nheatmap!(rotated_models[3].obs_model.C, title=\"Rotated C (R3)\", color=:RdBu, subplot=4, aspect_ratio=:equal)","category":"section"},{"location":"tutorials/lds_identifiability_example/#Procrustes-Alignment:-Apples-to-Apples-Comparisons","page":"Non-Identifiability in LDS Models","title":"Procrustes Alignment: Apples-to-Apples Comparisons","text":"The latent coordinates are arbitrary: we can rotate them without changing the model's likelihood. To compare two fits (or a rotated copy) fairly, align the states with an orthogonal Procrustes transform R̂ that minimizes ‖R̂ X - Y‖_F.\n\nfunction procrustes_R(X::AbstractMatrix, Y::AbstractMatrix; proper::Bool=false)\n    S = svd(Y * X')\n    R̂ = S.U * S.Vt                    # (not S.U * S.V!)\n    if proper && det(R̂) < 0           # optionally enforce det=+1\n        U2 = copy(S.U); U2[:,end] .= -U2[:,end]\n        R̂ = U2 * S.Vt\n    end\n    return R̂\nend\n\nChoose R3 for demonstration (random orthogonal)\n\nR_idx = 3\nm_rot = rotated_models[R_idx]\nx_rot, _ = smooth(m_rot, y_data)\n\nRhat = procrustes_R(x_rot[:,:,1], x_smooth_orig[:,:,1])  # map rotated -> original\nstate_align_relerr = norm(Rhat * x_rot[:,:,1] - x_smooth_orig[:,:,1]) / norm(x_smooth_orig[:,:,1])\n@printf(\"\nProcrustes state alignment (R%d): rel. error = %.3e\n\", R_idx, state_align_relerr)\n\nAlign parameters via R̂ for direct visual comparison:   Ã = R̂ * Arot * R̂'     and     C̃ = Crot * R̂'\n\nA_rot_aligned = Rhat * m_rot.state_model.A * Rhat'\nC_rot_aligned = m_rot.obs_model.C * Rhat'\n\nΔA = norm(A_true - A_rot_aligned)\nΔC = norm(C_true - C_rot_aligned)\n@printf(\"Aligned parameter diffs (R%d): ||ΔA||=%.3e  ||ΔC||=%.3e\n\", R_idx, ΔA, ΔC)\n\nVisualize with matched color scales for fairness\n\nAmin = minimum([minimum(A_true), minimum(A_rot_aligned)])\nAmax = maximum([maximum(A_true), maximum(A_rot_aligned)])\nCmin = minimum([minimum(C_true), minimum(C_rot_aligned)])\nCmax = maximum([maximum(C_true), maximum(C_rot_aligned)])\n\np_align = plot(layout=(2,2), size=(1000, 800))\nheatmap!(A_true, title=\"Original A\", color=:RdBu, subplot=1, aspect_ratio=:equal, clims=(Amin, Amax))\nheatmap!(A_rot_aligned, title=\"Aligned A (R3)\", color=:RdBu, subplot=2, aspect_ratio=:equal, clims=(Amin, Amax))\nheatmap!(C_true, title=\"Original C\", color=:RdBu, subplot=3, aspect_ratio=:equal, clims=(Cmin, Cmax))\nheatmap!(C_rot_aligned, title=\"Aligned C (R3)\", color=:RdBu, subplot=4, aspect_ratio=:equal, clims=(Cmin, Cmax))\n\nResidual over time (after Procrustes): should be ~0 except numerical noise\n\nrestit = [norm(Rhat * x_rot[:, t, 1] - x_smooth_orig[:, t, 1]) for t in 1:T]\nplot(1:T, restit, lw=2, xlabel=\"time\", ylabel=\"‖R̂ x_rot − x_orig‖₂\",\n     title=\"Procrustes residual over time (R3)\")","category":"section"},{"location":"tutorials/lds_identifiability_example/#Invariants:-What-*is*-identifiable?","page":"Non-Identifiability in LDS Models","title":"Invariants: What is identifiable?","text":"Similarity transforms preserve certain summaries:\n\neigenvalues of A (up to ordering), hence modal timescales τ ≈ -1/log|λ|\ncolumn space of C (compare via principal angles)\n\nfunction invariants_summary(lds)\n    λ = eigvals(lds.state_model.A)\n    τ = [-1 / log(abs(l)) for l in λ]  # (real-mode heuristic)\n    return λ, τ\nend\n\nλ_true, τ_true = invariants_summary(true_lds)\n\nfor (i, (name, model)) in enumerate(zip(rot_names, rotated_models))\n    λ_i, τ_i = invariants_summary(model)\n    θ = subspace_angles_deg(C_true, model.obs_model.C)\n    @printf(\"Invariant check %-24s  max|Δλ|=%.2e  max|Δτ|=%.2e  max angle(C)=%.3f°\n\",\n            name,\n            maximum(abs.(sort(λ_true; by=abs) - sort(λ_i; by=abs))),\n            maximum(abs.(sort(τ_true; by=abs) - sort(τ_i; by=abs))),\n            maximum(θ))\nend","category":"section"},{"location":"tutorials/lds_identifiability_example/#Observational-Equivalence:-Predictions-Match","page":"Non-Identifiability in LDS Models","title":"Observational Equivalence: Predictions Match","text":"New data from a rotated model and prediction with both models should have identical error.\n\nx_rot_new, y_rot_new = rand(rng, rotated_models[1]; tsteps=100, ntrials=1)\n\ntest_data = reshape(y_rot_new, D, 100, 1)\n\nx_pred_orig, _ = smooth(true_lds, test_data)\ny_pred_orig = true_lds.obs_model.C * x_pred_orig[:, :, 1]\n\nx_pred_rot, _ = smooth(rotated_models[1], test_data)\ny_pred_rot = rotated_models[1].obs_model.C * x_pred_rot[:, :, 1]\n\nmse_orig = mean((y_rot_new[:, :, 1] - y_pred_orig).^2)\nmse_rot  = mean((y_rot_new[:, :, 1] - y_pred_rot).^2)\n@printf(\"\nPrediction MSE (same test seq): original=%.6f  rotated=%.6f\n\", mse_orig, mse_rot)","category":"section"},{"location":"tutorials/lds_identifiability_example/#Summary-Diagnostics-Across-Transforms","page":"Non-Identifiability in LDS Models","title":"Summary Diagnostics Across Transforms","text":"A compact table: ΔLL, cond(R), orthogonality, max subspace angle for C, and Procrustes alignment error versus the original smoothed states.\n\nstruct RotDiag\n    name::String\n    dLL::Float64\n    condR::Float64\n    orth::Bool\n    max_angle_deg::Float64\n    proc_relerr::Float64\nend\n\ndiagnostics = RotDiag[]\n\nfor (name, R, model) in zip(rot_names, rotations, rotated_models)\n    x_s, _ = smooth(model, y_data)\n    ll = loglikelihood(x_s[:,:,1], model, y_true[:,:,1])\n    dLL = sum(abs.(ll - ll_orig))\n    Rhat_i = procrustes_R(x_s[:,:,1], x_smooth_orig[:,:,1])\n    relerr = norm(Rhat_i * x_s[:,:,1] - x_smooth_orig[:,:,1]) / max(norm(x_smooth_orig[:,:,1]), eps())\n    θ = subspace_angles_deg(C_true, model.obs_model.C)\n    push!(diagnostics, RotDiag(name, dLL, cond(R), isorthogonal(R), maximum(θ), relerr))\nend\n\nprint(\"\n\" * \"-\"^90 * \"\n\")\n@printf(\"%-24s | %-9s | %-8s | %-6s | %-14s | %-14s\n\",\n        \"Transform\", \"ΔLL\", \"cond(R)\", \"orth?\", \"max angle(C)°\", \"Procrustes err\")\nprint(\"-\"^90 * \"\n\")\nfor d in diagnostics\n    @printf(\"%-24s | %-.3e | %-8.2f | %-6s | %-14.3f | %-14.3e\n\",\n            d.name, d.dLL, d.condR, d.orth ? \"yes\" : \"no\", d.max_angle_deg, d.proc_relerr)\nend\nprint(\"-\"^90 * \"\n\")","category":"section"},{"location":"tutorials/lds_identifiability_example/#Practical-Takeaways","page":"Non-Identifiability in LDS Models","title":"Practical Takeaways","text":"Don’t interpret individual latent coordinates; they are defined only up to an invertible change of basis.\nWhen comparing models/fits, either align with Procrustes or report invariants (eigenvalues/timescales, subspace angles, predictive metrics).\nWatch conditioning: extreme transforms (large cond(R)) can inflate numerical errors even when theory says models are identical.\n(Optional next step) Implement a small canonicalization: whiten Q≈I, real-Schur form for A, mode ordering & sign conventions. This “fixes the gauge” so different runs are directly comparable without per-pair alignment.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Simulating-and-Fitting-a-Poisson-Linear-Dynamical-System","page":"Poisson LDS Example","title":"Simulating and Fitting a Poisson Linear Dynamical System","text":"This tutorial demonstrates how to use StateSpaceDynamics.jl to simulate and fit a Linear Dynamical System (LDS) with Poisson observations using the Laplace-EM algorithm. Unlike the standard Gaussian LDS, this model is designed for count data (e.g., neural spike counts, customer arrivals, or discrete event data) where observations are non-negative integers following Poisson distributions.\n\nThe key insight is that while latent dynamics remain continuous and Gaussian, the observations are discrete counts whose rates depend on the latent state through an exponential link function: lambda_i(t) = exp(mathbfC_i^T mathbfx_t + d_i).","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Load-Required-Packages","page":"Poisson LDS Example","title":"Load Required Packages","text":"using StateSpaceDynamics\nusing LinearAlgebra\nusing Random\nusing Plots\nusing LaTeXStrings\nusing StableRNGs\n\nSet up reproducible random number generation\n\nrng = StableRNG(54321);\nnothing #hide","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Why-Poisson-Linear-Dynamical-Systems?","page":"Poisson LDS Example","title":"Why Poisson Linear Dynamical Systems?","text":"Many real-world phenomena involve discrete events generated by underlying continuous processes. Traditional Gaussian LDS assumes continuous observations, but fails when data are:\n\nNeural spike counts (non-negative integers)\nCustomer arrivals per time window\nGene expression counts\nSocial media posts or interactions\n\nPoisson LDS elegantly handles this by maintaining Gaussian latent dynamics while modeling observations as count data with rates that depend on the hidden state.","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Create-a-Poisson-Linear-Dynamical-System","page":"Poisson LDS Example","title":"Create a Poisson Linear Dynamical System","text":"We define a system where continuous latent dynamics generate discrete count observations. This is particularly relevant in neuroscience (neural spike trains) and other domains where discrete events are generated by underlying continuous processes.\n\nobs_dim = 10       # Number of observed count variables (e.g., neurons)\nlatent_dim = 2;    # Number of latent state dimensions\nnothing #hide\n\nDefine latent dynamics: same spiral structure as Gaussian LDS Latent states evolve smoothly according to linear dynamics\n\nA = 0.95 * [cos(0.25) -sin(0.25); sin(0.25) cos(0.25)]  # Rotation with contraction\nb = zeros(latent_dim)               # bias\nQ = Matrix(0.1 * I(latent_dim))     # Process noise covariance\nx0 = zeros(latent_dim)              # Initial state mean\nP0 = Matrix(0.1 * I(latent_dim));   # Initial state covariance\nnothing #hide\n\nPoisson observation model parameters: For Poisson observations, the rate parameter lambda_i is modeled as: log(lambda_i) = mathbfC_i^T mathbfx_t + d_i where mathbfC maps latent states to log-rates and d_i provides baseline log-rates\n\nlog_d = log.(fill(0.1, obs_dim));    # Log baseline rates (small positive rates)\nnothing #hide\n\nObservation matrix mathbfC: maps 2D latent states to log-rates for each observed dimension Use positive values so latent activity increases firing rates\n\nC = permutedims([abs.(randn(rng, obs_dim))'; abs.(randn(rng, obs_dim))']);\nnothing #hide","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Understanding-Poisson-LDS-Parameters","page":"Poisson LDS Example","title":"Understanding Poisson LDS Parameters","text":"Latent dynamics parameters (same as Gaussian LDS):\n\nA: How latent states evolve (rotation + contraction creates stable oscillation)\nQ: Process noise (uncertainty in latent evolution)\nx_0, P_0: Initial state distribution\n\nObservation parameters (unique to Poisson case):\n\nCi: How latent dimensions affect log-rate of observation i\nPositive Cij: latent dimension j increases firing rate of unit i\nNegative Cij: latent dimension j decreases firing rate of unit i\ndi: Baseline log-rate for observation i when latent state = 0\nexp(di) gives the baseline firing rate","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#The-Exponential-Link-Function","page":"Poisson LDS Example","title":"The Exponential Link Function","text":"The key innovation is how we connect continuous latent states to discrete counts. Instead of linear observations y = mathbfC mathbfx + textnoise, we use:\n\nlambda_i(t) = exp(mathbfC_i^T mathbfx_t + d_i)\n\ny_i(t) sim textPoisson(lambda_i(t))\n\nThe exponential ensures rates are always positive (required for Poisson), and the log-linear relationship means latent states multiplicatively affect firing rates.\n\nThe baseline parameter d_i sets the minimum firing rate when latent states are zero.\n\nConstruct the model components\n\nstate_model = GaussianStateModel(; A, Q, b, x0, P0)          # Gaussian latent dynamics\nobs_model = PoissonObservationModel(; C, log_d);           # Poisson observations\nnothing #hide\n\nCreate the complete Poisson Linear Dynamical System\n\ntrue_plds = LinearDynamicalSystem(;\n    state_model=state_model,\n    obs_model=obs_model,\n    latent_dim=latent_dim,\n    obs_dim=obs_dim,\n    fit_bool=fill(true, 6)  # Learn all parameters: A, Q, C, log_d, x0, P0\n);\nnothing #hide","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Simulate-Latent-States-and-Count-Observations","page":"Poisson LDS Example","title":"Simulate Latent States and Count Observations","text":"Generate synthetic data from our Poisson LDS. Latent states evolve according to linear dynamics, while observations are drawn from Poisson distributions whose rates depend exponentially on the current latent state.\n\nGenerate both latent trajectories and count observations\n\ntSteps = 500\nlatents, observations = rand(rng, true_plds; tsteps=tSteps, ntrials=1);\nnothing #hide","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Visualize-Latent-Dynamics","page":"Poisson LDS Example","title":"Visualize Latent Dynamics","text":"Show the underlying continuous dynamics that drive discrete observations. This vector field illustrates how latent states evolve deterministically (ignoring noise).\n\nCreate grid for vector field\n\nx = y = -3:0.5:3\nX = repeat(x', length(y), 1)\nY = repeat(y, 1, length(x))\nU = zeros(size(X))  # Flow in x-direction\nV = zeros(size(Y));  # Flow in y-direction\n\nfor i in 1:size(X, 1), j in 1:size(X, 2)\n    v = A * [X[i,j], Y[i,j]]\n    U[i,j] = v[1] - X[i,j]\n    V[i,j] = v[2] - Y[i,j]\nend\n\nmagnitude = @. sqrt(U^2 + V^2)  # Normalize arrow lengths for cleaner visualization\nU_norm = U ./ magnitude\nV_norm = V ./ magnitude;\nnothing #hide\n\nPlot vector field with simulated trajectory\n\np1 = quiver(X, Y, quiver=(U_norm, V_norm), color=:blue, alpha=0.3,\n           linewidth=1, arrow=arrow(:closed, :head, 0.1, 0.1))\nplot!(latents[1, :, 1], latents[2, :, 1], xlabel=L\"x_1\", ylabel=L\"x_2\",\n      color=:black, linewidth=1.5, title=\"Latent Dynamics\", legend=false)\n\np1","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Visualize-Latent-States-and-Spike-Observations","page":"Poisson LDS Example","title":"Visualize Latent States and Spike Observations","text":"Create visualizations highlighting the contrast between continuous latent dynamics and discrete count observations (spike trains).\n\nstates = latents[:, :, 1]\nemissions = observations[:, :, 1]\n\nTwo-panel layout: continuous latent states above, discrete spike rasters below\n\nlim_states = maximum(abs.(states))\n\np2 = plot(size=(800, 600), layout=@layout[a{0.3h}; b])\n\nfor d in 1:latent_dim\n    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,\n          linewidth=2, label=\"\", subplot=1) # Plot smooth latent state trajectories\n\nend\n\nplot!(subplot=1, yticks=(lim_states .* (0:latent_dim-1), [L\"x_%$d\" for d in 1:latent_dim]),\n      xticks=[], xlims=(0, tSteps), title=\"Simulated Latent States\",\n      yformatter=y->\"\", tickfontsize=12)\n\ncolors = palette(:default, obs_dim)\nfor f in 1:obs_dim\n    spike_times = findall(x -> x > 0, emissions[f, :])\n    for t in spike_times\n        plot!([t, t], [f-0.4, f+0.4], color=colors[f], linewidth=1, label=\"\", subplot=2)\n    end\nend\n\nplot!(subplot=2, yticks=(1:obs_dim, [L\"y_{%$d}\" for d in 1:obs_dim]),\n      xlims=(0, tSteps), ylims=(0.5, obs_dim + 0.5), title=\"Spike Raster Plot\",\n      xlabel=\"Time\", tickfontsize=12, grid=false)\n\np2","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#The-Inference-Challenge","page":"Poisson LDS Example","title":"The Inference Challenge","text":"Unlike Gaussian LDS where exact inference is possible via Kalman filtering, Poisson observations break the conjugate Gaussian structure. The posterior p(x_t  y_1T) is no longer Gaussian, requiring approximations.\n\nLaplace-EM Algorithm:\n\nE-step: Use Laplace approximation to make posterior \"locally Gaussian\"\nM-step: Update parameters using expected sufficient statistics\nIteration: Repeat until ELBO converges\n\nThe Laplace approximation finds the mode of the posterior and approximates it with a Gaussian, enabling tractable inference at the cost of some accuracy.","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Initialize-and-Fit-Poisson-LDS","page":"Poisson LDS Example","title":"Initialize and Fit Poisson LDS","text":"In practice, we only observe spike counts, not latent states. Our goal is to infer both latent dynamics and the mapping from latent states to firing rates. Start with randomly initialized model.\n\nRandom initialization (simulating lack of prior knowledge)\n\nA_init = random_rotation_matrix(latent_dim, rng)  # Random rotation matrix\nQ_init = Matrix(0.1 * I(latent_dim))              # Process noise guess\nC_init = randn(rng, obs_dim, latent_dim)          # Random observation mapping\nlog_d_init = log.(fill(0.1, obs_dim))             # Baseline log-rate guess\nx0_init = zeros(latent_dim)                       # Start from origin\nP0_init = Matrix(0.1 * I(latent_dim));             # Initial uncertainty\nnothing #hide\n\nConstruct naive model\n\nsm_init = GaussianStateModel(; A=A_init, Q=Q_init, b=b, x0=x0_init, P0=P0_init)\nom_init = PoissonObservationModel(; C=C_init, log_d=log_d_init)\n\nnaive_plds = LinearDynamicalSystem(;\n    state_model=sm_init,\n    obs_model=om_init,\n    latent_dim=latent_dim,\n    obs_dim=obs_dim,\n    fit_bool=fill(true, 6)\n);\nnothing #hide\n\nFor Poisson observations, this requires Laplace approximations since the posterior is no longer Gaussian (unlike linear-Gaussian case)\n\nsmoothed_x_pre, smoothed_p_pre = smooth(naive_plds, observations);\nnothing #hide\n\nCompare true vs. initial estimated latent states\n\np3 = plot()\nfor d in 1:latent_dim\n    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,\n          linewidth=2, label=(d==1 ? \"True\" : \"\"), alpha=0.8)\n    plot!(1:tSteps, smoothed_x_pre[d, :, 1] .+ lim_states * (d-1), color=:red,\n          linewidth=2, label=(d==1 ? \"Initial Est.\" : \"\"), alpha=0.8)\nend\n\nplot!(yticks=(lim_states .* (0:latent_dim-1), [L\"x_%$d\" for d in 1:latent_dim]),\n      xlabel=\"Time\", xlims=(0, tSteps), title=\"Pre-EM: True vs. Initial Estimates\",\n      yformatter=y->\"\", tickfontsize=12, legend=:topright)\n\np3","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Fit-Using-Laplace-EM-Algorithm","page":"Poisson LDS Example","title":"Fit Using Laplace-EM Algorithm","text":"Fit the model - using fewer iterations due to computational cost\n\nelbo, _ = fit!(naive_plds, observations; max_iter=25, tol=1e-6);\n\nprint(\"Laplace-EM completed in $(length(elbo)) iterations\\n\")\n\nParameter identifiability:\n\nScale ambiguity: (mathbfC, d) and (alpha mathbfC, d + log(alpha)) give same likelihood\nCan be resolved by constraining norm of mathbfC or fixing one element\nRotation ambiguity in latent space (same as Gaussian LDS)\n\nPerform smoothing with learned parameters\n\nsmoothed_x_post, smoothed_p_post = smooth(naive_plds, observations);\nnothing #hide\n\nCompare true vs. learned latent state estimates\n\np4 = plot()\nfor d in 1:latent_dim\n    plot!(1:tSteps, states[d, :] .+ lim_states * (d-1), color=:black,\n          linewidth=2, label=(d==1 ? \"True\" : \"\"), alpha=0.8)\n    plot!(1:tSteps, smoothed_x_post[d, :, 1] .+ lim_states * (d-1), color=:red,\n          linewidth=2, label=(d==1 ? \"Post-EM Est.\" : \"\"), alpha=0.8)\nend\n\nplot!(yticks=(lim_states .* (0:latent_dim-1), [L\"x_%$d\" for d in 1:latent_dim]),\n      xlabel=\"Time\", xlims=(0, tSteps), title=\"Post-EM: True vs. Learned Estimates\",\n      yformatter=y->\"\", tickfontsize=12, legend=:topright)\n\np4","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Monitor-ELBO-Convergence","page":"Poisson LDS Example","title":"Monitor ELBO Convergence","text":"The Evidence Lower Bound (ELBO) tracks algorithm progress. For Poisson LDS, ELBO includes both data likelihood and Laplace approximation terms. Convergence may be less smooth than Gaussian case due to approximations.\n\np5 = plot(elbo, xlabel=\"Iteration\", ylabel=\"ELBO\",\n          title=\"Laplace-EM Convergence\", legend=false,\n          linewidth=2, marker=:circle, markersize=3, color=:darkgreen)\n\nif length(elbo) > 1\n    improvement = elbo[end] - elbo[1]\n    annotate!(p5, length(elbo)*0.7, elbo[end]*0.95,\n        text(\"Improvement: $(round(improvement, digits=1))\", 10)) # Add convergence annotation\nend\n\np5","category":"section"},{"location":"tutorials/poisson_latent_dynamics_example/#Summary","page":"Poisson LDS Example","title":"Summary","text":"This tutorial demonstrated fitting a Poisson Linear Dynamical System:\n\nKey Concepts:\n\nHybrid model: Continuous Gaussian latent dynamics generate discrete Poisson observations\nExponential link: log(lambda_i) = mathbfC_i^T mathbfx_t + d_i connects latent states to count rates\nLaplace-EM: Handles non-conjugate Poisson-Gaussian combination through approximations\nCount data modeling: Extends LDS framework to spike trains and event sequences\n\nTechnical Insights:\n\nMore computationally intensive than Gaussian LDS due to required approximations\nConvergence can be slower and less smooth than conjugate models\nParameter recovery quality depends on observation density and latent state separation\nLaplace approximations become more accurate with higher count rates\n\nAdvantages:\n\nPrincipled probabilistic framework for count data\nMaintains interpretable continuous latent dynamics\nEnables simultaneous state estimation and parameter learning\nProvides uncertainty quantification for both states and parameters\n\nThe Poisson LDS successfully bridges continuous dynamical systems and discrete observation models, enabling principled analysis of count data with underlying temporal structure.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"tutorials/gaussian_mixture_model_example/#Simulating-and-Fitting-a-Gaussian-Mixture-Model","page":"Gaussian Mixture Model Example","title":"Simulating and Fitting a Gaussian Mixture Model","text":"This tutorial demonstrates how to use StateSpaceDynamics.jl to create a Gaussian Mixture Model (GMM) and fit it using the EM algorithm. Unlike Hidden Markov Models which model temporal sequences, GMMs are designed for clustering and density estimation of independent observations. Each data point is assumed to come from one of several Gaussian components, but there's no temporal dependence.\n\nGMMs are fundamental in machine learning for unsupervised clustering, density estimation, anomaly detection, and as building blocks for more complex models. The key insight is that complex data distributions can often be well-approximated as mixtures of simpler Gaussian distributions, each representing a different \"mode\" or cluster in the data.","category":"section"},{"location":"tutorials/gaussian_mixture_model_example/#Load-Required-Packages","page":"Gaussian Mixture Model Example","title":"Load Required Packages","text":"using StateSpaceDynamics\nusing LinearAlgebra\nusing Random\nusing Plots\nusing StableRNGs\nusing Distributions\nusing StatsPlots\nusing Combinatorics\nusing LaTeXStrings\n\nSet up reproducible random number generation\n\nrng = StableRNG(1234);\nnothing #hide","category":"section"},{"location":"tutorials/gaussian_mixture_model_example/#Create-a-True-Gaussian-Mixture-Model","page":"Gaussian Mixture Model Example","title":"Create a True Gaussian Mixture Model","text":"We'll create a \"ground truth\" GMM with known parameters, generate data from it, then see how well we can recover these parameters using only the observed data.\n\nk = 3  # Number of mixture components (clusters)\nD = 2  # Data dimensionality (2D for easy visualization)\n\nDefine the true component means: boldsymbolmu_i in mathbbR^D for i = 1 ldots k Each column represents the mean vector boldsymbolmu_i for one component\n\ntrue_μs = [\n    -1.0  1.0  0.0;   # $x_1$ coordinates of the 3 component centers\n    -1.0 -1.5  2.0    # $x_2$ coordinates of the 3 component centers\n];  # Shape: $(D, k) = (2, 3)$\nnothing #hide\n\nDefine covariance matrices boldsymbolSigma_i for each component Using isotropic (spherical) covariances for simplicity\n\ntrue_Σs = [Matrix{Float64}(0.3 * I(2)) for _ in 1:k];\nnothing #hide\n\nDefine mixing weights pi_i (must sum to 1) These represent P(textcomponent = i) for a random sample\n\ntrue_πs = [0.5, 0.2, 0.3];  # Component 1 most likely, component 2 least likely\nnothing #hide\n\nConstruct the complete GMM\n\ntrue_gmm = GaussianMixtureModel(k, true_μs, true_Σs, true_πs);\n\nprint(\"Created GMM: $k components, $D dimensions\\n\")\nfor i in 1:k\n    print(\"Component $i: μ = $(true_μs[:, i]), π = $(true_πs[i])\\n\")\nend","category":"section"},{"location":"tutorials/gaussian_mixture_model_example/#Sample-Data-from-the-True-GMM","page":"Gaussian Mixture Model Example","title":"Sample Data from the True GMM","text":"Generate synthetic data from our true model. We'll sample both component assignments (for evaluation) and the actual observations.\n\nn = 500  # Number of data points to generate\n\nDetermine which component each sample comes from\n\nlabels = rand(rng, Categorical(true_πs), n);\nnothing #hide\n\nCount samples per component for verification\n\ncomponent_counts = [sum(labels .== i) for i in 1:k]\nprint(\"Samples per component: $(component_counts) (expected: $(round.(n .* true_πs)))\\n\");\nnothing #hide\n\nGenerate the actual data points\n\nX = Matrix{Float64}(undef, D, n)\nfor i in 1:n\n    component = labels[i]\n    X[:, i] = rand(rng, MvNormal(true_μs[:, component], true_Σs[component]))\nend\n\nVisualize the generated data colored by true component membership\n\np1 = scatter(X[1, :], X[2, :];\n    group=labels,\n    title=\"True GMM Components\",\n    xlabel=L\"x_1\", ylabel=L\"x_2\",\n    markersize=4,\n    alpha=0.7,\n    palette=:Set1_3,\n    legend=:topright\n)\n\nfor i in 1:k\n    scatter!(p1, [true_μs[1, i]], [true_μs[2, i]];\n        marker=:star, markersize=10, color=i,\n        markerstrokewidth=2, markerstrokecolor=:black,\n        label=\"\")\nend\n\np1","category":"section"},{"location":"tutorials/gaussian_mixture_model_example/#Fit-GMM-Using-EM-Algorithm","page":"Gaussian Mixture Model Example","title":"Fit GMM Using EM Algorithm","text":"Now we simulate the realistic scenario: observe only data points mathbfX, not the true component labels or parameters. Our goal is to recover the underlying mixture structure using EM.\n\nInitialize a GMM with correct number of components but unknown parameters\n\nfit_gmm = GaussianMixtureModel(k, D)\n\nprint(\"Running EM algorithm...\")\n\nFit the model using EM algorithm\n\nclass_probabilities, lls = fit!(fit_gmm, X;\n    maxiter=100,\n    tol=1e-6,\n    initialize_kmeans=true  # K-means initialization helps convergence\n);\n\nprint(\"EM converged in $(length(lls)) iterations\\n\")\nprint(\"Log-likelihood improved by $(round(lls[end] - lls[1], digits=1))\\n\");\nnothing #hide\n\nPlot EM convergence\n\np2 = plot(lls, xlabel=\"EM Iteration\", ylabel=\"Log-Likelihood\",\n          title=\"EM Algorithm Convergence\", legend=false,\n          marker=:circle, markersize=3, lw=2, color=:darkblue)\n\nif length(lls) < 100\n    annotate!(p2, length(lls)*0.7, lls[end]*0.95,\n        text(\"Converged in $(length(lls)) iterations\", 10)) # Add convergence annotation\nend","category":"section"},{"location":"tutorials/gaussian_mixture_model_example/#Visualize-Fitted-Model","page":"Gaussian Mixture Model Example","title":"Visualize Fitted Model","text":"Create visualization showing both data and fitted GMM with probability contours. Create grid for plotting contours\n\nx_range = range(extrema(X[1, :])..., length=100)\ny_range = range(extrema(X[2, :])..., length=100)\nxs = collect(x_range)\nys = collect(y_range)\n\np3 = scatter(X[1, :], X[2, :];\n    markersize=3,\n    alpha=0.5,\n    color=:gray,\n    xlabel=L\"x_1\",\n    ylabel=L\"x_2\",\n    title=\"Fitted GMM Components\",\n    legend=:topright,\n    label=\"Data points\"\n)\n\np3\n\ncolors = [:red, :green, :blue] # Plot probability density contours for each learned component\nfor i in 1:fit_gmm.k\n    comp_dist = MvNormal(fit_gmm.μₖ[:, i], fit_gmm.Σₖ[i])\n    Z_i = [fit_gmm.πₖ[i] * pdf(comp_dist, [x, y]) for y in ys, x in xs]\n\n    contour!(p3, xs, ys, Z_i;\n        levels=6,\n        linewidth=2,\n        c=colors[i],\n        label=\"Component $i (π=$(round(fit_gmm.πₖ[i], digits=2)))\"\n    )\n\n    scatter!(p3, [fit_gmm.μₖ[1, i]], [fit_gmm.μₖ[2, i]];\n        marker=:star, markersize=8, color=colors[i],\n        markerstrokewidth=2, markerstrokecolor=:black,\n        label=\"\")\nend","category":"section"},{"location":"tutorials/gaussian_mixture_model_example/#Component-Assignment-Analysis","page":"Gaussian Mixture Model Example","title":"Component Assignment Analysis","text":"Use fitted model to assign each data point to its most likely component and compare with true assignments.\n\nGet posterior probabilities: P(textcomponent  i  mathbfx_j)\n\npredicted_labels = [argmax(class_probabilities[:, j]) for j in 1:n];\nnothing #hide\n\nCalculate assignment accuracy (accounting for possible label permutation) Since EM can converge with components in different order\n\nfunction best_permutation_accuracy(true_labels, pred_labels, k)\n    best_acc = 0.0\n    best_perm = collect(1:k)\n\n    for perm in Combinatorics.permutations(1:k)\n        mapped_pred = [perm[pred_labels[i]] for i in 1:length(pred_labels)]\n        acc = mean(true_labels .== mapped_pred)\n        if acc > best_acc\n            best_acc = acc\n            best_perm = perm\n        end\n    end\n\n    return best_acc, best_perm\nend\n\naccuracy, best_perm = best_permutation_accuracy(labels, predicted_labels, k)\nprint(\"Component assignment accuracy: $(round(accuracy*100, digits=1))%\\n\");\nnothing #hide","category":"section"},{"location":"tutorials/gaussian_mixture_model_example/#Final-Comparison-Visualization","page":"Gaussian Mixture Model Example","title":"Final Comparison Visualization","text":"Side-by-side comparison of true vs learned component assignments\n\np_true = scatter(X[1, :], X[2, :]; group=labels, title=\"True Components\",\n                xlabel=L\"x_1\", ylabel=L\"x_2\", markersize=3, alpha=0.7,\n                palette=:Set1_3, legend=false)\n\nremapped_predicted = [best_perm[predicted_labels[i]] for i in 1:n] # Apply best permutation to predicted labels for fair comparison\np_learned = scatter(X[1, :], X[2, :]; group=remapped_predicted, title=\"Learned Components\",\n                   xlabel=L\"x_1\", ylabel=L\"x_2\", markersize=3, alpha=0.7,\n                   palette=:Set1_3, legend=false)\n\np4 = plot(p_true, p_learned, layout=(1, 2), size=(800, 350))","category":"section"},{"location":"tutorials/gaussian_mixture_model_example/#Summary","page":"Gaussian Mixture Model Example","title":"Summary","text":"This tutorial demonstrated the complete Gaussian Mixture Model workflow:\n\nKey Concepts:\n\nMixture modeling: Complex distributions as weighted combinations of simpler Gaussians\nEM algorithm: Iterative parameter learning via expectation-maximization\nSoft clustering: Probabilistic component assignments rather than hard clusters\nLabel permutation: Handling component identifiability issues\n\nApplications:\n\nUnsupervised clustering and density estimation\nAnomaly detection via likelihood thresholding\nDimensionality reduction (when extended to factor analysis)\nBuilding blocks for more complex probabilistic models\n\nTechnical Insights:\n\nK-means initialization significantly improves EM convergence\nLog-likelihood monitoring ensures proper algorithm behavior\nParameter recovery quality depends on component separation and sample size\n\nGMMs provide a flexible, interpretable framework for modeling heterogeneous data with multiple underlying modes or clusters, forming the foundation for many advanced machine learning techniques.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Choosing-\"K\"-for-a-hidden-Markov-model.","page":"HMM Model Selection","title":"Choosing \"K\" for a hidden Markov model.","text":"In principle, one can fit an HMM with any number of states, but how do we choose? One generally has no ground truth, except for the most rare cases. So it begs the question: How do we select the number of hidden states K? In this tutorial we will demonstrate a few typical approaches for model selection with enhanced cross-validation integration.","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Load-Required-Packages","page":"HMM Model Selection","title":"Load Required Packages","text":"using StateSpaceDynamics\nusing LinearAlgebra\nusing Random\nusing Plots\nusing Statistics\nusing StableRNGs\nusing Printf\n\nFix RNG for reproducible simulation and k-means seeding\n\nrng = StableRNG(1234);\nnothing #hide","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Create-a-True-HMM","page":"HMM Model Selection","title":"Create a True HMM","text":"For our example we will create a simple HMM with K=3 states and 2D Gaussian emissions. We will then generate ground truth data from this model for use in the tutorial.\n\nK = 3  # Number of hidden states\nD = 2  # Dimensionality of observations\nT = 500  # Number of time steps to simulate\n\nDefine the true transition matrix\n\ntrue_A = [0.90 0.05 0.05;\n          0.10 0.80 0.10;\n          0.15 0.15 0.70];\nnothing #hide\n\nDefine the true emission parameters (means and covariances)\n\ntrue_μs = [-1.0 0.0 1.0;\n            0.6 -1.0 0.0]\n\ntrue_Σs =[[0.1 -0.3; -0.3 1.0],\n          [0.5 0.2; 0.2 0.3],\n          [0.3 0.0; 0.0 0.3]];\nnothing #hide\n\nDefine the initial state distribution\n\ntrue_π = [0.5, 0.3, 0.2];\nnothing #hide\n\nCreate the true HMM\n\ntrue_hmm = HiddenMarkovModel(true_A,\n                            [GaussianEmission(2, true_μs[:, k],\n                            true_Σs[k]) for k in 1:K],\n                            true_π,\n                            K)\n\nstates, observations = rand(rng, true_hmm; n=T)\n\nNow plot the data colored by the true states\n\np1 = scatter(observations[1, :], observations[2, :],\n    group=states,\n    xlabel=\"x1\", ylabel=\"x2\",\n    title=\"HMM Observations Colored by True State\",\n    legend=:topright, alpha=0.7)","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Model-Selection-Approaches","page":"HMM Model Selection","title":"Model Selection Approaches","text":"With real data, we don't know the true number of states K. We'll explore several methods to estimate the optimal K by fitting HMMs with different numbers of states and comparing their performance using various criteria.\n\nDefine range of K values to test\n\nK_range = 1:8\n\nWe'll compare models using multiple criteria:\n\nLog-likelihood (higher is better, but tends to overfit)\nAIC (Akaike Information Criterion - penalizes complexity)\nBIC (Bayesian Information Criterion - stronger complexity penalty)\nCross-validation likelihood\n\nresults = Dict(\n    \"K\" => Int[],\n    \"log_likelihood\" => Float64[],\n    \"AIC\" => Float64[],\n    \"BIC\" => Float64[],\n    \"n_params\" => Int[],\n    \"CV_score\" => Float64[]\n);\nnothing #hide","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Helper-Functions-for-Model-Selection","page":"HMM Model Selection","title":"Helper Functions for Model Selection","text":"function initialize_hmm_kmeans(obs, k, rng)\n    \"\"\"Initialize HMM parameters using k-means clustering\"\"\"\n    if k == 1\n        means = [mean(obs, dims=2)[:, 1]]\n        covs = [cov(obs')]\n    else\n        Random.seed!(rng, 42)\n        cluster_centers = obs[:, randperm(rng, size(obs, 2))[1:k]]\n        means = [cluster_centers[:, i] for i in 1:k]\n        covs = [Matrix(0.5 * I(size(obs, 1))) for _ in 1:k]\n    end\n\n    A_init = fill(0.1/(k-1), k, k)\n    for i in 1:k\n        A_init[i, i] = 0.9\n    end\n    A_init = A_init ./ sum(A_init, dims=2)  # Normalize rows\n\n    π_init = fill(1/k, k)\n\n    return HiddenMarkovModel(A_init,\n                           [GaussianEmission(2, means[i], covs[i]) for i in 1:k],\n                           π_init,\n                           k)\nend\n\nfunction count_parameters(hmm)\n    \"\"\"Count the number of free parameters in an HMM\"\"\"\n    K = hmm.K\n    D = length(hmm.B[1].μ)\n\n    transition_params = K * (K - 1)\n    initial_params = K - 1\n    emission_params = K * D + K * D * (D + 1) ÷ 2\n\n    return transition_params + initial_params + emission_params\nend\n\nfunction cross_validate_hmm(observations, k, n_folds=5)\n    \"\"\"Perform k-fold cross-validation for HMM with k states\"\"\"\n    T = size(observations, 2)\n    fold_size = T ÷ n_folds\n    cv_scores = Float64[]\n\n    for fold in 1:n_folds\n        test_start = (fold - 1) * fold_size + 1\n        test_end = min(fold * fold_size, T)\n\n        train_idx = [1:(test_start-1); (test_end+1):T]\n        test_idx = test_start:test_end\n\n        if length(train_idx) == 0 || length(test_idx) == 0\n            continue\n        end\n\n        train_obs = observations[:, train_idx]\n        test_obs = observations[:, test_idx]\n\n        hmm_cv = initialize_hmm_kmeans(train_obs, k, rng)\n        fit!(hmm_cv, train_obs; max_iters=50, tol=1e-4)\n\n        test_ll = loglikelihood(hmm_cv, test_obs)\n        push!(cv_scores, test_ll / length(test_idx))  # Normalize by sequence length\n    end\n\n    return mean(cv_scores)\nend\n\nfor k in K_range\n    println(\"Evaluating HMM with K=$k states...\")\n\n    hmm_k = initialize_hmm_kmeans(observations, k, rng)\n    fit!(hmm_k, observations; max_iters=100, tol=1e-6)\n\n    ll = loglikelihood(hmm_k, observations)\n    n_params = count_parameters(hmm_k)\n    aic_val = -2*ll + 2*n_params\n    bic_val = -2*ll + log(T)*n_params\n\n    cv_score = cross_validate_hmm(observations, k, 5)\n\n    push!(results[\"K\"], k)\n    push!(results[\"log_likelihood\"], ll)\n    push!(results[\"AIC\"], aic_val)\n    push!(results[\"BIC\"], bic_val)\n    push!(results[\"n_params\"], n_params)\n    push!(results[\"CV_score\"], cv_score)\nend","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Find-optimal-K-for-each-criterion","page":"HMM Model Selection","title":"Find optimal K for each criterion","text":"aic_min_idx = argmin(results[\"AIC\"])\nbic_min_idx = argmin(results[\"BIC\"])\ncv_max_idx = argmax(results[\"CV_score\"])\n\nbest_aic_k = results[\"K\"][aic_min_idx]\nbest_bic_k = results[\"K\"][bic_min_idx]\nbest_cv_k = results[\"K\"][cv_max_idx]","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Interpreting-Information-Criteria","page":"HMM Model Selection","title":"Interpreting Information Criteria","text":"AIC (Akaike Information Criterion):\n\nEstimates relative model quality for prediction\nAsymptotically equivalent to leave-one-out cross-validation\nTends to select more complex models (higher K)\nBetter for prediction tasks\n\nBIC (Bayesian Information Criterion):\n\nEstimates probability that model is true among candidates\nStronger complexity penalty, especially for large datasets\nTends to select simpler models (lower K)\nBetter for identifying \"true\" model structure\n\nKey insight: Lower values are better for both AIC and BIC (they measure \"badness\" - deviance plus penalty)","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Cross-Validation:-The-Gold-Standard","page":"HMM Model Selection","title":"Cross-Validation: The Gold Standard","text":"Cross-validation provides the most honest estimate of generalization performance:\n\nTrains on subset of data, tests on held-out portion\nDirectly measures what we care about: performance on unseen data\nLess dependent on specific penalty terms than AIC/BIC\nMore computationally expensive but often worth it\n\nChallenges for HMMs:\n\nTemporal data makes random splits problematic\nSequential structure should be preserved when possible\nWe use contiguous blocks to maintain temporal coherence\n\nInterpreting CV results:\n\nHigher CV likelihood indicates better generalization\nPlateauing suggests additional complexity isn't helpful\nLarge variance across folds may indicate unstable model","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Visualization-of-Model-Selection-Results","page":"HMM Model Selection","title":"Visualization of Model Selection Results","text":"In our plots we will plot 1.) the loglikelihood 2.) negative AIC 3.) negative BIC and 4.) the loglikelihood of the test dataset We plot the negative AIC and BIC as those metrics are defined such that a lower score is better, so we invert the statistic, so like regular likelihood, higher indicates better model performance.\n\nCreate comprehensive plot showing all criteria including CV\n\np2 = plot(layout=(2, 2), size=(1000, 800))\n\nplot!(results[\"K\"], results[\"log_likelihood\"],\n      marker=:circle, linewidth=2, label=\"Log-likelihood\",\n      xlabel=\"Number of States (K)\", ylabel=\"Log-likelihood\",\n      title=\"Model Log-likelihood\", subplot=1)\nvline!([K], linestyle=:dash, color=:red, label=\"True K=$K\", subplot=1)\n\nplot!(results[\"K\"], -results[\"AIC\"],\n      marker=:circle, linewidth=2, label=\"AIC\", color=:orange,\n      xlabel=\"Number of States (K)\", ylabel=\"AIC\",\n      title=\"Negative AIC\", subplot=2)\nvline!([best_aic_k], linestyle=:dash, color=:orange,\n       label=\"nAIC max (K=$best_aic_k)\", subplot=2)\nvline!([K], linestyle=:dash, color=:red, label=\"True K=$K\", subplot=2)\n\nplot!(results[\"K\"], -results[\"BIC\"],\n      marker=:circle, linewidth=2, label=\"BIC\", color=:green,\n      xlabel=\"Number of States (K)\", ylabel=\"BIC\",\n      title=\"Negative BIC\", subplot=3)\nvline!([best_bic_k], linestyle=:dash, color=:green,\n       label=\"nBIC max (K=$best_bic_k)\", subplot=3)\nvline!([K], linestyle=:dash, color=:red, label=\"True K=$K\", subplot=3)\n\nplot!(results[\"K\"], results[\"CV_score\"],\n      marker=:circle, linewidth=2, label=\"CV Score\", color=:blue,\n      xlabel=\"Number of States (K)\", ylabel=\"CV Log-likelihood\",\n      title=\"Cross-Validation Results\", subplot=4)\nvline!([best_cv_k], linestyle=:dash, color=:blue,\n       label=\"CV max (K=$best_cv_k)\", subplot=4)\nvline!([K], linestyle=:dash, color=:red, label=\"True K=$K\", subplot=4)\n\np2","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Unified-Model-Selection-Comparison","page":"HMM Model Selection","title":"Unified Model Selection Comparison","text":"Create a single plot showing all criteria on normalized scales for direct comparison\n\np3 = plot(size=(800, 500))\n\nnorm_aic = (-results[\"AIC\"] .- maximum(-results[\"AIC\"])) ./ (maximum(-results[\"AIC\"]) - minimum(-results[\"AIC\"])) .+ 1\nnorm_bic = (-results[\"BIC\"] .- maximum(-results[\"BIC\"])) ./ (maximum(-results[\"BIC\"]) - minimum(-results[\"BIC\"])) .+ 1\nnorm_cv = (results[\"CV_score\"] .- maximum(results[\"CV_score\"])) ./ (maximum(results[\"CV_score\"]) - minimum(results[\"CV_score\"])) .+ 1\n\nplot!(results[\"K\"], norm_aic, marker=:circle, linewidth=2,\n      label=\"nAIC (normalized)\", color=:orange)\nplot!(results[\"K\"], norm_bic, marker=:square, linewidth=2,\n      label=\"nBIC (normalized)\", color=:green)\nplot!(results[\"K\"], norm_cv, marker=:diamond, linewidth=2,\n      label=\"CV (normalized)\", color=:blue)\n\nxlabel!(\"Number of States (K)\")\nylabel!(\"Normalized Score (lower is better)\")\ntitle!(\"Unified Model Selection Comparison\")\nvline!([K], linestyle=:dash, color=:red, linewidth=2, label=\"True K=$K\")\n\nscatter!([best_aic_k], [norm_aic[aic_min_idx]], markersize=8, color=:orange, markershape=:star5, label=\"\")\nscatter!([best_bic_k], [norm_bic[bic_min_idx]], markersize=8, color=:green, markershape=:star5, label=\"\")\nscatter!([best_cv_k], [norm_cv[cv_max_idx]], markersize=8, color=:blue, markershape=:star5, label=\"\");\n\np3","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Compare-ALL-Best-Models-Visually-(including-CV)","page":"HMM Model Selection","title":"Compare ALL Best Models Visually (including CV)","text":"Fit models with AIC, BIC, and CV selected K values\n\nhmm_aic = initialize_hmm_kmeans(observations, best_aic_k, rng)\nfit!(hmm_aic, observations; max_iters=100, tol=1e-6)\n\nhmm_bic = initialize_hmm_kmeans(observations, best_bic_k, rng)\nfit!(hmm_bic, observations; max_iters=100, tol=1e-6)\n\nhmm_cv = initialize_hmm_kmeans(observations, best_cv_k, rng)\nfit!(hmm_cv, observations; max_iters=100, tol=1e-6);\nnothing #hide\n\nGet most likely state sequences\n\nstates_aic = viterbi(hmm_aic, observations)\nstates_bic = viterbi(hmm_bic, observations)\nstates_cv = viterbi(hmm_cv, observations);\nnothing #hide\n\nCreate enhanced comparison plots (2x2 layout)\n\np4 = plot(layout=(2, 2), size=(1000, 800))\n\nscatter!(observations[1, :], observations[2, :], group=states,\n         xlabel=\"x1\", ylabel=\"x2\", title=\"True States (K=$K)\",\n         legend=false, alpha=0.7, subplot=1)\n\nscatter!(observations[1, :], observations[2, :], group=states_aic,\n         xlabel=\"x1\", ylabel=\"x2\", title=\"AIC Model (K=$best_aic_k)\",\n         legend=false, alpha=0.7, subplot=2)\n\nscatter!(observations[1, :], observations[2, :], group=states_bic,\n         xlabel=\"x1\", ylabel=\"x2\", title=\"BIC Model (K=$best_bic_k)\",\n         legend=false, alpha=0.7, subplot=3)\n\nscatter!(observations[1, :], observations[2, :], group=states_cv,\n         xlabel=\"x1\", ylabel=\"x2\", title=\"Cross-Validation Model (K=$best_cv_k)\",\n         legend=false, alpha=0.7, subplot=4)\n\np4","category":"section"},{"location":"tutorials/hmm_model_selection_example/#Key-Takeaways","page":"HMM Model Selection","title":"Key Takeaways","text":"Information Criteria:\n\nAIC tends to favor more complex models (higher K)\nBIC has stronger penalty for complexity, often selects simpler models\nBoth can help avoid overfitting compared to raw likelihood\n\nCross-Validation:\n\nMore robust estimate of generalization performance\nComputationally expensive but often provides the most reliable selection\nLess sensitive to the specific penalty terms in AIC/BIC\nDirectly measures out-of-sample performance\n\nPractical Recommendations:\n\nUse multiple criteria - they don't always agree, and disagreement is informative\nPrioritize cross-validation when computational resources allow\nConsider the practical significance of differences between close K values\nVisualize results to understand model behavior across different K values\nRemember that model selection depends on your specific goals and constraints\nWhen methods disagree, consider ensemble approaches or domain knowledge\n\nModel Selection Insights from This Example:\n\nRaw likelihood always increases with K (overfitting tendency)\nInformation criteria balance fit vs. complexity differently\nCross-validation provides unbiased performance estimates\nVisual inspection can reveal whether selected models make practical sense\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"#Getting-Started","page":"Home","title":"Getting Started","text":"StateSpaceDynamics.jl is a comprehensive Julia package for state space modeling, designed specifically with neuroscientific applications in mind. The package provides efficient implementations of various state space models along with tools for parameter estimation, state inference, and model selection.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"To install StateSpaceDynamics.jl, start up Julia and type the following code snippet into the REPL.\n\nusing Pkg\nPkg.add(\"StateSpaceDynamics\")\n\nor alternatively, you can enter the package manager by typing ] and then run:\n\nadd StateSpaceDynamics","category":"section"},{"location":"#What-are-State-Space-Models?","page":"Home","title":"What are State Space Models?","text":"State space models are a class of probabilistic models that describe the evolution of a system through two main components - a latent and observation process. The latent process is a stochastic process that is not directly observed, but is used to generate the observed data. The observation process is a conditional distribution that describes how the observed data is generated from the latent process.\n\nIn their most general form, state space models can be written as:\n\nbeginalign*\n    x_t+1 sim p(x_t+1  x_t) \n    y_t sim p(y_t  x_t)\nendalign*\n\nwhere x_t is the latent state at time t and y_t is the observed data at time t.","category":"section"},{"location":"#Example:-Linear-Dynamical-Systems","page":"Home","title":"Example: Linear Dynamical Systems","text":"A fundamental example is the Linear Dynamical System (LDS), which combines linear dynamics with Gaussian noise. The LDS can be expressed in two equivalent forms:\n\nEquation form:\n\nbeginalign*\n    x_t+1 = A x_t + b + epsilon_t \n    y_t = C x_t + d + delta_t\nendalign*\n\nwhere:\n\nmathbfA is the state transition matrix\nmathbfC is the observation matrix  \nmathbfb and mathbfd are bias terms\nboldsymbolepsilon_t and boldsymboldelta_t are Gaussian noise terms with covariances mathbfQ and mathbfR respectively\n\nDistributional form:\n\nbeginalign*\n    x_t+1 sim mathcalN(A x_t + b Q) \n    y_t sim mathcalN(C x_t + d R)\nendalign*\n\nwhere mathbfQ and mathbfR are the state and observation noise covariance matrices, respectively.","category":"section"},{"location":"#Models-Implemented","page":"Home","title":"Models Implemented","text":"StateSpaceDynamics.jl implements several types of state space models:\n\nLinear Dynamical Systems (LDS)\nGaussian LDS\nPoisson LDS\nHidden Markov Models (HMM)\nGaussian emissions\nRegression-based emissions\nGaussian regression\nBernoulli regression\nPoisson regression\nAutoregressive emissions","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"Here's a simple example on how to create a Gaussian SSM.\n\nusing StateSpaceDynamics\nusing LinearAlgebra\n\n# Define model dimensions\nlatent_dim = 3\nobs_dim = 10\n\n# Define state model parameters\nA = 0.95 * I(latent_dim)\nQ = 0.01 * I(latent_dim)\nx0 = zeros(latent_dim)\nP0 = 0.1 * I(latent_dim)\nstate_model = GaussianStateModel(A, Q, x0, P0)\n\n# Define observation model parameters\nC = ones(obs_dim, latent_dim)\nR = Matrix(0.5 * I(obs_dim))\nobs_model = GaussianObservationModel(C, R)\n\n# Construct the LDS\nlds = LinearDynamicalSystem(state_model, obs_model, latent_dim, obs_dim, fill(true, 6))","category":"section"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"If you encounter a bug or would like to contribute to the package, please open an issue on our GitHub repository. Once the suggested change has received positive feedback, feel free to submit a PR adhering to the BlueStyle guide.\n\nPlease include or update tests for any user-facing change. Tests live in the test/ folder and are run with:\n\njulia --project -e 'using Pkg; Pkg.test()'\n# or from the Pkg REPL by typing \"]\":\nadd StateSpaceDynamics","category":"section"},{"location":"#Citing-StateSpaceDynamics.jl","page":"Home","title":"Citing StateSpaceDynamics.jl","text":"If you use this software in your research, please cite our publication in the Journal Of Open Source Software:\n\n@article{Senne_StateSpaceDynamics_jl_A_Julia_2025,\n  author = {Senne, Ryan and Loschinskey, Zachary and Fourie, James and Loughridge, Carson and DePasquale, Brian D.},\n  doi = {10.21105/joss.08077},\n  journal = {Journal of Open Source Software},\n  month = nov,\n  number = {115},\n  pages = {8077},\n  title = {{StateSpaceDynamics.jl: A Julia package for probabilistic state space models (SSMs)}},\n  url = {https://joss.theoj.org/papers/10.21105/joss.08077},\n  volume = {10},\n  year = {2025}\n  }","category":"section"}]
}
