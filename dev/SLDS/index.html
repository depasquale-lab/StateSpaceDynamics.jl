<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Switching Linear Dynamical Systems · StateSpaceDynamics.jl</title><meta name="title" content="Switching Linear Dynamical Systems · StateSpaceDynamics.jl"/><meta property="og:title" content="Switching Linear Dynamical Systems · StateSpaceDynamics.jl"/><meta property="twitter:title" content="Switching Linear Dynamical Systems · StateSpaceDynamics.jl"/><meta name="description" content="Documentation for StateSpaceDynamics.jl."/><meta property="og:description" content="Documentation for StateSpaceDynamics.jl."/><meta property="twitter:description" content="Documentation for StateSpaceDynamics.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="StateSpaceDynamics.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">StateSpaceDynamics.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Models</span><ul><li><a class="tocitem" href="../LinearDynamicalSystems/">Linear Dynamical Systems</a></li><li><a class="tocitem" href="../HiddenMarkovModels/">Hidden Markov Models</a></li><li class="is-active"><a class="tocitem" href>Switching Linear Dynamical Systems</a><ul class="internal"><li><a class="tocitem" href="#Mathematical-Formulation"><span>Mathematical Formulation</span></a></li><li><a class="tocitem" href="#Implementation-Structure"><span>Implementation Structure</span></a></li><li><a class="tocitem" href="#Sampling-from-SLDS"><span>Sampling from SLDS</span></a></li><li><a class="tocitem" href="#Learning-in-SLDS:-Variational-Laplace-EM-(vLEM)"><span>Learning in SLDS: Variational Laplace EM (vLEM)</span></a></li><li><a class="tocitem" href="#The-vLEM-Algorithm"><span>The vLEM Algorithm</span></a></li><li><a class="tocitem" href="#Evidence-Lower-Bound-(ELBO)"><span>Evidence Lower Bound (ELBO)</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../EmissionModels/">Emission Models</a></li><li><a class="tocitem" href="../MixtureModels/">Mixture Models</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/gaussian_latent_dynamics_example/">Gaussian LDS Example</a></li><li><a class="tocitem" href="../tutorials/poisson_latent_dynamics_example/">Poisson LDS Example</a></li><li><a class="tocitem" href="../tutorials/lds_model_selection_example/">LDS Model Selection Example</a></li><li><a class="tocitem" href="../tutorials/lds_identifiability_example/">Non-Identifiability in LDS Models</a></li><li><a class="tocitem" href="../tutorials/hidden_markov_model_example/">Hidden Markov Model Example</a></li><li><a class="tocitem" href="../tutorials/hmm_model_selection_example/">HMM Model Selection</a></li><li><a class="tocitem" href="../tutorials/gaussian_glm_hmm_example/">Gaussian GLM-HMM Example</a></li><li><a class="tocitem" href="../tutorials/hmm_identifiability_example/">HMM Identifiability</a></li><li><a class="tocitem" href="../tutorials/gaussian_mixture_model_example/">Gaussian Mixture Model Example</a></li><li><a class="tocitem" href="../tutorials/poisson_mixture_model_example/">Poisson Mixture Model Example</a></li><li><a class="tocitem" href="../tutorials/Probabilistic_PCA_example/">Probabilistic PCA Example</a></li><li><a class="tocitem" href="../tutorials/switching_linear_dynamical_system_example/">Switching Linear Dynamical System Example</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Models</a></li><li class="is-active"><a href>Switching Linear Dynamical Systems</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Switching Linear Dynamical Systems</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/depasquale-lab/StateSpaceDynamics.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/depasquale-lab/StateSpaceDynamics.jl/blob/main/docs/src/SLDS.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="What-is-a-Switching-Linear-Dynamical-System?"><a class="docs-heading-anchor" href="#What-is-a-Switching-Linear-Dynamical-System?">What is a Switching Linear Dynamical System?</a><a id="What-is-a-Switching-Linear-Dynamical-System?-1"></a><a class="docs-heading-anchor-permalink" href="#What-is-a-Switching-Linear-Dynamical-System?" title="Permalink"></a></h1><p>A <strong>Switching Linear Dynamical System (SLDS)</strong> is a powerful probabilistic model that combines the temporal structure of linear dynamical systems with the discrete switching behavior of Hidden Markov Models. SLDS can model complex time series data that exhibits multiple dynamical regimes, where the system can switch between different linear dynamics over time.</p><p>An SLDS extends the standard Linear Dynamical System (LDS) by introducing a discrete latent state that determines which linear dynamics are active at each time step. This makes SLDS particularly suitable for modeling systems with:</p><ul><li><strong>Multiple operational modes</strong> (e.g., different flight phases of an aircraft)</li><li><strong>Regime changes</strong> (e.g., economic cycles, behavioral states)</li><li><strong>Non-stationary dynamics</strong> where linear dynamics change over time</li><li><strong>Hybrid systems</strong> combining discrete and continuous states</li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="StateSpaceDynamics.SLDS" href="#StateSpaceDynamics.SLDS"><code>StateSpaceDynamics.SLDS</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SLDS{T,S,O,TM,ISV}</code></pre><p>A Switching Linear Dynamical System (SLDS). A hierarchical time-series model of the form:</p><p class="math-container">\[z_t | z_{t-1} ~ Categorical(A_{z_{t-1}, :})
x_t | x_{t-1}, z_t ~ N(A^{(z_t)} x_{t-1} + b^{(z_t)}, Q^{(z_t)})
y_t | x_t, z_t ~ N(C^{(z_t)} x_t + d^{(z_t)}, R^{(z_t)})\]</p><p><strong>Fields</strong></p><ul><li><code>A::TM</code>: Transition matrix for the discrete states (K x K)</li><li><code>πₖ::ISV</code>: Initial state distribution for the discrete states (K-dimensional vector)</li><li><code>LDSs::Vector{LinearDynamicalSystem{T,S,O}}</code>: Vector of K Linear Dynamical Systems, one for each discrete state</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/depasquale-lab/StateSpaceDynamics.jl/blob/51e11510d4a7cabeb3197206ae2c8b7c31cc0539/src/SLDS.jl#L3-L18">source</a></section></article><h2 id="Mathematical-Formulation"><a class="docs-heading-anchor" href="#Mathematical-Formulation">Mathematical Formulation</a><a id="Mathematical-Formulation-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-Formulation" title="Permalink"></a></h2><p>An SLDS with <span>$K$</span> discrete states is defined by the following generative model:</p><p class="math-container">\[\begin{align*}
    z_1 &amp;\sim \text{Cat}(\pi_k) \\
    x_1 &amp;\sim \mathcal{N}(\mu_{0}, P_{0}) \\
    z_t &amp;\mid z_{t-1} \sim \text{Cat}(A_{z_{t-1}, :}) \\
    x_t &amp;\mid x_{t-1}, z_t \sim \mathcal{N}(F_{z_t} x_{t-1}, Q_{z_t}) \\
    y_t &amp;\mid x_t, z_t \sim \mathcal{N}(C_{z_t} x_t, R_{z_t})
\end{align*}\]</p><p>Where:</p><ul><li><span>$z_t ∈ {1, 2, …, K}$</span> is the <strong>discrete switching state</strong> at time <span>$t$</span></li><li><span>$x_t ∈ ℝᴰ$</span> is the <strong>continuous latent state</strong> at time <span>$t$</span></li><li><span>$y_t ∈ ℝᴾ$</span> is the <strong>observed data</strong> at time <span>$t$</span></li><li><span>$π_k$</span> is the <strong>initial discrete state distribution</strong></li><li><span>$A$</span> is the <strong>discrete state transition matrix</strong></li><li><span>$F_{z_t}$</span> is the <strong>state-dependent dynamics matrix</strong> for discrete state <span>$z_t$</span></li><li><span>$Q_{z_t}$</span> is the <strong>state-dependent process noise covariance</strong> for discrete state <span>$z_t$</span></li><li><span>$C_{z_t}$</span> is the <strong>state-dependent observation matrix</strong> for discrete state <span>$z_t$</span></li><li><span>$R_{z_t}$</span> is the <strong>state-dependent observation noise covariance</strong> for discrete state <span>$z_t$</span></li></ul><h2 id="Implementation-Structure"><a class="docs-heading-anchor" href="#Implementation-Structure">Implementation Structure</a><a id="Implementation-Structure-1"></a><a class="docs-heading-anchor-permalink" href="#Implementation-Structure" title="Permalink"></a></h2><p>In <code>StateSpaceDynamics.jl</code>, an SLDS is represented as:</p><pre><code class="language-julia hljs">mutable struct SLDS{
    T&lt;:Real,
    S&lt;:AbstractStateModel,
    O&lt;:AbstractObservationModel,
    TM&lt;:AbstractMatrix{T},
    ISV&lt;:AbstractVector{T},
} &lt;: AbstractHMM
    A::TM # Transition matrix
    πₖ::ISV # Initial state distribution
    LDSs::Vector{LinearDynamicalSystem{T,S,O}} # Vector of LDS models
end</code></pre><p>Each mode in the <code>LDSs</code> vector contains its own <code>LinearDynamicalSystem</code> with:</p><ul><li><strong>State model</strong>: Defines the continuous latent dynamics <span>$F_k$</span>, <span>$Q_k$</span></li><li><strong>Observation model</strong>: Defines the emission process. Currently supports Gaussian and Poisson emission models.</li></ul><h2 id="Sampling-from-SLDS"><a class="docs-heading-anchor" href="#Sampling-from-SLDS">Sampling from SLDS</a><a id="Sampling-from-SLDS-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling-from-SLDS" title="Permalink"></a></h2><p>You can generate synthetic data from an SLDS to test algorithms or create simulated datasets:</p><div class="admonition is-warning" id="Missing-docstring.-e1d448bde3f3bf7f"><header class="admonition-header">Missing docstring.<a class="admonition-anchor" href="#Missing-docstring.-e1d448bde3f3bf7f" title="Permalink"></a></header><div class="admonition-body"><p>Missing docstring for <code>rand(rng::AbstractRNG, slds::SLDS, T::Int)</code>. Check Documenter&#39;s build log for details.</p></div></div><p>The sampling process follows the generative model:</p><ol><li><strong>Initialize</strong>: Sample initial discrete state from <span>$\pi_k$</span> and initial continuous state</li><li><strong>For each time step</strong>:<ul><li>Sample next discrete state based on current state and transition matrix <span>$A$</span></li><li>Sample continuous state using the dynamics of the current discrete state</li><li>Generate observation using the observation model of the current discrete state</li></ul></li></ol><h2 id="Learning-in-SLDS:-Variational-Laplace-EM-(vLEM)"><a class="docs-heading-anchor" href="#Learning-in-SLDS:-Variational-Laplace-EM-(vLEM)">Learning in SLDS: Variational Laplace EM (vLEM)</a><a id="Learning-in-SLDS:-Variational-Laplace-EM-(vLEM)-1"></a><a class="docs-heading-anchor-permalink" href="#Learning-in-SLDS:-Variational-Laplace-EM-(vLEM)" title="Permalink"></a></h2><p><code>StateSpaceDynamics.jl</code> implements a <strong>Variational Laplace Expectation-Maximization (vLEM)</strong> algorithm for parameter estimation in SLDS. This approach efficiently handles the challenging interaction between discrete and continuous latent variables through a structured variational approximation.</p><div class="admonition is-warning" id="Missing-docstring.-a4201efb91f875fe"><header class="admonition-header">Missing docstring.<a class="admonition-anchor" href="#Missing-docstring.-a4201efb91f875fe" title="Permalink"></a></header><div class="admonition-body"><p>Missing docstring for <code>fit!(slds::AbstractHMM, y::AbstractMatrix{T}; max_iter::Int=1000, tol::Real=1e-3) where {T&lt;:Real}</code>. Check Documenter&#39;s build log for details.</p></div></div><h2 id="The-vLEM-Algorithm"><a class="docs-heading-anchor" href="#The-vLEM-Algorithm">The vLEM Algorithm</a><a id="The-vLEM-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#The-vLEM-Algorithm" title="Permalink"></a></h2><p>The vLEM algorithm maximizes the <strong>Evidence Lower Bound (ELBO)</strong> instead of the intractable marginal likelihood. The key insight is to use a structured variational approximation that factorizes as:</p><p class="math-container">\[q(z_{1:T}, x_{1:T}) = q(z_{1:T}) \prod_{k=1}^K q(x_{1:T} | z_{1:T} = k)^{\mathbb{I}[z_{1:T} = k]}\]</p><p>This factorization allows efficient inference by alternating between updating discrete and continuous posteriors.</p><h3 id="Variational-Laplace-Expectation-Step"><a class="docs-heading-anchor" href="#Variational-Laplace-Expectation-Step">Variational Laplace Expectation Step</a><a id="Variational-Laplace-Expectation-Step-1"></a><a class="docs-heading-anchor-permalink" href="#Variational-Laplace-Expectation-Step" title="Permalink"></a></h3><p><strong>0. Initialization:</strong> Initialize with uniform discrete state posteriors and perform an initial smoothing pass using provided parameter values. This establishes the starting point for iterative refinement.</p><p><strong>1. Update Continuous State Posterior (<span>$q(x_{1:T} | z_{1:T})$</span>):</strong> For each discrete state sequence <span>$k$</span>, run Kalman smoothing weighted by the current discrete posterior:</p><p class="math-container">\[q(x_{1:T} \mid z_{1:T} = k) = \prod_{t=1}^T \mathcal{N}(x_t; \hat{x}_{t|T}^{(k)}, P_{t|T}^{(k)})\]</p><p>To handle expectations efficiently, we use a single Monte Carlo sample from this posterior for subsequent computations.</p><p><strong>2. Update Discrete State Posterior (<span>$q(z_{1:T})$</span>):</strong> Run forward-backward algorithm with modified observation likelihoods that incorporate the current continuous posterior:</p><p class="math-container">\[\tilde{p}(y_t | z_t = k) = \int p(y_t | x_t, z_t = k) q(x_t | z_t = k) dx_t\]</p><p>This yields the discrete posterior marginals:</p><p class="math-container">\[q(z_t = k) = \gamma_t(k) = p(z_t = k \mid y_{1:T}, q(x_{1:T}))\]</p><h3 id="Maximization-Step"><a class="docs-heading-anchor" href="#Maximization-Step">Maximization Step</a><a id="Maximization-Step-1"></a><a class="docs-heading-anchor-permalink" href="#Maximization-Step" title="Permalink"></a></h3><p>The M-step updates all parameters using expectations from the E-step:</p><p><strong>Discrete State Parameters:</strong></p><ul><li>Initial distribution: <span>$\pi_k^{(\text{new})} = \gamma_1(k)$</span></li><li>Transition matrix: <span>$A_{ij}^{(\text{new})} = \frac{\sum_{t=1}^{T-1} \xi_{t,t+1}(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i)}$</span></li></ul><p>where <span>$\xi_{t,t+1}(i,j) = p(z_t = i, z_{t+1} = j | y_{1:T})$</span> are the two-slice marginals.</p><p><strong>Continuous State Parameters for each mode <span>$k$</span>:</strong></p><p>Using weighted sufficient statistics from the smoothed posteriors:</p><ul><li>Dynamics matrix: <span>$F_k^{(\text{new})}$</span> from weighted least squares</li><li>Process covariance: <span>$Q_k^{(\text{new})}$</span> from weighted innovation covariance</li><li>Observation matrix: <span>$C_k^{(\text{new})}$</span> from weighted observation regression</li><li>Observation covariance: <span>$R_k^{(\text{new})}$</span> from weighted observation residuals</li><li>Initial parameters: <span>$\mu_0^{(k)}, P_0^{(k)}$</span> from weighted initial state statistics</li></ul><p>The weights are given by the discrete posterior probabilities <span>$\gamma_t(k)$</span>.</p><h2 id="Evidence-Lower-Bound-(ELBO)"><a class="docs-heading-anchor" href="#Evidence-Lower-Bound-(ELBO)">Evidence Lower Bound (ELBO)</a><a id="Evidence-Lower-Bound-(ELBO)-1"></a><a class="docs-heading-anchor-permalink" href="#Evidence-Lower-Bound-(ELBO)" title="Permalink"></a></h2><p>The ELBO decomposes into discrete and continuous components:</p><p class="math-container">\[\mathcal{L}(q) = \underbrace{\mathbb{E}_{q(z_{1:T})}[\log p(z_{1:T})] - \mathbb{E}_{q(z_{1:T})}[\log q(z_{1:T})]}_{\text{Discrete HMM entropy}} + \sum_{k=1}^K \gamma_t(k) \underbrace{\left( \mathbb{E}_{q(x_{1:T}|k)}[\log p(y_{1:T}, x_{1:T} | z_{1:T}=k)] + H[q(x_{1:T}|k)] \right)}_{\text{Weighted LDS contribution for mode } k}\]</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><p>For theoretical foundations and algorithmic details:</p><ul><li><strong>&quot;A general recurrent state space framework for modeling neural dynamics during decision-making&quot;</strong> by <strong>David Zoltowski, Jonathon Pillow, and Scott Linderman</strong> (2020)</li><li><strong>&quot;Variational Learning for Switching State-Space Models&quot;</strong> by <strong>Zoubin Ghahramani and Geoffrey Hinton</strong> (1998)</li><li><strong>&quot;Probabilistic Machine Learning: Advanced Topics, Chapter 29&quot;</strong> by <strong>Kevin Murphy</strong></li><li><strong>&quot;A Unifying Review of Linear Gaussian Models&quot;</strong> by <strong>Sam Roweis and Zoubin Ghahramani</strong></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../HiddenMarkovModels/">« Hidden Markov Models</a><a class="docs-footer-nextpage" href="../EmissionModels/">Emission Models »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 21 October 2025 19:36">Tuesday 21 October 2025</span>. Using Julia version 1.12.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body><div data-docstringscollapsed="true"></div></html>
